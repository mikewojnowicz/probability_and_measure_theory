\documentclass{article} % For LaTeX2e

%%% 
% STANDARD PREAMBLE
%%%
%https://tex.stackexchange.com/questions/68821/is-it-possible-to-create-a-latex-preamble-header
\usepackage{/Users/mwojno01/Repos/latex_preamble/preamble}
           
%%% 
% SPECIFIC TO THIS DOCUMENT
%%%

% FASTER LIMITS, INTEGRALS AND SUMS
\newcommand{\dlim}{\ds\lim}
\newcommand{\dint}{\ds\int}
\newcommand{\dsum}{\ds\sum}
\newcommand{\dmu}{\wrt{\mu}}

% SIGMA-FIELDS 
% Sigma fields (text)
\renewcommand{\sf}{$\sigma$-field}
\newcommand{\sfs}{$\sigma$-fields}


% SET FUNCTIONS 
%Finitely additive set functions
\newcommand{\fasf}{\tilde{\mu}_0}
% Signed measure
\newcommand{\signedmu}{\wt{\mu}}

% RATIONALS
\renewcommand{\Q}{\mathbb{Q}}
\begin{document}


\title{Notes on Probability and Measure Theory} 
\maketitle
\setcounter{tocdepth}{2}
\tableofcontents
\newpage 

\section{Overview}

\subsection{References}
The primary reference here is \cite{ash2000probability}.   The book is wonderful for statistical machine learning – it is rigorous,  but also accessible (prerequisites are undergrad-level real analysis and mathematical probability).  Most importantly, it is structured to build towards the kinds of applications in probability that we care about.   (A point of contrast would be a book like that of Stein and Shakarchi, which tends to dwell heavily on things that are of higher interest to pure mathematicians –- long existence proofs, Cantor sets and fractals, etc.) 

 Unless otherwise specified, all references to the ``text" refers to this textbook.  Likewise the symbol $\S$ refers to a Section of that textbook.
 
\subsection{Motivation for topic} \label{sec:motivation_for_topic}

What are some motivations for measure theory?

\begin{itemize}
\item Measure theory underpins some of the most interesting research in Bayesian statistics and probabilistic machine learning (see work from Stephen G. Walker, Michael Jordan, Tamara Broderick, David Dunson, and so on).   Thus, fluency with measure theory opens doors to a higher level of research consumption. 
\item Measure theory underpins research on stochastic processes (as used in Bayesian nonparametrics) and stochastic differential equations (useful for continuous-time time series models, a current topic of active research interest in machine learning). 
\item Measure theory is convenient in unifying various kinds of random variables.\footnote{For example, it allows one to work with discrete and absolutely continuous random variables in a unified way.  For example, the exponential family includes both types of random variables.}
\item Lebesgue integration provide nice limit theorems, e.g. clarifying when one can interchange integrals and limits (such as derivatives).   
\item Lebesgue integrals can be seen as the completion of Riemann integrals (in the same way that the real numbers complete the rationals).
\item Abstract Lebesgue integration allows one to integrate over spaces more general than the reals. 

\end{itemize}



\subsection{Motivation for notes}

It is hard to beat directly consulting a textbook (such as \cite{ash2000probability}) written by a seasoned mathematician who is an excellent pedagogue. However, we have created these notes nonetheless in an attempt to \textit{support lecture and/or discussion}.   With that goal in mind, we:
\begin{itemize}
\item Format the presentation to encourage easier absorption.\footnote{E.g., we exploit space to organize the presentation, whereas a textbook will often provide proofs in paragraph form. We sometimes refactor presentations into more modular subsections.}
\item Add sketches to support intuition.
\item Curate the text.\footnote{We highlight some of the main themes (and cores of proofs), offloading additional detail to the text.} 
\item Provide additional detail in proofs.  Sometimes alternate paths have been given that seemed ``nicer" to me. 
\item Add remarks for color (illustrating the need for propositions, the utility of theorems, or connections between things).
\item Incorporate supporting material from worked homework problems and outside sources.\footnote{This will happen increasingly often as the notes evolve.}
\end{itemize}


%We begin with a discussion of $\sigma$-fields, which are the domains of probability measures, and measures more generally.  As it turns out, measures cannot be defined on all subsets of many spaces that we would like to deal with. For instance, consider Proposition 1.2.6 of \cite{rosenthal2006first} which asserts the existence of non-measurable sets for the uniform distribution.  In particular, there is no definition of $P(A)$ that is defined for all subsets $A \subseteq [0,1]$ satisfying all three conditions below



\section{$\S$ 1.1: Some notes on set theory}

\subsection{Limits of sequences of sets}

\begin{definition}
The \textbf{upper limit} of a sequence of sets is given by
\[ \lim\sup A_n := \bigcap_{n=1}^\infty \bigcup_{k \geq n} A_k \]
Alternatively,
\[ x \in \lim\sup A_n \text{ iff } x \in A_n \text{ for infinitely many } n \]
\end{definition}

\begin{definition}
The \textbf{lower limit} of a sequence of sets is given by
\[ \lim\inf A_n := \bigcup_{n=1}^\infty \bigcap_{k \geq n} A_k \]
Alternatively,
\[ x \in \lim\inf A_n \text{ iff } x \in A_n \text{ eventually ( for all but finitely many $n$ ) } \]
\end{definition}

\begin{figure}
\centering 
\includegraphics[width=.5\textwidth]{images/limsup_and_liminf}	
\caption{A sequence of sets with empty lower limit and non-empty upper limit.}
\end{figure}

\begin{discussion}
Discuss why the two characterizations of upper limit and lower limit are equivalent.	
\end{discussion}

\begin{definition}
If $\lim\inf A_n = \lim\sup A_n = A$, then A is called the \textbf{limit} of the sequence $A_1, A_2, ...$. 
\end{definition}

Now we present a particular kind of limit that will be useful when we discuss continuity of measure. 

\begin{definition}
If $A_1 \subset A_2 \subset ...$ and $\cup_{n=1}^\infty A_n = A$, we say that the $A_n$ form a \textbf{increasing} sequence of sets with limit $A$ or that the $A_n$ increase to $A$; we write $A_n \uparrow A$.  If $A_1 \supset A_2 \supset ... $ and  	$\cap_{n=1}^\infty A_n = A$, we say that the $A_n$ form a \textbf{decreasing} sequence of sets with limit $A$ or that the $A_n$ decrease to $A$; we write $A_n \downarrow A$.
\end{definition}


\begin{figure}[h!]
\centering 
\includegraphics[width=.5\textwidth, angle=90]{images/increasing_and_decreasing_sequences}
\caption{An increasing and decreasing sequence of sets, followed by a sequence of sets which is neither, but which has a limit.}
\label{fig:increasing_and_decreasing_limits_of_sets}
\end{figure}

One can verify that this definition is consistent with the definition of limits, i.e.
\[  \text{If } A_n \uparrow A \text{ or } A_n \downarrow A \text{ then } \lim\inf A_n = \lim\sup A_n = A.\]

As shown in Figure \ref{fig:increasing_and_decreasing_limits_of_sets}, limits of increasing and decreasing sequences are very special kinds of limits.


\subsection{Representing unions as disjoint unions} \label{sec:representing_unions_as_disjoint_unions}
 
\begin{remark}
If $A_1,A_2,...$ are subsets of some set $\Omega$, then
\begin{align*} 
\bigcup_{n=1}^\infty A_n = \bigcupdot_{n=1}^\infty \bigg(A_n \cap A_{n-1}^c \cap ... \cap A_1^c \bigg) 	
\labelit \label{eqn:union_as_disjoint_union}
\end{align*}

In other words, any union can be re-represented as a disjoint union. This is useful because measures are countably additive on disjoint sets, so we prefer to work with collections of disjoint sets.
\label{rk:rerepresenting_unions_as_disjoint_unions}
\end{remark}

\begin{remark}
If $A_n \uparrow A$, then \eqref{eqn:union_as_disjoint_union} becomes
\begin{align*}
	\bigcup_{n=1}^\infty A_n = \bigcupdot_{n=1}^\infty \bigg( A_n - A_{n-1} \bigg) 
\labelit \label{eqn:union_as_disjoint_union_for_increasing_sequences}
\end{align*}
This is because $A_{n-1} \subset A_{n}$, so $A_{n-1}^c \supset A_{n}^c$ by contraposition.	
\end{remark}

\section{$\S$ 1.2: Fields, \sfs, measures}

\subsection{$\S$ 1.2.1-1.2.2: Fields and \sfs}

Probability measures, and measures more generally, cannot be defined on all subsets of many spaces that we would like to deal with.  For instance, non-measurable sets can be shown to exist even for Lebesgue measure on the unit interval.  Proposition 1.2.6 of \cite{rosenthal2006first} shows that there is no definition of $P(A)$ that is defined for all subsets $A \subseteq [0,1]$ satisfying all three conditions below\footnote{In Proposition \ref{prop:existence_of_set_that_is_not_Lebesgue_measurable}, we make a similar observation, along with a proof: there cannot be a measure defined on all subsets of the reals that is both translation invariant and has a finite value on all bounded intervals.}
\begin{enumerate}
\item $P([a,b]) = b-a, \quad 0 \leq a \leq b \leq 1$.	
\item $P(\bigcupdot_{n=1}^\infty A_n ) = \ds\sum_{n=1}^\infty A_n$ for $A_1, A_2, ...$ disjoint subsets of $[0,1]$.
\item $P(A \bigoplus r) = P(A), \quad 0 \leq r \leq 1$, where $A \bigoplus r$ denotes the \textit{r-shift} of $A$, i.e. 
\[ A \bigoplus r := \set{a+r : a \in A, a+r \leq 1} \cup \set{a+r-1 : a \in A, a +r >1}\]
\end{enumerate}

The solution to this problem is to define measures on a restricted domain, $\sigma$-fields.

\subsubsection{$\sigma$-fields}



%We begin with a discussion of $\sigma$-fields, which are typically the domains of probability measures, and measures more generally.\footnote{In the construction of Lebesgue measure, Ash defines a probability measure on a field.  See 1.3.1 of \cite{ash2000probability}.}  As stated in the motivation (Section \ref{sec:motivation_for_topic}), measures cannot be defined on all subsets of many spaces that we would like to deal with. 

%\sfs\ are important because they are the domain of measures.  
%Here are some definitions.

\begin{definition}
Let $\F$ be a collection of subsets of a set $\Omega$.  Then $\F$ is called a \textbf{sigma-field} (or \textit{sigma-algebra}) if it satisfies

\begin{enumerate}[label=\alph*)]
	\item $\Omega \in \F$ 
	\item If $A \in \F$, then $A^c \in \F$.
	\item If $A_1,A_2, ... \in \F$ then $\cup_{i=1}^\infty A_i \in \F$.  
\end{enumerate}
that is, if $\Omega \in \F$ and $\F$ is closed under complementation and countable unions.
\label{def:sigma_field}	
\end{definition}

\begin{remark}
It follows that $\sigma$-fields are closed under countable intersections, since
\[ \cap_{i=1}^\infty A_i \stackrel{\text{DeMorgan's Law}}{=} \cup_{i=1}^\infty A_i^c \]	
\end{remark}

\begin{example}
$\F =\set{\emptyset, \Omega}$ is the smallest \sf\ on $\Omega$. 
\end{example}

\begin{example}
	$\F =2^\Omega$, i.e. the set of all subsets of $\Omega$, is the largest \sf\ on $\Omega$.
\end{example}

\begin{example}
If $A \in \Omega$ is non-empty, then $\F = \set{\emptyset, A, A^c, \Omega}$ is the smallest \sf\ containing $A$.
\end{example}

\begin{notation}
If $\C$ is a class of sets, the smallest \sf\ containing the sets of $\C$ is written as $\sigma(\C$).  This is sometimes called the \textit{minimal \sf\ over $C$} or the \textit{\sf\ generated by $C$}. 
\end{notation}
	
\begin{exercise}
\label{exercise:minimal_sigma_field_containing_n_subsets}
Let $A_1,...,A_n$ be subsets of $\Omega$.  Describe $\F := \sigma(\set{A_1,...,A_n})$, the smallest \sf\ containing $A_1,...,A_n$.  Also describe the number of sets in $\F$.   \textit{This is Ash's Problem 1.2.8.  We can derive the strict upper bound $|\F| \leq 2^{2^n}$. For a complete answer, see GoodNotes. }	
\end{exercise}

\begin{remark}
The gist of exercise \ref{exercise:minimal_sigma_field_containing_n_subsets} is that the collection $\set{A_1,...,A_n}$ partitions $\Omega$ into up to $M=2^N$ pieces, and the minimal sigma field contains all possible finite unions of these pieces, so has at most $2^{M}$ elements.
  
\begin{figure}[h!]
\centering 
\includegraphics[width=.7\textwidth]{images/minimal_sigma_fields}
%\caption{An increasing and decreasing sequence of sets, followed by a sequence of sets which is neither, but which has a limit.}
\end{figure}

\end{remark}

\subsubsection{Fields}

Fields are more general than $\sigma$-fields.  Measures are sometimes constructed by being defined on fields, and then extended to \sfs.  Indeed, we will see this strategy with Lebesgue measure. 

\begin{definition}
Let $\F$ be a collection of subsets of a set $\Omega$.  Then $\F$ is called a \textbf{field} (or \textit{algebra})  if satisfies Definition \ref{def:sigma_field} after replacing condition c) with

\begin{enumerate}
	\item[c')] If $A_1,...A_n \in \F$ then $\cup_{i=1}^n A_i \in \F$.
\end{enumerate}
that is, if $\Omega \in \F$ and $\F$ is closed under complementation and \textit{finite} unions.
\label{def:field}	
\end{definition}

\begin{example} What is an example of a collection that is a \textit{field}, but not a $\sigma$-\textit{field}?  

Let $\Omega=\R$ and $\F_0 = \set{\text{finite disjoint unions of right semi-closed intervals } (a,b], a \neq b}$.  Then $\F_0$ is a field, as can be easily verified.\footnote{By convention, we also count $(a, \infty)$ as right semi-closed for $-\infty\leq a < \infty$, which is necessary for the \sf\ to be closed under complements.}   

\begin{figure}[h!]
\centering
\includegraphics[width=.6\textwidth]{images/rsc_intervals}	
\end{figure}

But $\F_0$ is \underline{not} a \sf.  Note that if $A_n = (-\frac{1}{n},0]$, then $\bigcap_{n=1}^\infty A_n = \set{0}  \not\in \F_0$.
\label{ex:field_of_finite_disjoint_unions_of_rsc_intervals}
\end{example}

\begin{remark}
 If $\F$ is a field, a countable union of sets in $\F$ can be expressed as the limit of an increasing sequence of sets in $\F$, and conversely. For if $A_n \in \F$ and $A_n \uparrow A$, then A is a countable union of sets in $\F$ by definition.  Conversely, if $A = \cup_{n=1}^\infty A_n$, then set $B_N := \cup_{n=1}^N A_n$ and $B_N \uparrow A$. This shows that a \sf\ can also be described as a field that is closed under limits of increasing sequences.  More generally, if $\G$ is the collection of all limits of increasing sequences of sets in some field $\F_0$, we can also describe $\G$ as the collection of all countable unions of sets in $\F_0$. \label{rk:the_limits_of_increasing_and_decreasing_sequences_of_sets_in_a_field_are_also_the_countable_unions}
\end{remark}
%Recalling Figure \ref{fig:increasing_and_decreasing_limits_of_sets}, limits of increasing sequences are very special kinds of limits.


\subsubsection{``Good sets" strategy} \label{sec:good_sets_strategy}

Ash says that there is a type of reasoning that occurs so often in problems involving \sfs\ that it deserves explicit mention.  It is called the \textit{good sets strategy}.   Suppose you want to show that all members of a $\sigma$-algebra   $\F$ have some property $P$.  Define ``good sets" as those that satisfy the property
\[ \G := \{ G \in \F : G \text{ has property } P \} \]
The strategy is then to simply
\begin{enumerate}
\item Show $\G$ contains some class $\C$ such that $\F = \sigma(\C)$
\item Show $\G$ is a $\sigma$-algebra 	
\end{enumerate}


Then you're done!  

Why does this work?

\begin{align*}
& \quad \C \subset \G &&	\text{by 1}\\
&\implies \sigma(\C) \subset \sigma(\G) &&  \\
&\implies \F \subset \G && \text{by 1,2} \\
& \text{Yet $\G \subset \F$ by definition of $\G$.} && \\
& \text{So $\G = \F$.} && \\
& \text{ So all sets in $\F$ are good.} && \\
\end{align*}

Some example applications:
 \begin{itemize}
 \item In the text, Ash uses this strategy (see pp.5) to show that if $\C$ is a class of subsets of $\Omega$, and $A \in \Omega$, then

\[ \explaintermbrace{take minimal sigma field first, then intersect}{\sigma_\Omega(\C) \cap A} = \explaintermbrace{intersect first, then take minimal sigma-field}{\sigma_A(\C \cap A)} \]
 \item  See my handwritten homework exercise for  $\S$ 1.2, Problem 6.
 %\item See the proof of Caratheodory Extension Theorem (Theorem \ref{thm:caratheodory_extension}).	
 \end{itemize}

\begin{remark} 
Later, we will cover the Monotone Class Theorem (see Theorem \ref{thm:monotone_class_theorem}), which provides an alternate mechanism for executing the Good Sets Strategy.  See Remark \ref{rk:monotone_class_theorem_for_executing_good_sets_strategy}.
\end{remark}

\subsubsection{Borel Sets} \label{sec:borel_sets}

An important example of a $\sigma$-field is the Borel Sets $\B(\R)$, defined as the smallest \sf\ of subsets of $\R$ containing all intervals $(a,b] \subset \R$.  

We may alternately characterize $\B(\R)$ as the smallest \sf\ containing
\begin{alphabate}
\item all intervals $(a,b], \; a,b \in \R$
\item all intervals $(a,b), \; a,b \in \R$
\item all intervals $[a,b), \; a,b \in \R$
\item all intervals $[a,b], \; a,b \in \R$.
\item all intervals $(a,\infty), \; a \in \R$.
\item  all intervals $[a,\infty), \; a \in \R$.
\item 	 all intervals $(-\infty,b), \; b \in \R$.
\item  all intervals $(-\infty,b], \; b \in \R$.
\item all open sets of $\R$.\footnote{Recall that an open set is a countable union of open intervals.}
\item all closed sets of $\R$.\footnote{Recall that a set is open iff its complement is closed.}
\end{alphabate}

To illustrate these equivalences, let us equate the first two conditions. That is, let us show that a \sf\ contains all open intervals $(a,b)$ iff it contains all right semi-closed intervals $(a,b]$.  To see this, simply note
\begin{subequations}
\begin{align}
(a,b] &= \bigcap_{n=1}^\infty \bigg(a, b+\frac{1}{n}\bigg) \\
	\intertext{and}
(a,b) &= \bigcup_{n=1}^\infty \bigg(a, b-\frac{1}{n}\bigg] 
\end{align}
\label{eqn:open_intervals_as_rsc_intervals_and_vice_versa}
\end{subequations}

\begin{question}
The text gives another description of the Borel sets $\B(\R)$ as the smallest \sf\ containing $\F_0$, the field of disjoint unions of right semi-closed intervals $(a,b]$.  Can we make the same statement about the field of finite disjoint unions of left semi-closed intervals?
\end{question}

The Borel sets are a large collection of sets.  For instance, Remark \ref{rk:cantor_set_is_a_borel_set} notes that the Cantor set is a Borel set. 

\begin{remark}{\remarktitle{The Cantor set is a Borel set}}
The Cantor set must be a Borel set because it is closed.  To see this more explicitly, note that in each step you "remove the middle third of each part".  
\[K = \bigcap_{i=1}^\infty\bigcap_{j=1}^{3^{i-1}-1}\left[0,\frac{3j+1}{3^i}\right]\cup \left[\frac{3j+2}{3^i}, 1\right] \]
which is a countable number of intersections and unions of closed intervals, and hence Borel by characterization (d) above. 
\label{rk:cantor_set_is_a_borel_set}
\end{remark}

\subsection{$\S$ 1.2.3-1.2.4: Measures}




\begin{definition}
A \textbf{measure} on a \sf\ $\F$ is a non-negative, extended real-valued function $\mu$ on $\F$ such that whenever $A_1, A_2, ...$ form a finite or countably infinite collection of disjoint sets in $\F$, we have countable additivity; that is,
\[ \mu \bigg( \bigcupdot_n A_n \bigg) = \ds\sum_n \mu(A_n) \]
\label{def:measure}	
\end{definition}

\begin{definition}
A \textbf{probability measure} is a measure (Definition \ref{def:measure}) where $\mu(\Omega)=1$.
\label{def:prob_measure}		
\end{definition}

\begin{remark}
Ash additionally assumes that a measure does not take $\mu(A) = \infty$ for all $A \in \F$.\footnote{Likewise, he assumes that signed measures do not take $\mu(A) = -\infty$ for  for all $A \in \F$.}  From this, we automatically obtain $\mu(\emptyset)=0$. For $\mu(A) < \infty$ for some $A$, and by considering the sequence $A, \emptyset, \emptyset, ...$, we have that $\mu(\emptyset)=0$ by countable additivity.   	
\end{remark}

\begin{example}
Let $\Omega$ be any set.  Fix $x_0 \in \Omega$.  Let $\F = 2^\Omega$.  For any $A \in \F$ define $\mu(A) = 1$ if $x_0 \in A$ and $\mu(A) = 0$ if $x_0 \not\in A$.  Then $\mu$ may be called the \textbf{unit mass} concentrated at $x_0$.
\end{example}

\begin{example}
Let $\Omega = \set{x_1,x_2,...}$ be a finite or countably infinite set.  Let $p_1, p_2,...$ be non-negative reals.  Let $\F = 2^\Omega$.  Define
\[\mu(A) = \ds\sum_{x_i \in A} p_i \quad \text{ for all } A \in \F\]
Then $\mu$ is a measure on $\F$. We might call it the ``point weighting" measure. 
\begin{itemize}
\item If $p_i \equiv 1 \; \forall \, i$, then $\mu$ is called the \textbf{counting measure}.
\item If $\sum_i p_i =1$, then $\mu$ is a probability measure.	
\end{itemize}
	
\end{example}


\begin{example}{\remarktitle{Lebesgue measure}}
Define $\mu$ such that 
\[ \mu(a,b] = b-a \quad \forall \, a,b \in \R : b>a \]
As we will see in Section \ref{sec:extension_of_measures}, this requirement determines $\mu$ on a large collection of sets, the Borel Sets $\B(\R)$, which we defined in Section \ref{sec:borel_sets} as the smallest \sf\ of subsets of $\R$ containing all intervals $(a,b] \subset \R$. 
\label{ex:Lebesgue_measure}
\end{example}


\subsection{$\S$ 1.2.5-1.2.6: Properties of measures (and some more general set functions)}

The text considers some generalizations of measures that can be obtained
\begin{enumerate}
\item  by restricting the domain to a field {\footnotesize (in other texts, such functions are called \textit{pre-measures}) }
\item  by only assuming \textit{finite} additivity 
\item by allowing the range to be extended reals ($\bar{\R}$) instead of non-negative extended reals ($\bar{\R}_{\geq 0}$).  
\end{enumerate}



\begin{remark}
With respect to pre-measures, a countably additive function can be defined on a \textit{field} (rather than \sf) if the condition is taken to hold whenever a countable union \textit{does} happen to still be in the field.  Unless otherwise specified, I will assume in these notes by that countably additive functions are always defined on \sfs, and finitely additive functions are defined on fields.
\label{rk:i_am_assuming_a_domain_based_on_the_type_of_additivity}
\end{remark}	



\begin{table}[!h]
\centering	
\begin{tabular}{rcc}
&\multicolumn{2}{c}{\textbf{Range}} \\
& \textbf{non-negative extended reals} & \textbf{extended reals} \\
\textbf{countably additive}& $\mu$ measure  & $\tilde{\mu}$ signed measure \\
\textbf{finitely additive}& $\mu_0$ & $\tilde{\mu}_0$ \\	
\end{tabular}
\caption{Notation for generalizations of measure (For assumed domain in each case, see Remark \ref{rk:i_am_assuming_a_domain_based_on_the_type_of_additivity}.)}
\label{tab:notation_for_generalizations_of_measure}
\end{table}

In Table \ref{tab:notation_for_generalizations_of_measure},  we introduce some notation to try to clarify more immediately when results hold. Note the relations\footnote{So, for example, if something holds for $\tilde{\mu}_0$, it holds for $\mu$.  A simple mnemonic is that adding stuff to the notation generalizes the function.}  
\[ \set{\mu} \subset \set{\mu_0}, \set{\tilde{\mu}} \subset \set{\tilde{\mu}_0}. \]

\begin{remark}
Being able to work with these generalizations will be important in Section \ref{sec:extension_of_measures} on extension of measures.  In particular, it will help us show that we can construct the Lebesgue measure on the Borel sets.
\end{remark}

 \begin{example} Let $\F_0$ be the field of finite disjoint unions of right semi-closed intervals (see Definition \ref{def:rsc_intervals} ), and define the set function $\fasf$ on $\F_0$ as follows\footnote{This example comes from Problem 4 in Section 1.2 of the text}:

\begin{align*}
\fasf(-\infty,a] &=a, && a \in \R  \\
\fasf(a,b] &= b-a, && a,b \in \R, \quad a<b  \\
\fasf(b, \infty) &= -b, && b \in \R \\
\fasf(\R) &=0 &&\\
\fasf(\bigcupdot_{i=1}^n I_i) &= \sum_{i=1}^n \fasf(I_i), && \text{if $I_1, ..., I_n$ are right semi-closed intervals} 
\end{align*}
	
Then $\fasf$ is finitely additive, but not countably additive on $\F_0$.  (Why?) For a proof, see GoodNotes.
 \end{example}

 
Measure-like set functions have useful properties. Using the notation in Table \ref{tab:notation_for_generalizations_of_measure}, we rewrite Theorem 1.2.5 of the text:
 
 \begin{theorem}
 Let $\fasf$ be a finitely additive set function on the field $\F_0$.  Then
 \begin{enumerate}[label=\alph*)]
 \item \label{itm:first} $\fasf(\emptyset)=0$
 \item \label{itm:second} $\fasf(A \cup B) + \fasf (A \cap B) = \fasf(A) + \fasf(B)$ for all $A,B \in \F_0$.
 \begin{figure}[H]
 \centering
 \includegraphics[width=.2\textwidth]{images/two_overlapping_sets}	
 \end{figure}

 \item \label{itm:piece-and-difference} If $A,B \in \F_0$ and $B \subset A$, then   
  \[ \fasf(A) = \fasf(B) + \fasf(A-B)\quad \text{(piece-and-difference decomposition)} \] 
 \begin{figure}[H]
 \centering
 \includegraphics[width=.2\textwidth]{images/whole_and_piece}	
 \end{figure}
 
 \footnote{If the ``piece" satisfies $\fasf(B) < \infty$, we have $\fasf(A-B) = \fasf(A) - \fasf(B) $.  One useful takeaway for piece-and-difference decompositions is that : \textit{the finite measure of the difference is the difference of the finite measures}.}So $\fasf(A) \geq \fasf(B)$ if $\fasf(A-B) \geq 0$. More generally, for non-negative set functions, we have
 \[ \mu_0 (A) \geq \mu_0 (B) \quad \text{(monotonicity)} \] 
 \item \label{itm:subadditivity} Subadditivity holds if $\fasf$ is non-negative, i.e.
 \begin{align*}
 \mu_0 (\cup_{i=1}^n A_i)& \leq \sum_{i=1}^n \mu_0(A_i) \\
  \mu (\cup_{i=1}^\infty A_i)& \leq \sum_{i=1}^\infty \mu(A_i) \\
 \end{align*}
 \end{enumerate}
\label{thm:basic_properties_of_finitely_additive_set_functions}
 \end{theorem}
  
\begin{proof}
 We prove Theorem \ref{thm:basic_properties_of_finitely_additive_set_functions} (b).  The rest is an exercise for the reader (or see the text).
 
 First, we break things into disjoint pieces
 {\footnotesize 
\begin{align*}
A &= \bigg(A \cap B \bigg) \, \bigcupdot \, \bigg(A \cap B^c \bigg)	&& \implies \fasf(A) = \fasf (A \cap B) +  \fasf (A \cap B^c)  && (1) \\
B &= \bigg(A \cap B \bigg) \, \bigcupdot \, \bigg(A^c \cap B \bigg)	&& \implies \fasf(B) = \fasf (A \cap B) +  \fasf (A^c \cap B)  && (2) \\
A \cup B &= \bigg(A \cap B \bigg) \, \bigcupdot \, \bigg(A \cap B^c \bigg) \bigcupdot \, \bigg(A^c \cap B \bigg)	&& \implies \fasf(A \cup B) = \fasf (A \cap B) +  \fasf (A \cap B^c) + \fasf (A^c \cap B)   && (3) 
\end{align*}
}

Summing (1) and (2), we obtain
\[\fasf(A) + \fasf(B) = 2 \fasf(A \cap B) + \fasf(A \cap B^c) + \fasf(A^c \cap B). \]
We use (3) to simplify the RHS, and the result follows.
\end{proof}

\begin{remark}
In the proof of Theorem \ref{thm:basic_properties_of_finitely_additive_set_functions} (b), note that we use a common strategy -- breaking sets into disjoint pieces so that we can apply the assumed (finite or countable) additivity of the set function. 
\end{remark}


\begin{remark}
Is \textit{finiteness} ($|\mu_g (A)| < \infty \; \forall \; A \in \F_g$) equivalent to \textit{boundedness} ($\sup \set{|\mu_g (A)| : A \in \F_g} < \infty$)?
\begin{itemize}
\item $\mu_0, \signedmu$ ? \greencheck
\item $\fasf$ ? \redx (too general)
\end{itemize}
The fact that equivalence holds for signed measures $\signedmu$ is surprising.  Somehow countable additivity compensates for the signedness. See Section 2.1.3 of the text. 
\end{remark}


\subsection{$\S$ 1.2.7-1.2.8: Continuity of countably additive set functions}

Countably additive set functions have a basic continuity property. Continuity of measure is a special case. 

\begin{theorem}
Let $\signedmu$ be a countably additive set function on the \sf\ $\F$. Then

\begin{alphabate}
\item (continuity from below) If $A_1, A_2, ... \in \F$ and $A_n \uparrow A$, then $\signedmu(A_n) \to \signedmu(A)$ as $n \to \infty$.

\begin{figure}[H]
 \centering
\includegraphics[width=.2\textwidth, angle=90]{images/increasing_sequence_of_sets}	
 \end{figure}
   
\item (continuity from above)  If $A_1, A_2, ... \in \F$, $A_n \downarrow A$, and $\signedmu(A_1)$ is finite, then $\signedmu(A_n) \to \signedmu(A)$ as $n \to \infty$. 
\end{alphabate}
\label{thm:continuity_of_countably_additive_set_functions}
\end{theorem}

\begin{proof}
We prove continuity from below, and leave continuity from above as an exercise to the reader (or see text). 
 
First let us assume that all $\signedmu(A_n)$ are finite (*). Then 
\begin{align*}
A &= A_1 \cupdot (A_2 - A_1) \cupdot (A_3 - A_2) \cupdot ... && 	\text{ by } \eqref{eqn:union_as_disjoint_union_for_increasing_sequences} \\
\implies \signedmu(A) &= \signedmu(A_1) + \signedmu(A_2 - A_1) + \signedmu(A_3 - A_2) + ... && \text{(countable additivity)}\\ 
&= \signedmu(A_1) + \signedmu(A_2) - \signedmu(A_1) + \signedmu(A_3) - \signedmu(A_2) + ... && \text{(Theorem \ref{thm:basic_properties_of_finitely_additive_set_functions} \ref{itm:piece-and-difference}, (*) }\\
&= \ds\lim_{n \to \infty} \signedmu(A_n) && \text{(telescoping difference)}
\end{align*}
Now suppose $\signedmu(A_n) = \infty$ for some $n$.   So write 
\begin{align*}
A &= A_n \cupdot A- A_n && \text{(increasing sequence)}\\ 
\implies \signedmu(A) &= \signedmu(A_n) + \signedmu(A - A_n) && \text{(countable additivity)}\\  
&= \infty + \signedmu(A - A_n) 
\end{align*}

So $\signedmu(A)=\infty$.\footnote{Note that we cannot have $\signedmu(A - A_n)=-\infty$, because that would violate additivity.} Replace $A$ by $A_k$ for any $k \geq n$ to also find $\signedmu(A_k)=\infty$ for all $k \geq n$ and the result follows.

Finally suppose $\signedmu(A_n) = -\infty$ for some $n$. Then the result follows in the same way as for $\signedmu(A_n) = \infty$. 

\end{proof}

\begin{remark}
The logic of the proof of Theorem \ref{thm:continuity_of_countably_additive_set_functions} under the finiteness assumption is as follows.  First, we re-represent the union as a disjoint union (the form is particularly simple since the sets are increasing).  This allows us to apply countable additivity. Then we apply the piece-and-difference decomposition (and the subtraction is defined under the finiteness assumption). 	
\end{remark}



\begin{remark}

In proving Theorem \ref{thm:continuity_of_countably_additive_set_functions}  for the case where $\mu(A_n) = \infty$ for some $n$, it is tempting to make the simpler argument 
\begin{align*}
\mu(A) & \geq \mu(A_n) && \text{(monotonicity)}\\	
\mu(A_k) & \geq \mu(A_n) && \text{(monotonicity)}	 
\end{align*}
for $k \geq n$.  But recall from Theorem \ref{thm:basic_properties_of_finitely_additive_set_functions} that monotonicity only holds under non-negativity, and the theorem statement is more general, applying to \textit{signed} set functions as well. 
\end{remark}

\begin{remark}
Theorem \ref{thm:continuity_of_countably_additive_set_functions} still holds if $\F$ is only assumed to be a field, so long as the limit sets $A$ belong to $\F$.  %We will use this formulation later when we want to extend the set function $\mu(a,b]=b-a$ from a field (of disjoint unions of right semi-closed intervals) to a sigma field. 
\end{remark}

We have the result that finite additivity plus continuity equals countable additivity. 

\begin{theorem}
Let $\fasf$ be a finitely additive set function on the field $\F_0$.  Suppose either
\begin{alphabate}
\item $\fasf$ is continuous from below
\item $\fasf$ is continuous from above at the empty set.	
\end{alphabate}
Then $\fasf$ is countably additive.
\label{thm:finite_additivity_plus_continuity_gives_countable_additivity}
\end{theorem}

\begin{proof}
We prove that the conclusion holds under (a) and leave doing the same for (b) as an exercise to the reader (or see text). 	%To show that $\fasf$ is countably additive, we need to show that  $ \fasf \bigg( \bigcupdot_{n=1}^\infty A_n \bigg) = \ds\sum_{n=1}^\infty \fasf(A_n)$.   

Given $A = \bigcupdot_{n=1}^\infty A_n$, we define $P_n := \bigcup_{m \leq n} A_n$ and so $P_n \uparrow A$.   So we have
\begin{align*}
\fasf(P_n) &\to \fasf(A) && \text{(continuity from below)} \\
\implies \fasf(\bigcup_{m \leq n} A_n) &\to \fasf(A) && \text{(definition)} \\	
\implies \ds\sum_{m=1}^n \fasf(A_n) &\to \fasf(A) && \text{(finite additivity)} \\
\end{align*}
Taking $n \to \infty$ gives countable additivity.
\end{proof}





%By , we have


 %we break up the limit of the increasing sequence into a disjoint union as follows	



 \section{$\S$ 1.3: Extension of measures} \label{sec:extension_of_measures}
 
 
\subsection{Extension and approximation} \label{sec:extension_and_approximation}
 
In Example \ref{ex:Lebesgue_measure}, we discussed the concept of length of a subset of $\R$; in particular, we mentioned extending the set function given on intervals by $\mu(a,b] = b-a$ to a larger class of subsets of $\R$.  


 As remarked in Example \ref{ex:field_of_finite_disjoint_unions_of_rsc_intervals}, if we define $\F_0 = \set{\text{finite disjoint unions of right semi-closed intervals } (a,b], a < b}$, then $\F_0$ is a field, as can be easily verified.  And $\mu$ can easily be seen to be a finitely additive set function on $\F_0$.   

\begin{figure}[H]
\centering
\includegraphics[width=.6\textwidth]{images/rsc_intervals}	
\end{figure}

However, $\F_0$ is not a $\sigma$-field.   So how can we extend this function to a measure on a larger class of subsets?  For instance, we would at least like to be able to measure intervals such as $(a,b), [a,b)$ or $[a,b]$ and points $\set{x}$.   The challenges are:

\begin{itemize}
\item \textit{We need to show that $\mu$ is countably additive.} We will do this in Section 5.   Moreover, in that section, we will generalize our problem to set functions given by $\mu(a,b] = F(b)-F(a)$, where $F$ is an increasing right-continuous function from $\R$ to $\R$.
\item \textit{We need to extend $\mu$ to $\sigma(\F_0)$, the minimal $\sigma$-field containing $\F_0$.} In other words, we need to extend $\mu$ to the Borel sets.  We will handle the problem in this section more generally.  In this section, we will deal with the problem of extending a measure on $\F_0$ to a measure on $\sigma(\F_0)$. We do so using Carath\'eodory's Theorem  (Theorem \ref{thm:caratheodory_extension}).  Along the way, we will use Theorem \ref{thm:extension_of_finite_measure} and Theorem \ref{thm:monotone_class_theorem} to prove Theorem \ref{thm:caratheodory_extension}. 
% We refer to a countably additive set function $\mu$ on a field $\F_0$ as a \textit{pre-measure}
\end{itemize}

 \begin{theorem}
 (Theorem 1.3.6 \cite{ash2000probability}) A finite measure on a field $\F_0$ can be extended to a measure on $\sigma(\F_0)$. 	
 \label{thm:extension_of_finite_measure}
 \end{theorem}

\begin{proof}
See pp. 12-17 of \cite{ash2000probability}.	
\end{proof}

\begin{theorem}{\textbf{(Monotone Class Theorem)}}
Let $\F_0$ be a field of subsets of $\Omega$ and $\C$ be a class of subsets of $\Omega$ that is monotone (if $A_n \in \C$ and $A_n \uparrow 
A$ or $A_n \downarrow A$, then $A \in \C$).  If $\C \supset \F_0$ then $\C \supset \sigma(\F_0)$, then minimal $\sigma$-field over $\F_0$. 
 \label{thm:monotone_class_theorem}
\end{theorem}

\begin{proof}
See pp. 18-19 of \cite{ash2000probability}.	
\end{proof}

\begin{remark}
During the proof of Theorem \ref{thm:monotone_class_theorem}, some key observations are made about the relationship between monotone classes and $\sigma$-fields:
\begin{alphabate}
\item A monotone class that is also field is a sigma-field.  (See Remark \ref{rk:the_limits_of_increasing_and_decreasing_sequences_of_sets_in_a_field_are_also_the_countable_unions}.)
\item The smallest monotone class and smallest sigma-field over a field coincide. 
\end{alphabate}
\label{rk:monotone_classes_and_sigma_fields}
\end{remark}

\begin{remark}{\remarktitle{The utility of the Monotone Class Theorem}}
The Monotone Class Theorem provides an alternate route towards executing on the Good Sets Strategy (Section \ref{sec:good_sets_strategy}.)  Suppose you want to show that all members of a $\sigma$-algebra   $\F$ have some property $P$.  Define ``good sets" as those that satisfy the property
\[ \G := \{ G \in \F : G \text{ has property } P \} \]
The strategy is then to simply
\begin{enumerate}
\item Show $\G$ contains some class $\C$ such that $\F = \sigma(\C)$
\item Show $\G$ is a monotone class.  
\end{enumerate}	 
\label{rk:monotone_class_theorem_for_executing_good_sets_strategy}
\end{remark}

\begin{remark}
The strategy in Remark \ref{rk:monotone_class_theorem_for_executing_good_sets_strategy} is very much like induction.  Step \#1 is the ``base" step and step \#2 is the ``induction" step.
\end{remark}

For an example of where the strategy in Remark \ref{rk:monotone_class_theorem_for_executing_good_sets_strategy} is used, see the proof of uniqueness in the Caratheodory Extension Theorem (Theorem \ref{thm:caratheodory_extension}).  It is also used extensively to show that Borel sets have some property; see Section \ref{sec:properties_of_borel_sets}.


\begin{theorem}{\textbf{(Carath\'eodory Extension Theorem)}} Let $\mu$ be a measure on the field $\F_0$ of subsets of $\Omega$, and assume that $\mu$ is $\sigma$-finite on $\F_0$, so that $\Omega$ can be decomposed as $\cup_{n=1}^\infty A_n$ where $A_n \in \F_0$ and $\mu(A_n) < \infty$ for all $n$.  Then $\mu$ has a unique extension to a measure on $\F := \sigma(\F_0)$, the minimal $\sigma$-field over $\F_0$. 
 \label{thm:caratheodory_extension}
\end{theorem}

\begin{proof} (We follow the argument of \cite{ash2000probability}, but add some detail.) 
First we prove existence.  {\footnotesize [Without loss of generality, we assume the $A_n$ are disjoint.  This is possible because we can use \eqref{eqn:union_as_disjoint_union} to re-express the countable union as a disjoint countable union:  $\Omega = \cup_{i=1}^\infty A_i = \cupdot_{i=1}^\infty B_i$, where $B_i := A_i \cap A_{i-1}^c ... \cap A_1^c$.]  } 

If we define $\mu_n(A)=\mu(A \cap A_n)$ for each $A \in \F_0$, then we can decompose $\mu$ into a countable sum of finite measures:
\begin{itemize}
\item $\mu_n$ is a measure on $\F_0$. {\footnotesize   [Its countable additivity is inherited from $\mu$. If $\cupdot_{i=1}^\infty A_i$ is a disjoint union, then so is $\cupdot_{i=1}^\infty (A_i \cap A_n)$, and $\mu( \cupdot_{i=1}^\infty (A_i \cap A_n)) = \sum_{i=1}^\infty \mu(A_i \cap A_n) $ since $A_i \cap A_n$ are in $\F_0$. ] }
\item $\mu_n$ is finite.  {\footnotesize  [True because $\mu_n(A) = \mu(A \cap A_n) \stackrel{\text{monotonicity}}{\leq} \mu(A_n) < \infty$.]	 }
\item  $\mu = \sum_{n=1}^\infty \mu_n$. {\footnotesize  [True because $\mu(A) = \mu(A \cap \Omega) = \mu(A \cap (\cupdot_{n=1}^\infty A_n)) =\mu(\cupdot_{n=1}^\infty (A \cap A_n)) = \sum_{n=1}^\infty \mu(A \cap A_n) = \mu_n (A). $] }
\end{itemize}
Now by Theorem \ref{thm:extension_of_finite_measure}, we can extend each $\mu_n$ to a measure $\mu_n^*$ on $\F$.   Thus $\mu^* := \sum_{n=1}^\infty \mu_n^*$ extends $\mu$ to $\F$.  Moreover, $\mu^*$ is still a measure since the order of summation in a double series of nonnegative terms can be reversed.  {\footnotesize   [Countable additivity still holds  since:

\begin{align*}
\mu^*(\cupdot_{i=1}^\infty A_i) &= \ds\sum_{n=1}^\infty \mu_n^* (\cupdot_{i=1}^\infty A_i) && \\ &= \ds\sum_{n=1}^\infty \ds\sum_{i=1}^\infty \mu_n^* (A_i) && \tinytext{$\mu_n^*$ is measure, so countably additive}\\
	&= \ds\sum_{i=1}^\infty \ds\sum_{n=1}^\infty \mu_n^*(A_i) && \tinytext{reverse order of summation for double series with non-negative terms} \\
	&= \ds\sum_{i=1}^\infty \mu^*(A_i) && \tinytext{def. of $\mu^*$}
\end{align*}

]. }


Now we prove uniqueness.   That is, we prove that if $\lambda$ is a measure on $\F$ and $\lambda = \mu^*$ on $\F_0$, then $\lambda = \mu^*$ on $\F$.    To see this, as before, we decompose the measure into a sum of finite measures: $\lambda = \sum_{n=1}^\infty \lambda_n$ where $\lambda_n := \lambda (A_n \cap A)$.  Now by assumption $\lambda_n = \mu_n^*$ on $\F_0$.  Where are they equal on $\F$?  Let us define the ``good sets" (recall Section \ref{sec:good_sets_strategy})
\[ \G : = \set{A \in \F : \lambda_n (A) = \mu_n^* (A)} \]
Now we can show $\G = \F$ -- that is, \textit{all} sets in the $\sigma$-field are good sets -- by observing
\begin{itemize} 
\item 	 $\G$ is a monotone class.  {\footnotesize 
[This is true by continuity from below (see Theorem \ref{thm:continuity_of_countably_additive_set_functions}). In particular, a countable union can be considered the limit of an increasing sequence of partial unions (See Remark \ref{rk:the_limits_of_increasing_and_decreasing_sequences_of_sets_in_a_field_are_also_the_countable_unions}.) As a result, the measure of the limiting set is determined, as the limit of the the measure of the sets in that sequence.] }
\item $\G \supset \F_0$. {\footnotesize 
[This is true by construction.] }
\end{itemize} 
And so by Monotone Class Theorem (Theorem \ref{thm:monotone_class_theorem}), we have $\G \supset \F$.  But by construction $\G \subset \F$, and so $\G = \F$.  Therefore $\lambda_n = \mu_n^*$ for each $n$.  

So 
\[ \lambda \stackrel{\text{decomposition}}{=} \sum_n \lambda_n = \sum_n \mu_n^* \stackrel{\text{recomposition}}{=} \mu^*, \] proving uniqueness.
\end{proof}


\begin{remark}
The proof of Theorem \ref{thm:caratheodory_extension} reveals the appeal of $\sigma$-finite measures -- they can be decomposed as the countable sum of finite measures (and the order of summation of double series can be reversed for nonnegative series, so countable additivity still holds). 
\end{remark}


In Remark \ref{rk:monotone_classes_and_sigma_fields} (b), we observed that minimal $\sigma$-fields over a field can be characterized as the minimal monotone classes over a field -- so we merely need to close the field over increasing and decreasing sequences of sets.   This idea suggests that if $\F_0$ is a field and $\F = \sigma(\F_0)$, sets in $\F$ can be approximated in some sense by sets in $\F_0$.  The following result formalizes this notion. 


\begin{theorem}{\textbf{(Approximation Theorem)}} Let $(\Omega, \F, \mu)$ be a measure space.  Let $\F = \sigma(\F_0)$ where $\F_0$ is a field of subsets of $\Omega$.  Let $\mu$ be $\sigma$-finite on $\F_0$.  Then for every $A \in \F$ and fixed $\epsilon >0$, there is a set $B \in \F_0$ such that $\mu( A \triangle B) < \epsilon$.  
\label{thm:approximation theorem}	
\end{theorem}


\begin{example}

This interesting example (from \cite{ash2000probability} pp. 20) provides a counterexample to the theorems when $\F_0$ is not $\sigma$-finite. 

\begin{figure}[h!]
\centering
\includegraphics[width=1.\textwidth]{images/example_of_extension}	
\end{figure}
\end{example}

\subsection{Completion of measure spaces} \label{sec:completion_of_measure_spaces}

\begin{definition}
A measure $\mu$ on a $\sigma$-field $\F$ is said to be \textit{complete} iff whenever $A \in F$ and $\mu(A) =0$, we have $B \in F$ for all $B \subset A$.
\end{definition}

\begin{definition}
The \textit{completion} of a measure space $(\Omega, \F, \mu)$ is given by $(\Omega, \F_\mu, \mu)$, where 
\[ \F_\mu := \set{A \cup S : A \in \F, S \subset N 
\text{ for some } N \in \F \text { with } \mu(N) = 0 } \]
and where $\mu$ is extended to $\F_\mu$ by setting $\mu (A \cup S) = \mu(A)$.
\label{def:completion_of_measure_space}
\end{definition}

\begin{remark}
Let us show that Definition \ref{def:completion_of_measure_space} is a valid definition by showing that

\begin{enumerate}
\item \textit{$\F_\mu$ is a $\sigma$-field.}
\item \textit{$\mu$ is a measure on $\F_\mu$.}
\item \textit{The completion is complete.} 	
\end{enumerate}

We justify these in turn:

\begin{enumerate}
\item $\F_\mu$ is closed under countable unions, since 
\[ \cup_{i=1}^\infty (A_i \cup S_i) =  \explaintermbrace{$\in \F$}{(\cup_{i=1}^\infty A_i)} \; \cup \; \explaintermbrace{has measure 0}{(\cup_{i=1}^\infty S_i)} \]
 where the term on the right has measure 0 because $\cup_{i=1}^\infty S_i \subset \cup_{i=1}^\infty N_i \in \F$, and $\mu(\cup_{i=1}^\infty N_i) = \sum_{i=1}^\infty \mu(N_i)= 0$.
 
 $F_\mu$ is also closed under complements, since $S \subset N \implies N^c \subset S^c$, and so
 \[ ( A \cup S)^c = (A^c \cap S^c) = \explaintermbrace{$\in \F$}{(A^c \cap N^c)} \cup \explaintermbrace{has measure 0}{(A^c \cap S^c - N^c)} \]
 where the term on the right has measure 0 by monotonicity, because $A^c \cap S^c - N^c \subset S^c - N^c = S^c \cap (M^c)^c = S^c \cap N \subset N$.
\item First, we show that countable additivity holds in $\F_\mu$. 
\[ \mu(\cupdot_{i=1}^\infty  (A_i \cup S_i)) \stackexplain{see below}{=} \mu(\cupdot_{i=1}^\infty A_i) \stackexplain{$\mu$ countably additive on $\F$ \; }{=} \sum_{i=1}^\infty \mu(A_i) \stackexplain{construction of extension}{=}  \sum_{i=1}^\infty \mu(A_i \cup S_i)  \]
The first equality holds because we can re-represent a disjoint union  $\cupdot_{i=1}^\infty  (A_i \cup S_i) = (\cupdot_{i=1}^\infty A_i) \cup (\cupdot_{i=1}^\infty S_i) $.  Since $\cupdot_{i=1}^\infty S_i  \subset \explaintermbrace{has measure 0 in $\F$}{\cupdot_{i=1}^\infty N_i}$, we have that $\mu((\cupdot_{i=1}^\infty A_i) \cup (\cupdot_{i=1}^\infty S_i)) = \mu(\cupdot_{i=1}^\infty A_i)$. 

Next, we show that $\mu$ is invariant to decompositions: if $A_1 \cup S_1 = A_2 \cup S_2$, then $\mu(A_1 \cup S_1) = \mu(A_2 \cup S_2)$, or more simply $\mu(A_1)=\mu(A_2)$.

\begin{figure}[H]
\centering
\includegraphics[width=.4\textwidth]{images/completion_of_measure_space}	
\end{figure}

We have    
\[ \mu(A_1)  \stackexplain{countable additivity}{=} \mu(A_1 \cap A_2) + \mu(A_1 \cap A_2^c)\stackexplain{see below}{=} \mu(A_1 \cap A_2) \stackexplain{monotonicity}{\leq} \mu(A_2) \]
where the second equality holds since $A_1 \cap A_2^c \subset S_2$ {\footnotesize (which, in turn, holds since $x \in A_1 \implies x \in A_2 \text{ or } x \in S_2$, so $x \in A_1 \text{ and } x \not\in A_2 \implies x \in S_2$)} .

By symmetry, $\mu(A_2) \leq \mu(A_1)$, so $\mu(A_1)=\mu(A_2)$. 
\item By the definition of a complete measure, we need to show that if $B \in \F_\mu$ and $\mu(B)=0$ then $C \in \F_\mu$ for all $C \subset B$.

%Now $B \in \F_\mu \implies B = \explaintermbrace{$\in \F$}{A} \cup \explaintermbrace{has measure 0}{S}$.  

Now $B \in \F_\mu \implies B = \explaintermbrace{$\in \F$}{A} \cup \explaintermbrace{$\subset N \in \F : \mu(N)=0$}{S}$.  

So our assumption $\mu(B) = 0$ gives us $\mu(A) = 0$, since $\mu(B) = \mu(A \cup S) \stackrel{\text{choice of extension}}{=} \mu(A)  =0$.

Now since we have assumed $C \subset B$ we have
\[\mu(C) \stackexplain{monotonicity}{\leq} \mu(B) \stackrel{B \in \F_\mu}{=} \mu(A \cup S)  \stackexplain{subadditivity}{\leq} \mu(A)+\mu(S)  \stackexplain{see above}{=} 0 + \mu(S) = 0 + 0= 0\]

Since $\mu$ is non-negative, this implies that $\mu(C) =0$.  

We can therefore write $C = \explaintermbrace{$\in \F$}{\emptyset} \cup \explaintermbrace{has measure 0}{C}$, so $C \in \F_\mu$.

Thus, $\mu$ on $\F_\mu$ is complete, since any subset of measure 0 is contained in $\F_\mu$.  
\end{enumerate}
\label{rk:completion_of_measure_space_is_well_defined} 
\end{remark}


\begin{example}
Let us provide a simple example of where completing a measure space generates new measurable sets. Consider a measure space given by $(\Omega, \F, \mu)$ where $\Omega=\R$, $\F = \set{\emptyset, A, A^c, \Omega}$ where we take $A=[0,1]$ for concreteness, and where $\mu$ is defined by $\mu(A^c)=1$ and $\mu(A)=0$.  The measure space is not complete, since no proper subset of $A$  is contained in $\F$. (For example, $[0,\half] \not\in \F$.)  If we complete the measure space, we obtain $(\Omega, \F_\mu, \mu)$ where $\F_\mu = \set{\emptyset, A, A^c, \Omega, \text{ any subset of } [0,1]}$.
\end{example}

\begin{problem}
Let $(\Omega, \F, \mu)$ be a complete measure space.  If $f: (\Omega, \F) \to (\Omega', \F')$ and $g: \Omega \to \Omega'$, $g=f$ except on a subset of a set $A \in \F$ with $\mu(A)=0$, show that $g$ is measurable (relative to $\F$ and $\F'$)
\label{prob:in_a_complete_metric_space_you_are_a_measurable_function_if_you_are_equal_to_some_other_measurable_function_ae}
\end{problem}

\begin{proof}[Solution.]
For all $A \in \F'$, 
{\footnotesize 
\begin{align*}
g^{-1}(A) &= \biggset{x: x \in g^{-1}(A) \text{ and } x \in f^{-1}(A)} && \bigcup \biggset{x: x \in g^{-1}(A) \text{ and } x \not\in f^{-1}(A)}	 \\
&= \explaintermbrace{$\in \F$ since $f$ measurable}{\set{x \in f^{-1}(A)}}\setminus \explaintermbrace{$\in \F$ by completeness, as a subset of a set of measure 0 }{\biggset{x : x \in f^{-1}(A) \text{ and } x \not\in g^{-1}(A)}} && \bigcup \explaintermbrace{$\in \F$ by completeness, as a subset of a set of measure 0 }{\biggset{x: x \in g^{-1}(A) \text{ and } x \not\in f^{-1}(A)}}
\end{align*}
 }
 
So by closure properties of $\sigma$-fields, $g^{-1}(A) \in \F$. 

 \begin{figure}[H]
 \centering
 \includegraphics[width=.4\textwidth, angle=90]{images/measurability_of_functions_in_complete_measure_spaces_from_ae_equality}
 \end{figure}

\end{proof}



 \section{$\S$ 1.4: Lebesgue-Stieltjes Measures and Distribution Functions} \label{sec:ls_measures_and_distribution_functions}
 
 \begin{definition}
 A \textit{Lebesgue-Stieltjes measure} on $\R$ is a measure $\mu$ on $\B(\R)$ such that $\mu(I) < \infty$ for each bounded interval $I$.	
 \end{definition}

\begin{definition}
 A \textit{distribution function} on $\R$ is a map $F : \R \to \R$ that is increasing [ $a<b$ implies $F(a) \leq F(b)$] and right continuous [ $\lim_{x \downarrow x_0} F(x) = F(x_0)$]. 
 \end{definition}
 
In this Section, we show that the formula $\mu(a,b] = F(b) - F(a)$ sets up a one-to-one correspondence between distribution functions and Lebesgue-Stieltjes measures.    

 
 \subsection{$\S$ 1.4.2 Each Lebesgue-Stietljes measure uniquely determines a distribution function (up to an additive constant)}
 First, the easy part: we show that to every Lebesgue-Stieltjes  measure, there is a unique distribution function (up to an additive constant). 
 
 \begin{theorem}
 Let $\mu$ be a Lebesgue-Stietljes measure on $\R$.  Let $\F : \R \to \R$ be defined (up to additive constant) by $F(b)-F(a) = \mu(a,b]$ for $a<b$. Then $F$ is a distribution function.
 \end{theorem}

\begin{proof}
We must show that $F$ is increasing and right continuous.

\begin{enumerate}
\item We have $F(b) - F(a) = \mu(a,b] \geq 0$, since $\mu$ is non-negative. So $F$ is increasing.  
\item By the continuity (from above) of measure (which can be applied since since Lebesgue-Stietljes measures are finite on any interval), 
\[ \ds\lim_{b' \downarrow b}[F(b') - F(a)] = \ds\lim_{b' \downarrow b} \mu(a,b'] = \mu(a,b]\]

Thus, rearranging,
\[ \ds\lim_{b' \downarrow b} F(b') = \mu(a,b] + F(a) = \bigg(F(b)-F(a)\bigg) + F(a) = F(b)\]
So $F$ is right continuous.  
\end{enumerate}
\end{proof}


  \subsection{$\S$ 1.4.3-1.4.4 Each distribution function (identified up to additive constant) uniquely determines a Lebesgue-Stietljes measure }
  
 Now the harder part.  We need to show that every distribution function $F$ (identified up to additive constant) uniquely determines a Lebesgue-Stieltjes  measure.  
 
 We will temporarily work with $\overline{\R}$, because it is a compact space, and then convert back to $\R$.  In $\overline{\R}$, by a similar reasoning as we've seen before (e.g. see Section \ref{sec:extension_and_approximation}), it is straightforward to show that the formula $\mu(a,b] = F(a)-F(b), a,b \in \overline{\R}, a <b$ defines a finitely additive set function on $\F_0(\overline{\R})$, the field of disjoint unions of right semi-closed intervals of the extended reals.  
 
 The challenge will be to show that this set function is countably additive.  If we can do that, then we can apply Carath\'eodory's Extension Theorem to extend the corresponding function $\mu$ on $\F_0(\R)$ to $\B(\R)$, as will be done in Theorem \ref{thm:extension_for_Lebesgue_stietljes_measure}. 

\begin{lemma}
The set function $\mu$ is countably additive on $\F_0(\overline{\R})$.
\label{lemma:ls_measures_are_countably_additive_on_the_field_of_disjoint_rsc_intervals} 	
\end{lemma}

\begin{proof}
We assume $F(\infty) - F(-\infty) < \infty$, so that $\mu$ is finite.   (We leave the case where $F(\infty) - F(-\infty) = \infty$	to the reader, or see the text.)  Our strategy will be to show that $\mu$ is continuous from above, in which case we can apply Theorem \ref{thm:finite_additivity_plus_continuity_gives_countable_additivity} (b) to show that the set function is countably additive.

Let $A_n$ be a sequence of sets in $\F_0(\overline{\R})$ such that $A_n \downarrow \emptyset$.  Now each $A_n$ is a finite union of disjoint r.s.c. intervals.

\begin{figure}[H]
\centering
\includegraphics[width=.45\textwidth]{images/decreasing_sequence_of_union_of_rsc_intervals}	
\end{figure}

 Suppose one such interval is $(a,b]$.  By the right continuity of $F$, we can find intervals $(a',b]$ that approximate $(a,b]$ from the inside arbitrarily well, since by continuity from below
\[ \mu(a',b] = F(b) - F(a') \to \mu(a,b] = F(b) - F(a) \text{ as } a' \downarrow a \] 

\begin{figure}[H]
\centering
\includegraphics[width=.45\textwidth]{images/approximating_union_of_rsc_intervals}	
\end{figure}

Thus, we can find sets $B_n \in \F_0(\overline{\R})$  where $\mu(B_n)$ approximates $\mu(A_n)$ to any desired $\epsilon > 0$ that satisfy $B_n \subset \overline{B}_n \subset A_n$.  By these inclusion properties and the decreasing nature of the sequence, we have:
\begin{alphabate}
\item $\cap_{n=1}^\infty \overline{B}_n = \emptyset$.	\quad  {[\footnotesize True because each $\overline{B}_n \subset A_n$, so $\cap_{n=1}^\infty \overline{B}_n \subset \cap_{n=1}^\infty A_n = \emptyset$.  ]} 
\item $\cap_{k=1}^n \overline{B}_k = \emptyset$ for sufficiently large $n$.	\quad  {\footnotesize [We have $\overline{\R} \; \stackrel{ \text{item a)}}{=} \; (\overline{\R} - \cap_{n=1}^\infty \overline{B}_n) \; \stackrel{\text{DeMorgan } \eqref{eqn:demorgan_for_relative_complements}}{=} \; \cup_{n=1}^\infty (\overline{\R} - \overline{B}_n)$.   So $\set{\overline{\R} - \overline{B}_n}$ is an open cover of the compact space $\overline{\R}$. By the Heine-Borel theorem, there must be a finite subcover.  So for sufficiently large $n$, we have $\cup_{k=1}^n (\overline{\R} - \overline{B}_k) = \overline{\R}$.  Taking complements of both sides, and once again applying DeMorgan's law \eqref{eqn:demorgan_for_relative_complements} to the relative complement, we find $\cap_{k=1}^n \overline{B}_k = \emptyset$.  ]}
\item $\cap_{k=1}^n B_k = \emptyset$ for sufficiently large $n$. {\footnotesize [This follow from item b) and the fact that each $B_k \subset \overline{B}_k$.]}
\end{alphabate}

So now we use a piece-and-difference decomposition (Theorem \ref{thm:basic_properties_of_finitely_additive_set_functions} (b) ):
\begin{align*}
A_n &= \bigg( \bigcap_{k=1}^n B_k \bigg) \; \bigcupdot \; \bigg(  A_n - \bigcap_{k=1}^n B_k \bigg) && \tinytext{since $\cap_{k=1}^n B_k \subset B_n \subset A_n$} \\
\implies \mu(A_n) &= \mu(\cap_{k=1}^n B_k) \; + \; \mu(A_n - \cap_{k=1}^n B_k) && \tinytext{countable additivity}\\
 &= \cancelto{0}{\mu(\cap_{k=1}^n B_k)} \; + \; \mu(A_n - \cap_{k=1}^n B_k) && \tinytext{for sufficiently large $n$, by item c) above}\\ 
& \leq  \mu( \cup_{k=1}^n (A_k - B_k))&& \tinytext{monotonicity, since $A_n - \cap_{k=1}^n B_k \stackrel{\text{DeMorgan}}{=} \cup_{k=1}^n
(A_n - B_k) \subset \cup_{k=1}^n
(A_k - B_k)$} \\
& \leq \sum_{k=1}^n \mu( A_k - B_k) && \tinytext{finite subadditivity} \\
& = \sum_{k=1}^n \mu( A_k) - \mu(B_k) && \tinytext{piece-and-difference decomposition; also uses finiteness} \\
&\leq \epsilon \sum_{k=1}^n 2^{-k} && \tinytext{Choose $B_k$ such that $\mu(A_k) - \mu(B_k) < \epsilon 2^{-k}$} \\
& < \epsilon. 
\end{align*}

So for sufficiently large $n$, we have $\mu(A_n) < \epsilon$ for any fixed $\epsilon >0$. Thus, $\mu(A_n) \to 0$ for $A_n \downarrow \emptyset$, and so $\mu$ is continuous from above.  So by Theorem \ref{thm:finite_additivity_plus_continuity_gives_countable_additivity} (b), $\mu$ is countably additive.
\end{proof}

\begin{remark}
The proof of Lemma \ref{lemma:ls_measures_are_countably_additive_on_the_field_of_disjoint_rsc_intervals} is a very cool application of Heine-Borel!  In trying to show continuity from above, we started out with an \textit{infinite} intersection of sets.  But in showing continuity, we needed to work with \textit{finite} collection so that we could apply \textit{finite} subadditivity, since that's all we had to use, by assumption. 
\end{remark}

\begin{theorem}
Let $F$ be a distribution function on $\R$, and let $\mu(a,b] = F(b) - F(a), a < b$.  Then there is a unique extension of $\mu$ to a Lebesgue-Stietljes measure on $\R$.
\label{thm:extension_for_Lebesgue_stietljes_measure}
\end{theorem}

\begin{proof}
See text. 	
\end{proof}

\begin{remark}
The proof of Theorem \ref{thm:extension_for_Lebesgue_stietljes_measure}
essentially directly applies Carathe\'odory's Extension Theorem, since we know from Lemma \ref{lemma:ls_measures_are_countably_additive_on_the_field_of_disjoint_rsc_intervals} that $\mu$ is countably additive on $\F_0(\R)$, a field from which the Borel sets are generated.  The only real additional work is a tedious technical detail to identify a $\mu$-preserving correspondence between sets in $\F_0(\overline{\R})$ (over which we proved countable additivity) and sets in $\F_0(\R)$ (which is the field we actually want to extend).
\end{remark}

  \subsection{$\S$ 1.4.5 Properties of Lebesgue-Stietljes measures}
 Before extension, we had $\mu(a,b] =F(b) - F(a)$ for $a < b$ where $F$ is a distribution function. The set function $\mu$ was defined only on $\F_0(\R)$, the field of disjoint unions of r.s.c interval.  But after extension, $\mu$ is defined on $\B(\R) = \sigma(\F_0(\R))$, which allows us to measure other types of intervals as well (by expressing those intervals as countable unions or intersections of r.s.c intervals; recall \eqref{eqn:open_intervals_as_rsc_intervals_and_vice_versa}).
 
 \begin{proposition}
 Let $\mu$ be a Lebesgue-Stieltjes measure, and let $F$ be its associated distribution function.    Let $F(x^-) = \lim_{y \uparrow x} F(y)$. Then 

 \begin{alphabate}
 \item $\mu(a,b] = F(b) - F(a)$	
 \item $\mu(a,b) = F(b^-) - F(a)$	
 \item $\mu[a,b] = F(b) - F(a^-)$	
 \item $\mu[a,b) = F(b^-) - F(a^-)$	
 \item $\mu\set{x} = F(x) - F(x^-)$	
 \item $\mu(-\infty,x] = F(x) - F(-\infty)$	
 \item $\mu(-\infty,x) = F(x^-) - F(-\infty)$	
 \item $\mu(x,\infty) = F(\infty) - F(x)$	
 \item $\mu[x,\infty) = F(\infty) - F(x^-)$	
 \item $\mu(\R) = F(\infty) - F(-\infty)$	
 \end{alphabate}
 \label{prop:properties_of_LS_measures}
\end{proposition}

\begin{proof}
We prove some of these statements and leave the rest to the reader.  

For (b), note that $(a,b) = \cup_{n=1}^\infty (a, b-\frac{1}{n}]$.  So let $A_n = (a, b-\frac{1}{n}]$. Then  by continuity from below,
\[\mu(a,b) = \ds\lim_{n \to \infty}  \mu(A_n) = \ds\lim_{n \to \infty} \big[F(b-\frac{1}{n}) - F(a) \big] = F(b^-) - F (a) \]

For (c), note that $[a,b] = \cap_{n=1}^\infty (a-\frac{1}{n}, b]$.   So by continuity from above (which applies since the sets in the intersection have finite measure),
\[\mu(a,b] = \ds\lim_{n \to \infty} \big[F(b) - F(a - \frac{1}{n}) \big] = F(b) - F (a^-) \]

For (e), note that $\set{x} = \cap_{n=1}^\infty (x-\frac{1}{n}, x]$.   So the statement follows by the same argument as used in (c).

For (i), we can write $[x,\infty) = \cup_{n=1}^\infty [x, x+n)$.  So by continuity from below, 
\[\mu[x,\infty) = \ds\lim_{n \to \infty}  \mu[x, x+n) \stackrel{(d)}{=} \ds\lim_{n \to \infty} \big[ F\big( (x+n)^- \big) - F(x^-) \big] = F(\infty) - F(x^-) \]

For (j), we can write $\R = \cup_{n=1}^\infty [-n, n]$.  So by continuity from below, 
\[\mu(\R) = \ds\lim_{n \to \infty}  \mu[-n,n] \stackrel{(c)}{=} \ds\lim_{n \to \infty} \big[ F(n) - F(-n) \big] = F(\infty) - F(-\infty) \]
\end{proof}


\begin{remark}{\remarktitle{Continuity at a point iffi measure zero at a point}}
\;
\begin{enumerate}
\item Note that
\begin{align*} 
\mu\set{x} = 0 \quad \Leftrightarrow \quad \text{F is continuous at } x
\labelit\label {eqn:continuity_at_a_point_iffi_measure_zero_at_a_point}
\end{align*} 

which holds by Proposition \ref{prop:properties_of_LS_measures} part e) and the fact that $F$ is already right-continuous by definition. 

\item The magnitude of the discontinuity corresponds with the measure of $\set{x}$. 
\end{enumerate}

 For example, the measure corresponding to the distribution function in Figure \ref{fig:distribution_function_with_positive_mass_on_points_that_is_not_concentrated_on_a_countable_set} puts positive probability mass on the points $\set{x_1}, \set{x_2}, \set{x_3}$ and zero probability mass on all other points. 

 \begin{figure}[H]
 \centering
 \includegraphics[width=.5\textwidth]{images/distribution_function_with_positive_mass_on_points_that_is_not_concentrated_on_a_countable_set}
 \caption{A distribution function with positive mass on points that is not concentrated on a countable set}	
\label{fig:distribution_function_with_positive_mass_on_points_that_is_not_concentrated_on_a_countable_set}
\end{figure}


%Figure \ref{fig:distribution_function_with_positive_mass_on_points_that_is_not_concentrated_on_a_countable_set} helps to illuminate how working with distribution functions will allow us to cover absolutely continuous, discrete, and mixed random variables in a single paradigm. 
   
\label{rk:continuity_at_a_point_iffi_measure_zero_at_a_point}
\end{remark}

\begin{remark}
The characterization of continuity in Remark \ref{rk:continuity_at_a_point_iffi_measure_zero_at_a_point} in terms of measure zero can be an interesting way to prove continuity, or prove the existence of functions with interesting properties.   For instance, take a countable set $S = \set{x_1, x_2, ...}$ and non-negative weights $\set{w_1, w_2, ...}.$ such that $\sum_i w_i < \infty$.   Then define $\mu(A) = \sum_{i} \set{w_i : x_i \in A}$.  Now $\mu$ is a Lebesgue-Stietljes measure (and is in fact a finite measure), since $\mu(I) < \infty$ for each bounded interval $I$. By taking $S$ to be the rationals, we have proven the existence of an increasing function $F : \R \to \R$ that is continuous on the irrationals and discontinuous on the rationals {\footnotesize [since each Lebesgue-Stieltjes measure determines a distribution function $F$ (up to additive constant), and the set of continuities is given by \eqref{eqn:continuity_at_a_point_iffi_measure_zero_at_a_point}]}.
\end{remark}

\begin{remark}{\remarktitle{Lebesgue-Stieltjes measures of intervals for continuous distribution functions}}
When a distribution function $F$ is continuous rather than simply right continuous, the properties in Proposition \ref{prop:properties_of_LS_measures} reveal that the Lebesgue-Stieltjes measure of an interval does not depend upon whether the intervals are open or closed, i.e. 
\begin{subequations}
\begin{align}
\mu(a,b] &= \mu(a,b) = \mu[a,b) = \mu[a,b] = F(b)-F(a) &&  \text{for } a \leq b \\
\mu(-\infty,x) &= \mu(-\infty,x] = F(x) - F(-\infty) && \text{for } x \in \R  \\
\mu(x,\infty) &= \mu[x,\infty) = F(\infty) - F(x) && \text{for } x \in \R  
\end{align}
\label{eqn:LS_measures_with_continuous_distribution_function_dont_care_about_intervals_being_open_or_closed}
\end{subequations}

We will informally summarize this as $\mu(a,b]=\mu(a,b)=\mu[a,b)=\mu[a,b]$, where we may take $a,b \in \overline{\R}$ as long as we aren't closing the interval at $\pm \infty$.
\label{rk:LS_measures_with_continuous_distribution_function_agnostic_to_open_vs_closed_intervals}
\end{remark}


\begin{remark}
Note that the properties in Proposition \ref{prop:properties_of_LS_measures} hold even though differences (between a set and a subset) and measures don't commute outside of finite measures.\footnote{See Theorem \ref{thm:basic_properties_of_finitely_additive_set_functions}.}  For instance, if we determine $F$ from the equivalence class by setting $F(-\infty)=0$, then property d) of Proposition \ref{prop:properties_of_LS_measures} says 
\[  \mu[a,b) = \mu(-\infty, b) - \mu(-\infty, a).\]
But we couldn't make that statement by the piece-and-difference decomposition (see Theorem \ref{thm:basic_properties_of_finitely_additive_set_functions}), since $\mu$ isn't necessarily finite.  Thus, continuity of measure lets claim things that the piece-and-difference decomposition does not.
\end{remark}



\subsection{Examples of Lebesgue-Stieltjes measures on $\R$}

\begin{example}{\remarktitle{Lebesgue measure}}
Under the identity distribution function ($F(x)=x$), we have $\mu(a,b]=F(b)-F(a)$.  This is known as Lebesgue measure.  Recall from Remark \ref{rk:LS_measures_with_continuous_distribution_function_agnostic_to_open_vs_closed_intervals} that since $F$ is continuous, we also have $\mu(a,b]=\mu(a,b)=\mu[a,b)=\mu[a,b]$.
\label{ex:Lebesgue_measure_as_example_of_Lebesgue_stieltjes} 
\end{example}

\begin{example}{\remarktitle{Generating Lebesgue-Stieltjes measures via integration}}
We can generate a large class of measures on $\B(\R)$ as follows.  Let $f$ be integrable (Riemann for now) on any finite interval, and define
\[ F(b) - F(a) = \ds\int_{a}^b f(t) \, dt\]
which determines $F$ up to an additive constant.   Then $F$ is a distribution function (as it is both increasing and continuous), so it gives rise to a Lebesgue-Stieltjes measure $\mu(a,b] = F(b) - F(a)$.  Lebesgue measure (Example \ref{ex:Lebesgue_measure_as_example_of_Lebesgue_stieltjes}) is a special case where $f \equiv 1$.  Once again, Remark \ref{rk:LS_measures_with_continuous_distribution_function_agnostic_to_open_vs_closed_intervals} reveals that by continuity of $F$, we have $\mu(a,b]=\mu(a,b)=\mu[a,b)=\mu[a,b]$.  
\end{example}

\paragraph{A non-example.} All Lebesgue-Stieltjes measures are sigma-finite. (To see this, simply set $\R = \cup_{n \in \mathbb{N}} (-n,n)$, and observe that $\mu(-n,n)<\infty$.). Here we provide an example of a sigma-finite measure that is not Lebesgue-Stieltjes.   First, let $\mu$ be concentrated on $S$ (i.e. $\mu(S^c)=0$), where we set $S= \set{1/n : n=1,2,...}$.    Take $\mu\set{1/n}=1/n$ for all $n$.  Since $\R = \cup_{n=1}^\infty {1/n} \cup S^c$, $\mu$ is sigma-finite.  However,
\[  \mu[0,1] \stackrel{\text{countable additivity}}{=} \ds\sum_{n=1}^\infty \df{1}{n} = \infty\]
and so $\mu$ is not a Lebesgue-Stieltjes measure. 
 
\subsection{Lebesgue measurable sets} \label{sec:Lebesgue measurable sets}

\begin{definition}
The completion of Lebesgue measure relative to $\B(\R)$ gives what is known as the \textit{Lebesgue measurable sets}, denoted $\overline{\B}(\R)$.\footnote{See Section \ref{sec:completion_of_measure_spaces} for the definition of the completion of a measure space.}   
\end{definition}

Each Lebesgue measurable set is the union of a Borel set and a subset of a Borel set with Lebesgue measure zero.

\begin{remark}
Sometimes people use the term ``Lebesgue measure" to refer to

\begin{align*}
\mu : \; & \overline{\B}(\R) \to \R^+
\intertext{as well as}
\mu : \; & \B(\R) \to \R^+
\end{align*}
\end{remark}

\subsection{$\S$ 1.4.6 Lebesgue-Stieltjes Measures on $\R^n$}

\subsubsection{Overview}
In $\R^n$, as with $\R$, is it possible to establish a one-to-one correspondence between Lebesgue-Stieltjes measures and distribution functions (up to some identification conditions).  However, the details are quite tedious.  

For our purposes, we will focus on
\begin{itemize}
\item Pointing out that, and motivating why, the definition of a distribution function must change in $\R^n$.
\item Showing that if $\mu$ is a \textit{finite} measure on the Borel sets of $\R^n$ and $F(x) = \mu(-\infty, x], x \in \R^n$, then $F$ is a distribution function on $\R^n$ and $\mu(a,b]$ can be provided in terms of it.     (The finite condition can be relaxed, but we omit this here.) %#= \Delta_{(a,b]} F$.
\item Providing some examples of Lebesgue-Stieltjes distribution functions in $\R^n$. 
%\item Stating the converse -- that if $F$ is a distribution on $\R^n$, there there is a unique Lebesgue-Stieltjes measure associated to it, with $\mu(a,b]$ determined by it. 	
\end{itemize}

 
\subsubsection{Definitions}
The definition of Lebesgue-Stieltjes measures on $\R^n$ parallels those on $\R$.

\begin{definition}
We define a \textit{right semi-closed interval} (or right semi-closed box) in $\R^n$ as
\[ (a,b] :=	(a_1,b_1] \times ... \times (a_n, b_n]  = \set{x \in \R^n : a_1 < x_1 \leq b_1, ...., a_n < x_n \leq b_n }\]
\end{definition}
\begin{definition}
The \textit{vertices} of a right semi-closed interval in $\R^n$ are given by
\[ V(a,b] = \set{a_1,b_1} \times ... \times \set{a_n, b_n}\]
\label{def:vertices_of_rsc_interval_in_Rn}
\end{definition}

\begin{definition}
The \textit{Borel sets} of 	$\R^n$, denoted $\B(\R^n)$, are those sets which are members of the smallest sigma field containing all right semi-closed intervals $(a,b], a,b \in \R^n$. 
\end{definition}

\begin{definition}
A \textit{Lebesgue-Stieltjes measure} on $\R^n$ is a measure $\mu$ on $\B(\R^n)$ such that $\mu(I) < \infty$ for each bounded interval $I$. 	
\end{definition}

%We have established how to relate distribution functions and measures when the underlying space is $\R$.  When the underlying space is $\R^n$, the situation is different.

\subsubsection{From (finite) measures on $\B(\R^n)$ to distribution functions}
Recall that in $\R$, we observed the following relation between distribution functions  and Lebesgue-Stieltjes measures on right semi-closed intervals 
\begin{align*}
\mu(a,b] = F(b) - F(a), \quad a,b \in \R, a<b 
\labelit \label{eqn:measure_as_distribution_function_difference_for_motivating_LS_in_Rn}
\end{align*}
In particular, we observed that given $\mu$, we could construct an $F$ (up to additive constant) via the above relationship.   If we defined $F(-\infty) = 0$, then we could construct $F$ from $\mu$ directly via 
\[ F(x)=\mu(-\infty, x] = \mu(\omega \in \R : \omega \leq x) \]

We would like to to do the same for $\R^n$.  However, note that the equation 
\begin{align*}
\mu(a,b] = F(b) - F(a), \quad a,b \in \R^n, a<b 	
\labelit \label{eqn:measure_as_distribution_function_difference_for_motivating_LS_in_Rn}
\end{align*}
does \textit{not} hold anymore! To see this, let us define  $F : \R^n \to \R$ via 
\[  F(x) = \mu(-\infty, x] = \mu(\omega \in \R^n : \omega_1 \leq x_1, ..., \omega_n \leq x_n)\]

%{\footnotesize We note that that this parallels the situation in $\R$, where  we have $\mu(-\infty, a]=F(a)$ if we identify a member from the equivalence classes of distribution functions by assuming $F(-\infty)=0$.}


\begin{figure}[H]
\centering
\includegraphics[width=.5\textwidth]{images/distribution_functions_in_Rn}	
\caption{Using a distribution function in $\R^2$ to measure the box $I_1 \times I_2$.}
\label{fig:distribution_functions_in_Rn}
\end{figure}


Now consider Figure \ref{fig:distribution_functions_in_Rn}. We see that if $(a,b] = I_1 \times I_2 = (a_1,b_1] \times (a_2, b_2]$, then 
\begin{align*}
\mu(a,b] &= F(b_1, b_2) - F(a_1, b_2) - F(b_1, a_2) + F(a_1, a_2)
\labelit \label{eqn:measure_of_rsc_interval_in_R2} \\
& \neq F(b_1, b_2) - F(a_1, a_2)
\end{align*}
(Note that we add back in the region that we had double subtracted.)

Now we generalize \eqref{eqn:measure_of_rsc_interval_in_R2} to a formula for measuring r.s.c. intervals in $n$ dimensions, rather than just $2$ dimensions.

\begin{theorem}
Let $\mu$ be a finite measure on $\B(\R^n)$. Define  $F : \R^n \to \R$ via $F(x) = \mu(-\infty, x] = \mu(\omega \in \R^n : \omega_1 \leq x_1, ..., \omega_n \leq x_n)$. Then 
\begin{alphabate}
\item We have 	
	\begin{align*}
	\mu(a,b] &= \Delta_{(a,b]} F  := \Delta_{b_1a_1} \cdots \Delta_{b_na_n} F(x_1, ..., x_n) 
	\labelit \label{eqn:measure_of_rsc_interval_in_Rn_via_distribution_function}
	\intertext{where}
	\Delta_{b_ia_i} G(x_1,...,x_n) &:= G(x_1,....,x_{i-1}, b_i, x_{i+1}, ..., x_n) - G(x_1,....,x_{i-1}, a_i, x_{i+1}, ..., x_n)
	\end{align*}
\item We have
	\begin{align*}
\Delta_{(a,b]} F = \sum_{v \in V(a,b]} (-1)^{\# \text{ of $a_i$'s in v}} \; F(v)
\labelit \label{eqn:computing_area_of_a_rectangle_via_a_distribution}	
	\end{align*}
where $V(a,b]$ are the vertices of $(a,b]$ (see Definition \ref{def:vertices_of_rsc_interval_in_Rn}). 
\end{alphabate}
\label{thm:measure_of_rsc_interval_in_Rn_via_distribution_function}
\end{theorem}

\begin{proof}
We prove part (a) and leave (b) to the reader.
\begin{align*}
\Delta_{b_na_n} &F(x_1, ..., x_n) = 	F(x_1,...,x_{n-1}, b_n) - F(x_1,...,x_{n-1}, a_n)\\
&=\mu(\set{\omega_1 \leq x_1, \; ..., \; \omega_{n-1} \leq x_{n-1}, \; \omega_{n} \leq b_{n}}) - \mu(\set{\omega_1 \leq x_1, \; ..., \; \omega_{n-1} \leq x_{n-1}, \;\omega_{n} \leq a_{n}}) \\
&=\mu(\set{\omega_1 \leq x_1, \; ..., \; \omega_{n-1} \leq x_{n-1}, \; a_n < \omega_{n} \leq b_{n}})
\end{align*}
where the last equality follows by the piece-and-difference decomposition of finite measures.

Similarly, 
\begin{align*}
\Delta_{b_{n-1}a_{n-1}} &\Delta_{b_na_n} F(x_1, ..., x_n) \\
&=\mu(\set{\omega_1 \leq x_1, \;..., \; \omega_{n-2} \leq x_{n-2}, \; a_{n-1} < \omega_{n-1} \leq b_{n-1}, \; a_n < \omega_{n} \leq b_{n}})
\end{align*}
Repeating this, we obtain
\[\Delta_{b_1a_1} \cdots \Delta_{b_na_n} F(x_1, ..., x_n) =  \mu(\set{a_1 < \omega_1 \leq b_1, \; ... \; a_n < \omega_{n} \leq b_{n}}) = \mu(a,b]\]

\end{proof}

\begin{remark}
Note from the proof of Theorem \ref{thm:measure_of_rsc_interval_in_Rn_via_distribution_function} part (a) that the application of the $n$th difference operator restricts the set being measured to the bounds given in the $n$th dimension.  See Figure \ref{fig:applying_the_difference_operator_to_distribution_functions_in_R2}.

\begin{figure}[H]
\centering
\includegraphics[width=.5\textwidth]{images/applying_the_difference_operator_to_distribution_functions_in_R2}	
\caption{Repeated applications of the difference operator to a distribution function in $\R^2$.}
\label{fig:applying_the_difference_operator_to_distribution_functions_in_R2}
\end{figure}


\end{remark}

\begin{remark}
Equation \eqref{eqn:computing_area_of_a_rectangle_via_a_distribution} tells us that we can measure any $n$-dimensional rectangle in $\R^n$ via $2^n$ evaluations of the distribution function. 
\end{remark}


\subsubsection{Defining distribution functions in $\R^n$}

When defining distribution functions on $\R^n$,  we must alter our notion of \textit{increasing}.     This is due to Theorem \ref{thm:measure_of_rsc_interval_in_Rn_via_distribution_function} part (a).

\begin{definition}
 A \textit{distribution function} on $\R^n$ is a map $F : \R^n \to \R$ that is:
 
 \begin{alphabate}
 \item \textit{increasing}, i.e. its increments must be non-negative in the sense that
 \begin{align*}
 \Delta_{(a,b]} F \geq 0 \quad \text{ for all r.s.c. intervals $(a,b]$}
 \labelit \label{eqn:increasing_condition_for_distribution_functions_on_Rn}
 \end{align*}



 \item \textit{right continuous}, that is
 \[ \ds\lim_{y \downarrow x} F(y) = F(x) \]
 where $y \downarrow x$ means $y_i \downarrow x_i$ for each $i=1,...,n$.
 \end{alphabate}
 \label{def:distribution_function_on_Rn}
 \end{definition}
 
 \begin{remark}
 Note that Definition \ref{def:distribution_function_on_Rn} defines increasing in a different manner than what might be intuitive:
 \[ F(y) \geq F(x) \; \text { if } \; y_i \geq x_i \quad \text{ for all } i=1,...,n\]
 However, such a condition would be insufficient to describe a distribution function in $\R^n.$ For an example of a distribution function that is right continuous and increasing in this sense, but which can assign negative measure to an interval, see pp. 6-7 of \cite{durrett2010probability}.
 \end{remark}

 \subsubsection{From distribution functions on $\R^n$ to Lebesgue-Stieltjes measures}
 
 \begin{theorem}
 Let $F$ be a distribution function on $\R^n$, and let $\mu(a,b] = F(a,b], a,b \in \R^n, a \leq b$. Then there is a unique extension of $\mu$ to a Lebesgue-Stieltjes measure on $\R^n$.	
 \end{theorem}
 
 \begin{proof}
 See text. 	
 \end{proof}

\subsubsection{Examples}

Here we provide some examples of how Lebesgue-Stieltjes measures can be constructed on $\R^n$ via distribution functions.

\begin{enumerate}
\item Let $F_1,F_2,...,F_n$ be distribution functions on $\R$, and define $F(x_1,...,x_n) = F_1(x_1) F_2(x_2) \cdots F_n(x_n)$.  Then $F$ is a distribution function on $\R^n$; it is clearly right-continuous, and it is increasing since
\[ \Delta_{(a,b]} F =\ds\prod_{i=1}^n [F(b_i) - F(a_i)] \geq 0 \]
	
A special case is where each $F_i$ is the distribution function corresponding to Lebesgue measure on $\B(\R)$.  Then each $F_i(x_i) = x_i$, and so we have
\[ F(x_1,...,x_n) = x_1x_2 \cdots x_n\]
This $\mu$ is \textit{Lebesgue measure} on $\B(\R^n)$.  Note that 
\[ \mu(a,b] = \Delta_{(a,b]} F = \ds\prod_{i=1}^n (b_i-a_i) \]
and more generally, the Lebesgue measure of any rectangular box is its volume (which can be seen by using a slight tweak to the arguments of parts (b)-(d) of the proof of Proposition \ref{prop:properties_of_LS_measures}). 
\item Let $f$ be any non-negative function from $\R^n$ to $\R$ such that 
\[ \ds\int_{-\infty}^\infty \cdots  \ds\int_{-\infty}^\infty f(x_1,...,x_n) \; dx_1 \cdots dx_n < \infty \]
(For now, we assume the integration is in the Riemann sense.)

Define 
\[ F(x) = \ds\int_{(-\infty,x]} f(t) dt \]
Then $F$ is a distribution function. It is continuous by the fundamental theorem of calculus, and it is increasing since
\[ \Delta_{(a,b]} F(x) = \ds\int_{a_1}^{b_1} \cdots  \ds\int_{a_n}^{b_n} f(x_1,...,x_n) \; dx_1 \cdots dx_n < \infty \]  
\end{enumerate}

%\begin{exercise}
%We wrote ``more generally, the Lebesgue measure of any rectangular box is its volume."  Show that, indeed, 
%\[  \mu(a,b]  = \mu(a,b) = \mu[a,b) = \mu[a,b] \]
%for Lebesgue measure on $\B(\R^n)$.  (Recall that we have shown that these equalities hold for Lebesgue measure on $\B(\R)$.)
%\end{exercise}

\begin{remark}

It may seem hard to verify \eqref{eqn:increasing_condition_for_distribution_functions_on_Rn}, the condition that a distribution function on $\R^n$ must be increasing.  Not to worry, the recipes above provide straightforward mechanisms for constructing distribution functions on $\R^n$ in which the condition will automatically be verified.
\end{remark}

\subsubsection{Summary}

Let us summarize.\footnote{This passage is basically a paragraph from \cite{ash2000probability} pp. 32 verbatim. However, we alter it slightly here to match our notation.} We have seen that if $F$ is a distribution function on $\R^n$, then there is a unique Lebesgue-Stieltjes measure determined by $\mu(a,b] = \Delta_{(a,b]} F, a \leq b$.  Also, if $\mu$ is a finite measure on $\B(\R^n)$ and $F(x) = \mu(-\infty, x], x \in \R^n$, then $F$ is a distribution function on $\R^n$ and $\mu(a,b] =  \Delta_{(a,b]} F, a \leq b$.   It is possible to associate a distribution function with arbitrary Lebesgue-Stieltjes measure on $\R^n$, and thus to establish a one-to-one correspondence between Lebesgue-Stieltjes measures and distribution fucntions (provided distribution functions with the same increments $\Delta_{(a,b)} F, a,b \in \R^n, a \leq b$ are identified).  However, the result will not be needed, and the details are quite tedious. 

%applying_the_difference_operator_to_distribution_functions_in_R2

% TODO: Define the difference operator, give theorem 1.4.8 but for (b) use the Durrett statement, prove (a) like my notes.  Skip the proof of (b).   Perhaps give the Ash statement for (b) in a remark.  Make a picture and remark for (a) giving the intuition: the $n$th application of the difference operator restricts the set being measured to the bounds given in the $n$th dimension.   Then define distribution functions in R^n.  Finally give the extension statement for $R^n$. 

\subsection{Properties of Borel sets under Lebesgue measure} \label{sec:properties_of_borel_sets}

Below we show some properties of Borel sets that hold under Lebesgue measure.  How can we accomplish this?  After all, the Borel sets are rather abstractly defined, and although we have been generating them via disjoint unions of r.s.c intervals, they also contain many types of members (e.g., proper open intervals, proper closed intervals, and singletons; bizarre sets like the Cantor set; inverse images of Borel measurable sets under Borel measurable functions; etc.).

To prove that such properties hold, we can take a standard tact: use the the Monotone Class Theorem,  to show that the Borel sets have some property.  Using this approach, we can show that a property holds for \textit{all} Borel sets if we can just show that the property holds for some field generating the Borel sets (e.g., $\F_0 := \set{\text{disjoint unions of } (a,b], a,b \in \R^n }$) -- a much more tangible object to work with.


\begin{remark}{\remarktitle{Using the Monotone Class Theorem to prove that the Borel sets have some property}}
Suppose you want to show that all Borel sets $\B(\R^n)$ have some property $P$.  Define ``good sets" as those that satisfy the property
\[ \G := \{ B \in \B(\R^n) : B \text{ has property } P \} \]
The strategy is then to simply
\begin{enumerate}
\item Show $\G$ contains $\F_0 := \set{\text{disjoint unions of } (a,b], a,b \in \R^n }$.
\item Show $\G$ is a monotone class.  
\end{enumerate}	 
\label{rk:monotone_class_theorem_for_executing_good_sets_strategy_with_borel_sets}
\end{remark}


This is a particular version of the Good Sets Strategy (see Remark \ref{rk:monotone_class_theorem_for_executing_good_sets_strategy}) in the special case where the $\sigma$-field of interest is the Borel sets (and where we take the field generating them to be $\F_0$).  As pointed out in Remark \ref{rk:monotone_class_theorem_for_executing_good_sets_strategy}, this strategy is very much like induction.  Step \#1 is the ``base" step and Step \#2 is the ``induction" step.

For examples where this strategy is used, see the  Approximation Theorem for Borel sets (Theorem \ref{thm:approximation_theorem_for_borel_sets}) or the proof that Lebesgue measure is translation invariant (Proposition \ref{prop:Lebesgue_measure_is_translation_invariant}). We begin with the Approximation Theorem for Borel sets.  This theorem shows that under appropriate conditions, a Borel set can be approximated from below by a compact set, and from above by an open set. 

%\begin{remark}{\remarktitle{Using the Monotone Class Theorem to prove that the Borel sets have some property}} The Borel sets are rather abstract, and also contain many types of members (e.g., proper open intervals, proper closed intervals, singletons, bizarre sets like the Cantor set, etc.).  The MCT gives us a mechanism for showing that some property holds for \textit{all} Borel sets if we can just show that the property holds for some field generating the Borel sets (e.g., $\F_0 := \set{\text{disjoint unions of } (a,b], a,b \in \R^n }$) -- a much more tangible object to work with.  The strategy that is often used is a variant of the Good Sets strategy (see Remark \ref{rk:monotone_class_theorem_for_executing_good_sets_strategy}):  we consider the class of sets that have some desired property, and show that it is a monotone class and contains $\F_0$.  By the Monotone Class Theorem, these two facts are sufficient to prove that some property holds for all Borel sets.  For examples where this is used, see the  Approximation Theorem for Borel sets (Theorem \ref{thm:approximation_theorem_for_borel_sets}) or the proof that Lebesgue measure is translation invariant (Proposition \ref{prop:Lebesgue_measure_is_translation_invariant}).
%\label{rk:utility_of_montone_class_theorem}	
%\end{remark}

%\subsubsection{$\S$ 1.4.11 Approximation theorem for Borel sets}



\begin{theorem}
\textbf{(Approximation Theorem for Borel sets).} If $\mu$ is a $\sigma$-finite measure on $\B(\R^n)$, then for each $B \in \B(\R^n)$,
\begin{alphabate}
\item $\mu(B) = \sup \set{\mu(K) : K \subset B, K \text{ compact}}$
\item If $\mu$ is in fact a Lebesgue-Stieltjes measure, then
\[ \mu(B) = \inf \set{\mu(V) : V \supset B, V \text{ open}}\]
\item There is an example of a $\sigma$-finite measure on $\B(\R^n)$ that is not a Lebesgue-Stieljes measure for which (b) fails.
\end{alphabate}
\label{thm:approximation_theorem_for_borel_sets}	
\end{theorem}

\begin{proof}
\;
\begin{alphabate}
\item We prove (a) for finite measures.   For the extension to $\sigma$-finite measures, see the text.  

We use the Monotone Class Theorem to show that all Borel sets have the desired property. Let $\G$ be the class of subsets that have the desired property.\footnote{The reader may recognize that we are using the ``good sets" strategy.  See Section \ref{sec:good_sets_strategy} and Remark \ref{rk:utility_of_montone_class_theorem}.} 
	\begin{itemize}
	\item \textit{First, observe that $\G$ contains all compact sets.}  If $K$ is a compact set, then $\mu(K)$ is an upper bound on $\set{\mu(K') : K' \subset K, K' \text{ compact}}$ by monotonicity {\footnotesize [$\mu(K) \geq \mu(K') \text{ for } K' \subset K,  K' \text{ compact}$].}  It is also the least upper bound since for each $\epsilon$, there is a compact $K' \subset K$ satisfying $\mu(K') > \mu(K) - \epsilon$. {\footnotesize [Just take $K'=K$].}  
	\item \textit{Next, we show that $\G$ is a monotone class.}  So we need to show that (i) if $B_n \in \G$ and $B_n \downarrow B$ then $B \in \G$ and (ii) if $B_n \in \G$ and $B_n \uparrow B$ then $B \in \G$.  
		\begin{itemize}
		\item[(i)] Since each $B_n \in \G$, by definition of supremum (see Remark \ref{rk:usage_of_alternate_characterization_of_inf_and_sup}), we can find $K_n \subset B_n$, $K_n$ compact, such that 
		\[\mu(B_n) \leq \mu(K_n) + \epsilon 2^{-n}\]
		Set $K=\cap_{n=1}^\infty K_n$.   Then
		\begin{align*}
		\mu(B) - \mu(K) &= \mu(B-K) && \tinytext{piece-and-difference, $\mu$ finite} \\
		&\stackrel{1}{\leq} \mu(\cup_{n=1}^\infty (B_n-K_n)) && \tinytext{DeMorgan, monotonicity}\\
		&\leq \sum_{n=1}^\infty \mu(B_n - K_n) && \tinytext{countable subadditivity} \\
		&= 	\sum_{n=1}^\infty \mu(B_n) - \mu(K_n) && \tinytext{piece-and-difference, $\mu$ finite} \\
		&= \epsilon 
		\end{align*}
		{\footnotesize [For more detail, Equation (1) applies because $B - \cap_{n=1}^\infty K_n \stackrel{\text{DeMorgan}}{=} \cup_{n=1}^\infty (B-K_n) \stackrel{B \subset B_n}{\subset} \cap_{n=1}^\infty (B_n - K_n)$.]} \\
		
		So for all sets $B$ formed by $B_n \downarrow B$ for $B_n \in \G$, we have that $\mu(B)$ satisfies the second property of the supremum (see Definition \ref{def:supremum_and_infimum}).  {\scriptsize [It satisfies the first property immediately since $K_n \subset B_n  \implies \cap_{n=1}^\infty K_n \subset \cap_{n=1}^\infty  B_n$, so by monotonicity $\mu(K) \leq \mu(B)$, and so $B$ is an upper bound.]} 
		\item[(ii)]  Up to reader or see text for proof. 	
		\end{itemize}
	\item \textit{Now we show that $\G$ contains $\F_0 := \set{\text{disjoint unions of } (a,b], a,b \in \R^n}$}.  Consider that 
	\[ (a,b] = \bigcup_{n=1}^\infty \explaintermbrace{compact}{ \big[a+\frac{1}{n}, b \big] } \]	
	So $[a+1/n, b] \uparrow (a,b]$.  And since $(a,b]$ is the limit of an increasing sequence of compact sets, $(a,b] \in \G$ by the first two bullet points.  A similar argument holds for disjoint unions of sets which have the form $(a,b]$.  
	\item \textit{Now we use the Monotone Class Theorem to finish the proof.} By the previous bulletpoints, $\G$ contains $\F_0 := \set{\text{disjoint unions of } (a,b], a,b \in \R^n}$, and $\G$ is a monotone class.  So by the Monotone Class Theorem (Theorem \ref{thm:monotone_class_theorem}), $\G$ contains $\sigma(\F_0) = \B(\R^n)$.\footnote{In other words, \textit{all} Borel sets are are ``good" - they have the property stated in part (a).}  
	\end{itemize}


\item We prove part (b) for finite measures.  For the extension to $\sigma$-finite measures, see the text.

We have 
\begin{align*}
\mu(B) & \stackrel{1}{\leq}	\inf \set{\mu(V) : V \supset B, V \text{ open}} && \tinytext{by monotonicity and Definition \ref{def:supremum_and_infimum}} \\
 & \stackrel{2}{\leq}	\inf \set{\mu(K^c) : K^c \supset B, K \text{ compact}} && \tinytext{by monotonicity and Proposition \ref{prop:sup_and_inf_for_subsets_are_tighter}} \\
 &= \inf \set{\mu(\R^n) - \mu(K) : K \subset B^c, K \text{ compact}} && \tinytext{by piece-and-difference, $\mu$ finite} \\
 & \stackrel{3}{=}	\mu(\R^n) - \sup \set{\mu(K) : K \subset B^c, K \text{ compact}} && \tinytext{by Proposition \ref{prop:sup_and_inf_for_minkowski_sum_and_diff}} \\
  & =	\mu(\R^n) - \mu(B^c)  && \tinytext{by part (a)}\\
&= \mu(B)
\end{align*}
For more details, Equation (1) holds since, by monotonicity, the LHS is a lower bound on the RHS, so the statement must be true by definition of infimum. Equation (2) holds since the LHS is a smaller set than the RHS (because not every open set is the complement of a compact set)\footnote{Recall that in $\R^n$, a compact set is both closed \textit{and} bounded.}, and the infimum can only increase on subsets by Proposition \ref{prop:sup_and_inf_for_subsets_are_tighter}. Equation (3) holds by writing $\mu(K^c) = \mu(\R^n) - \mu(K)$.  This has the form of a Minkowski set difference $A = \set{c} - B$, where $c$ is a singleton.  So we have $\inf A = \inf ( \set{c} - B) \stackrel{Prop. \ref{prop:sup_and_inf_for_minkowski_sum_and_diff}}{=} \inf \set{c} - \sup B = c - \sup B$. 
\item See the text.
\end{alphabate}
 
 \end{proof}

%\subsubsection{Translation Invariance of Lebesgue Measure}

\begin{proposition}
\textbf{(Translation Invariance of Lebesgue Measure).} Lebesgue measure is translation invariant.  That is, if $B \in \overline{\B}(\R^n)$ and $c \in \R^n$, then $B+c \in  \overline{\B}(\R^n)$ and $\mu(B+c)=\mu(B)$, where $\mu$ is Lebesgue measure.	
\label{prop:Lebesgue_measure_is_translation_invariant}
\end{proposition}

\begin{proof}
We prove the statement for $\B(\R^n)$ and leave the extension to $\overline{\B}(\R^n)$ to the reader. We shall use the Monotone Class Theorem as our vehicle for executing the Good Sets Strategy (see Remark \ref{rk:monotone_class_theorem_for_executing_good_sets_strategy}).  That is, we will let $\G$ be the class of ``good sets" that have the desired property. Then we must show: (a) that $\G$ is a monotone class and (b) that $\G$ contains $\F_0 = \set{\text{disjoint union of sets of the form } (a,b], a, b \in \R^n}$. We will use this strategy twice, to show: (1) that $B \in \B(\R^n)$ and $c \in \R^n$ implies $B+c \in  \B(\R^n)$  (2) that $\mu(B+c)=\mu(B)$ for all $B \in \B(\R^n)$.  

\begin{enumerate}
\item We want to show that $B \in \B(\R^n) \implies B+c \in \B(R^n)$.  Let $\G$ be the sets where the property holds.
	\begin{alphabate}
	\item Consider a sequence $B_n \uparrow B$ such that $B_n \in \G$.  That is, by hypothesis, we have $B_n \in \B(\R^n) \implies B_n+c \in \B(R^n)$.  Then 
	\[  B+c = (\bigcup_{n=1}^\infty B_n) + c = \bigcup_{n=1}^\infty \explaintermbrace{\quad in $ \B(\R^n)$ \, by hypothesis}{(B_n + c)} \explaintermbrace{\quad by $\sigma$-field}{\in \B(\R^n)}\]
	So $B \in \G$.
	\item This property holds on $\F_0$; that is $\G \supset \F_0$.   Given $(a,b] \in \F_0, (a,b]+c = (a+c,b+c] \in \F_0$.  A similar statement holds for disjoint unions of r.s.c. intervals. 
	\end{alphabate}
\item We want to show that $\mu(B+c)=\mu(B)$ for all $B \in \B(\R^n)$.
	\begin{alphabate}
	\item Let $\G$ be the sets where the property holds. We show $\G$ is a monotone class. \\
	 
	 First, we handle increasing sequences. So we want to show $B_n \in \G, B_n \uparrow B \implies B \in G$.   Now by hypothesis, $\mu(B_n + c) = \mu(B_n)$.  So 
	 \begin{align*}
	 \mu(B+c) &=  \mu \big( \cup_{n=1}^\infty (B_n)+c \big)  && \tinytext{def. of $B$} \\
	  &=  \mu \big( \cup_{n=1}^\infty (B_n+c) \big)  && \tinytext{def. of union and +; still an increasing sequence} \\
	 &= \ds\lim_{n \to \infty} \mu(B_n+c)  && \tinytext{continuity from below} \\
	 &= \ds\lim_{n \to \infty} \mu(B_n) && \tinytext{hypothesis} \\
	 &= \mu(B) && \tinytext{continuity from below}
	 \end{align*}
 
 	Now we handle decreasing sequences.  So we want to show $B_n \in \G, B_n \downarrow B \implies B \in G$.  We could use the same argument as above with continuity from above instead of continuity from below, but continuity from above only applies for sets with finite measure.  However, Lebesgue measure is $\sigma$-finite, so we can handle this problem in the standard way.\footnote{In particular, we write $\Omega = \cupdot_{n=1}^\infty \Omega_n$ where $\mu (\Omega_n) < \infty$.\footnote{Recall that we can represent any union as a disjoint union; see Section \ref{sec:representing_unions_as_disjoint_unions}.}  Then we define a finite measure $\mu_n$ via $\mu_n(A) := \mu(A \cap \Omega_n)$.  We have 
 		\[ \mu(A) = \sum_{n=1}^\infty \mu_n(A), \quad (*)\]
 		since $\mu(A) = \mu(\cupdot A \cap \Omega_n) = \sum_n \mu(A \cap \Omega_n) = \sum_n \mu_n(A)$.
 		
 		Now, using the continuity from above argument for finite measures, we have 
 			\[ \mu_n(B+c) = \mu_n(B), \quad (+)\]
 			
 		And so
 		\[\mu(B+c) \stackrel{(*)}{=} \sum_n \mu_n (B+c)   \stackrel{(+)}{=}  \sum_n \mu_n(B) \stackrel{(*)}{=} \mu(B)  \]
 	}
% 	 \begin{align*}
%	 \mu(B+c) &\leq \mu(B) + \mu(c) && \tinytext{countable subadditivity} \\
%	 &= \ds\lim_{n \to \infty} [\mu(B_n)] + \mu(c) && \tinytext{continuity from below} \\
%	 &= \ds\lim_{n \to \infty} [\mu(B_n) + \mu(c)] && \tinytext{limit properties} \\
%	 &= \ds\lim_{n \to \infty} [\mu(B_n)] && \tinytext{hypothesis} \\
%	 &= \mu(B) && \tinytext{continuity from below}
%	 \end{align*}
% 
% 	\red{I AM ON DRUGS, THIS DOESNT HOLD}
	\item Now we show that $\G$ contains $\F_0$. The property certainly holds for r.s.c intervals; that is, $\mu(a+c,b+c] = \mu(a,b]$. \footnote{ For example, in $\R$, we have
	\[ \mu\big( (a,b] + c \big) = \mu\big( (a+c,b+c]\big) =(b+c) - (a+c) = b-a = \mu(a,b]\] 
	}  For Lebesgue measure on $\R^n$, the distribution function is $F(x_1, ..., x_n) = x_1 \cdots x_n$, and so $\mu (a,b] = \Delta_{b_1 a_1} \cdots \Delta_{b_n a_n} [x_1 \cdots x_n]$. Now note that
		\begin{align*}
		\Delta_{b_i + c_i, a_i+c_i} [x_1 \cdots x_n] &= x_1 \cdots x_{i-1} \bigg( (b_i + c_i) - (a_i + c_i)  \bigg) x_{i+1} \cdots x_n \\
		& = x_1 \cdots x_{i-1} \bigg( b_i - a_i  \bigg) x_{i+1} \cdots x_n \\
		&= \Delta_{b_i a_i} [x_1 \cdots x_n]  
		\end{align*}
	So $\Delta_{b_i + c_i, a_i+c_i} = \Delta_{b_i, a_i}$ for each $i=1,..n$.  Thus,  
	\[ \mu(a+c,b+c] = \Delta_{b_1+c_1, a_1 +c_1} \cdots \Delta_{b_n+c_n, a_n+c_n} [x_1 \cdots x_n] = \Delta_{b_1 a_1} \cdots \Delta_{b_n a_n} [x_1 \cdots x_n] = \mu(a,b] \] 
	A similar proof holds for disjoint unions of r.s.c intervals.
	\end{alphabate}
\end{enumerate}

\end{proof}

\subsection{A set that is not Lebesgue measurable} \label{sec:set_that_is_not_Lebesgue_measurable}

\begin{proposition}
Call $x,y \in \R$ equivalent iff $x-y \in \mathbb{Q}$.\footnote{So, for example, some equivalence classes are:
\begin{itemize}
\item $e \sim e + \frac{1}{10} \sim e - \frac{1}{10} \sim e+\frac{50}{3} \sim ...$
\item  $\pi \sim \pi + \frac{1}{10} \sim \pi - \frac{1}{10} \sim \pi+\frac{50}{3} \sim ...$
\item $1 \sim 1 + \frac{1}{10} \sim 1 - \frac{1}{10} \sim 1 +\frac{50}{3} \sim ...$
\end{itemize}
} Define $A \subset [0,1]$ as a set containing one member from each class. (This set exists by axiom of choice.) Then $A$ is not Lebesgue measurable.

\label{prop:existence_of_set_that_is_not_Lebesgue_measurable}
\end{proposition}

\begin{proof}
\begin{alphabate}
\item First, we show that we can partition the reals as $\R = \bigcupdot_{q \in \mathbb{Q}} (q+A)$.  
	\begin{itemize}
		\item \textit{(disjointedness)} Suppose $x \in q+A$ and $x \in r+A$ for some $r,q \in \mathbb{Q}, r \neq q$.  Then $\exists\, a_1,a_2 \in A : q + a_1 = r + a_2 \implies a_1 - a_2 = r - q$.   Now since $r \neq q$, we know that $a_1$ and $a_2$ are not the same.  But they are in the same equivalence class, since $r-q \in \mathbb{Q}$. This  contradicts how $A$ was constructed.
		\item \textit{(containment)} We show $\R \subset \bigcupdot_{q \in \mathbb{Q}} (q+A)$ (as the other direction is obvious).  If $x \in \R$ and $a_x$ is its representative in $A$, then $x-a_x = q \in \mathbb{Q}$, and so $x \in q + A$. %x is in A translated by q.
	\end{itemize}
\item Now we note that since $A \subset [0,1]$, we have 
\[ \bigcupdot_{q \in \mathbb{Q}, 0 \leq q \leq 1} (q + A) \subset [0,2] \]
So 
\[ 2 = [0,2] \stackreltext{subadditivity}{\geq} \mu\bigg(\bigcupdot_{q \in \mathbb{Q}, 0 \leq q \leq 1} q + A \bigg)  = \ds\sum_{q \in \mathbb{Q}, 0 \leq q \leq 1} \mu(q+A) \stackreltext{translation invariance}{=} \ds\sum_{q \in \mathbb{Q}, 0 \leq q \leq 1}  \mu(A) \]
This implies $\mu(A) = 0$, since the RHS of this equation is a countable sum of a constant, and so can only take on values $0$ or $\infty$.
	
But then 
\[ \infty = \mu(\R) \stackreltext{part (a)}= \mu \bigg(\bigcupdot_{q \in \mathbb{Q}} (q+A) \bigg)
= \ds\sum_{q \in \mathbb{Q}} \mu(q+A) 
 \stackreltext{translation invariance}{=}   \ds\sum_{q \in \mathbb{Q}} \mu(A) \stackreltext{see above}{=} 0. \;    \contradiction \]

\end{alphabate}

	
\end{proof}

\begin{remark}
The proof of Proposition \ref{prop:existence_of_set_that_is_not_Lebesgue_measurable} only used the following two properties of Lebesgue measure:
\begin{itemize}
\item translation invariance
\item finiteness on bounded intervals %(note that the argument in part (b) would go through for any bounded interval $[a,b]$ by the choice of bounds on $A$ and on the rationals used in part (b)). % Commented this out because it's outdated and possibly no longer relevant
\end{itemize}
Therefore, our argument shows that there cannot be a translation invariant measure $\lambda$ (except $\lambda \equiv 0$) on the class of all subsets of $\R$ such that $\lambda(I) < \infty$ for all bounded intervals $I$.
\label{rk:implications_of_existence_of_set_that_is_not_Lebesgue_measurable}
\end{remark}

% Commented the question out because it's outdated and possibly no longer relevant
%\begin{question}
%Our discussion in Remark \ref{rk:implications_of_existence_of_set_that_is_not_Lebesgue_measurable} parallels that of \cite{ash2000probability} pp. 35.  But haven't we actually proved a stronger result - namely that there cannot be a translation invariant measure $\lambda$ (except $\lambda \equiv 0$) on the class of all subsets of $\R$ such that $\lambda(I) < \infty$ for \textit{any} bounded interval $I$?
%\end{question}

\section{$\S$ 1.5 Measurable functions and Integration}

In this section, we will introduce the general theory of integration of a function with respect to a general measure, as introduced by Lebesgue.  We will refer to this as \textit{integration} or \textit{Lebesgue integration}. We use use \textit{(Lebesgue) integration against Lebesgue measure} to refer to the special case of integrating a function defined on a sub-domain of the real line with respect to the Lebesgue measure.   %  Some authors reserve the term \textit{Lebesgue integration} for  the special case of integration of a function defined on a sub-domain of the real line with respect to the Lebesgue measure, and refer to integration against arbitrary measure as \textit{abstract Lebesgue integration}.  We will differentiate between the general and special cases by referring to \textit{Lebesgue integration} (which can be against arbitrary measure) and \textit{Lebesgue integration against Lebesgue measure}.

\subsection{Intuition\footnote{Here we borrow freely from some sections of Wikipedia.}} \label{sec:intuition_on_Lebesgue_integration}

Folland summarizes the difference between the Riemann and Lebesgue approaches thus: ``to compute the Riemann integral of $f$, one partitions the domain [...] into subintervals", while in the Lebesgue integral, ``one is in effect partitioning the range of $f$ " \cite{folland1999real}.

Figure \ref{fig:Lebesgue_vs_Riemann} compares how the Riemann and Lebesgue approaches would approximate the area under the curve of a function $f : \R \to \R$. 

\begin{figure}[H]
\centering 
\includegraphics[width=.7\textwidth, angle=270]{images/Lebesgue_vs_Riemann}
\caption{Illustrating the fundamental differences between Riemann and Lebesgue integration}
\label{fig:Lebesgue_vs_Riemann}
\end{figure}

 In particular, notice:
\begin{enumerate}
\item Lebesgue integration partitions the range of $f$, whereas Riemann integration partitions the domain of $f$. As a result, the Lesbegue approach provides \textit{adaptive grouping} when computing the area under the curve as the sum over $n$ contributions.  Whereas a function can vary a lot in Riemann subintervals of the form $A_i = (a_i,b_i)$, in the Lebesgue approach, the function will have controlled amount of variation for each of the $n$ contributions.  While the approaches give equivalent answers for sufficiently nice functions (like continuous functions), the Lebesgue definition makes it possible to calculate integrals for a broader class of functions. For example, as we will see, the \textit{Dirichlet function}, which is 0 where its argument is irrational and 1 otherwise, has a Lebesgue integral, but does not have a Riemann integral.

Lebesgue summarized his approach to integration in a letter to Paul Montel:
\begin{quotation}
I have to pay a certain sum, which I have collected in my pocket.  I take the bills and coins out of my pocket and give them to the creditor in the order I find them until I have reached the total sum. This is the Riemann integral. But I can proceed differently. After I have taken all the money out of my pocket I order the bills and coins according to identical values and then I pay the several heaps one after the other to the creditor. This is my integral.
\end{quotation}



The insight is that one should be able to rearrange the values of a function freely, while preserving the value of the integral.  This process of rearrangement can convert a very pathological function into one that is ``nice" from the point of view of integration, and thus let such pathological functions be integrated.

\item The Riemann approach implicitly assumes that sets in the domain have sizes that are given by Lebesgue measure ($\mu(A) = |A|)$, whereas the Lebesgue approach allows sets in the domain to have sizes given by any arbitrary measure $\mu$.
% Commenting this out because I'm not sure if it's true. \item The Riemann approach assumes that the domain is totally ordered.  In contrast, Lebesgue integrals can be defined for functions on arbitrary spaces.
\end{enumerate}


For another example with domain in $\R^2$, suppose we want to find a mountain's volume (above sea level).

\begin{itemize}
\item \textbf{The Riemann approach}: Divide the base of the mountain into a grid of 1 meter squares. Measure the altitude of the mountain at the center of each square. The volume on a single grid square is approximately 1 $m^2 \times$  (that square's altitude), so the total volume is 1 $m^2$ times the sum of the altitudes.
\item \textbf{The Lebesgue approach}: Draw a contour map of the mountain, where adjacent contours are 1 meter of altitude apart. The volume of earth a single contour contains is approximately 1 m $\times$ (that contour's area), so the total volume is the sum of these areas times 1 m.

\begin{figure}[H]
\centering 
\includegraphics[width=.5\textwidth]{images/contour_plot}
\end{figure}
\end{itemize}

While the Riemann integral considers the area under a curve as made out of vertical rectangles, the Lebesgue definition considers slabs that are not necessarily just rectangles, and so it is more flexible. 



\subsection{$\S$ 1.5.1 Measurable functions}

\subsubsection{Definitions}

\begin{definition}
If $\F$ is a $\sigma$-field of subsets of $\Omega$, then $(\Omega, \F)$ is called a \textit{measurable space} and sets in $\F$ are called \textit{measurable sets}.
\label{def:measurable_space_and_measurable_sets}	
\end{definition}

We can now define measurable functions as those which preserve measurability under inverse images.
   
\begin{definition}
If $h : \Omega_1 \to \Omega_2$, $h$ is a \textit{measurable function} relative to the $\sigma$-fields $\F_j$ of subsets of $\Omega_j$, $j=1,2$, iff $h^{-1}(A) \in F_1$ for all $A \in \F_2$.  We sometimes denote measurable functions as an explicit mapping between measurable spaces: $h : (\Omega_1, \F_1) \to (\Omega_2, \F_2)$.
\label{def:measurable_function}
\end{definition}


Borel measurable functions are a special case of particular interest.  
 
\begin{definition}
A \textit{Borel measurable function} is a measurable function $h : (\Omega_1, \F_1) \to (\R^n, \B(\R^n))$ or  $h : (\Omega_1, \F_1) \to (\overline{\R}^n, \B(\overline{\R}^n))$.  
\label{def:borel_measurable_function}
\end{definition}

Note that the \textit{Borel} in Borel measurability refers to the measurable sets in the \textit{range}, not the domain.  A more precise term would be \textit{$(\F_1, \text{Borel})$-measurable}, since the condition to be a measurable function depends on both sigma-fields.  However, people do not say that.  Unless stated otherwise, we assume $\F_1 = \B$ whenever $\Omega_1$ is a Borel subset of $\R^k$ or $\overline{\R}^k$.

\subsubsection{``Computational" definitions}
In practice, to show that a function is measurable, it suffices to apply what we might call the ``computational definition of measurable functions."

\begin{claim}{\remarktitle{Computational definition of measurable functions}}
For $h : \Omega_1 \to \Omega_2$ to be measurable relative to the $\sigma$-fields $\F_j$ of subsets of $\Omega_j$, $j=1,2$, it suffices to show that $h^{-1}(B) \in \F_1$ for all $B \in \C : \sigma(\C) = \F_2$. 
\label{claim:computational_def_measurability}	
\end{claim}

\begin{proof}
We apply the ``Good Sets" strategy (see Section \ref{sec:good_sets_strategy}).  The ``base" condition is satisfied by hypothesis.  For the ``induction step", we need to show that the good sets form a $\sigma$-field.

Let us define the good sets as $\G := \set{B \in \F_2 : h^{-1}(B) \in \F_1}$.  We check the three conditions:
\begin{itemize}
\item $\Omega_2 \in \G$	? \greencheck.  True because $h^{-1}(\Omega_2) = \Omega_1 \in \F_1$ by  the fact that $\F_1$ is a $\sigma$-field.
\item $B \in \G \implies B^c \in \G$? \greencheck.  Since complements and inverse images commute (see Section \ref{sec:why_define_measurability_this_way}), we have $h^{-1}(B^c) = h^{-1}(B)^c \in \F_1$ by assumption and the fact that $\F_1$ is a $\sigma$-field, and hence closed under complements.
\item $B_1, B_2, ... \in \G \implies \cup_{i=1}^\infty B_i \in \G$? \greencheck.  Since unions and inverse images commute (see Section \ref{sec:why_define_measurability_this_way}), we have $h^{-1}(\cup_{i=1}^\infty B_i) = \cup_{i=1}^\infty h^{-1}(B_i) \in \F_1$ by assumption and the fact that $\F_1$ is a $\sigma$-field, and hence closed under countable unions.   
\end{itemize}

\end{proof}




%\begin{definition}
%Given a measurable function $h : (\Omega_1, \F_1) \to (\Omega_2, \F_2)$, sets in $\F_1$ are called the \textit{measurable sets}. 
%\label{def:measurable_sets}
%\end{definition}

\begin{remark}{\remarktitle{The computational definition of Borel measurability.}}
Thanks to Claim \ref{claim:computational_def_measurability}, to show that a function $h$ is Borel measurable, we simply need to show that $h^{-1}(B) \in \F_1$ for $B \in \C$ for any collection $\C$ that generates the Borel sets. For instance, when $h$ is real-valued, it suffices to show
\begin{itemize}
\item $h^{-1}\big((a,\infty)\big) \in \F_1$ for each $a \in \R$.
\item $h^{-1}\big([a,\infty)\big) \in \F_1$ for each $a \in \R$.
\item $h^{-1}\big((a,b)\big) \in \F_1$ for each $a,b \in \R$.
\item $h^{-1}\big([a,b]\big) \in \F_1$ for each $a,b \in \R$.
\item $h^{-1}(U) \in \F_1$ for each open set $U \subset \R$.
\item $h^{-1}(V) \in \F_1$ for each closed set $V \subset \R$.
\item etc.
\end{itemize}
For a larger list, recall Section \ref{sec:borel_sets}. 
\label{rk:computational_definition_of_Borel_measurability}
\end{remark}

\subsubsection{Examples}

\begin{example}{\remarktitle{Constant functions are Borel measurable}}
Consider a constant function, i.e. $h: (\Omega_1, \F_1) \to (\Omega_2, \F_2)$ such that $h(\omega) =   c$ for all $\omega \in \Omega_1$.  Then $h$ is Borel measurable, since 
\[ h^{-1}(B) = 
\begin{cases}
\Omega, & \text{ if } c \in B\\ 
\emptyset, & \text{ if } c \not\in B\\ 
\end{cases}
\]
\label{ex:constant_functions_are_borel_measurable}
\end{example}

\begin{example}{\remarktitle{Any function is measurable with respect to the trivial $\sigma$-field.}}
Consider any function $h : (\Omega_1, \F_1) \to (\Omega_2, \F_2)$, where $\F_2$ is the trivial $\sigma$-field: $\F_2 = \set{\emptyset, \Omega_2}$.  Then $h$ is measurable since $h^{-1}(\emptyset) = \emptyset \in \F_1$ and  $h^{-1}(\Omega_2) = \Omega_1 \in \F_1$
\label{ex:any_function_is_measurable_with_respect_to_trivial_sigma_field}	
\end{example}

\begin{example}{\remarktitle{Indicators of Borel sets are Borel measurable.}}
Let $A$ be a Borel subset of $\R$,\footnote{Recall Section \ref{sec:borel_sets}.  For instance, we might take $A$ to be an open interval, or a disjoint union of open intervals, or the Cantor set.} and let $I_A : \R \to \R$ be the indicator of $A$; that is $I_A(\omega)=1$ for $\omega \in A$ and $0$ for $\omega \not\in A$. Then $I_A$ is Borel measurable, since for all $B \in \B(\R)$, we have
\[ I_A^{-1}(B) = 
\begin{cases}
\Omega, & \text{ if } 0,1 \in B\\ 
A, & \text{ if } 1 \in B, 0 \not\in B \\
A^c, & \text{ if } 0 \in B, 1 \not\in B \\	
\emptyset, & \text{ if } 0,1 \not\in B\\ 
\end{cases}
\]

\begin{figure}[H]
\centering
\includegraphics[width=.5\textwidth]{images/indicator_of_borel_set}	
\end{figure}

\end{example}

\begin{example}{\remarktitle{Indicators of non-Borel sets are not Borel measurable - but they may still be measurable.}}
Let $A$ be a subset of $\R$ that is not Borel (e.g., $A$ could be the non-Borel set described in Section \ref{sec:set_that_is_not_Lebesgue_measurable}), and let $I_A : \R \to \R$ be the indicator of $A$.   Then $I_A$ is \textit{not} Borel measurable.  

However, $I_A$  \textit{is} measurable with respect to the trivial sigma-field; that is, if we take the mapping to be $I_A : (\R, \B(\R)) \to (\R, \F_2)$, where $F_2 := \set{\emptyset, \R}$.  See Example \ref{ex:any_function_is_measurable_with_respect_to_trivial_sigma_field}.
\label{ex:indicators_of_non_borel_sets_are_not_borel_measurable}
\end{example}

\begin{example}{\remarktitle{Continuous functions are Borel measurable}}. Let $h : \R^k \to \R^n$ be continuous.  Since $h$ is continuous, the inverse image of any open set is open. Hence $h$ is Borel measurable by the computational definition of Borel measurability -- see Remark \ref{rk:computational_definition_of_Borel_measurability}.
\end{example}

\subsubsection{Why define measurability this way?} \label{sec:why_define_measurability_this_way}

Measurable functions do \textit{not} preserve measurability in \textit{both} directions. That is, if $h : (\Omega_1, \F_1) \to (\Omega_2, \F_2)$ is a measurable function, it is not necessarily true that $h(A) \in \F_2$ for all $A \in \F_1$.  For a counterexample, we take $\F_2 = \set{\emptyset, \Omega_2}$, recalling Example \ref{ex:any_function_is_measurable_with_respect_to_trivial_sigma_field}.   Then any $h$ is measurable.  But if there is $A \in F_1$ such that $h(A)$ is a nonempty proper subset of $\Omega_2$, then it is not a measurable set ($h(A) \not\in \F_2$). 

So why is measurability defined by preserving measurability over \textit{inverse} images, rather than in terms of direct images?  In measure theory, inverse images are much nicer objects than direct images.  This is because basic set operations are preserved by inverse images, but in general not by images.  

In particular, for any function $f$
\begin{alphabate}
\item Inverse images and complements commute: $f^{-1}(B^c) = \big(f^{-1}(B)\big)^c$	

\textit{Proof.} $ \big(f^{-1}(B)\big)^c := \set{x : x \not\in f^{-1}(B) } = \set{x : f(x) \not\in B } = \set{x: f(x) \in B^c} = \set{x: x \in f^{-1}(B^c)} := f^{-1}(B^c).$

\item Inverse images and unions commute: $f^{-1}(\cup_i B_i) = \cup_i \big(f^{-1}(B_i)\big)$
\item Inverse images and intersections commute: $f^{-1}(\cap_i B_i) = \cap_i \big(f^{-1}(B_i)\big)$	
\end{alphabate}

However, 
\begin{itemize}
\item[d)] Direct images and complements do not in general commute: $f(A^c) \neq \big(f(A)\big)^c$	

\textit{Proof.} Let $f : \Omega \to \R$ be the constant function, i.e. $f(\omega) = c$ for some $c \in \R$ for all $\omega \in \Omega$.  Let $A$ be a non-empty proper subset of $\Omega$.  Then $h(A) = c$ and $h(A^c) = c$.  So $\R \setminus c = \big(h(A)\big)^c \neq  h(A^c) = c$.

\begin{figure}[H]
\centering
\includegraphics[width=.25\textwidth]{images/direct_images_and_complements}	
\end{figure}


\item[e)] Direct images and intersections do not in general commute: $f(\cap_i A_i) \neq \cap_i \big(f(A_i)\big)$	
\end{itemize}

Recall in Section \ref{sec:intuition_on_Lebesgue_integration} that Lebesgue and Riemann integration are distinguished in terms of whether they partition the range or domain of the function.  My speculation is that the nice interplay of basic set operations and inverse images (but not direct images) at least partially explains why Lebesgue's approach has been more successful than Riemann's approach (in the sense of better limit theorems, better handling of non-Euclidean spaces, etc.).

\subsubsection{Closure properties} \label{sec:closure_properties_of_measurable_functions}

\begin{proposition}
If $h_1, h_2 : (\Omega, \F) \to (\overline{\R}, \B(\overline{\R}))$ are Borel measurable, then so are $h_1 + h_2$ and $h_1 h_2$.  
\label{prop:borel_measurability_closed_under_multiplication_and_addition}
\end{proposition}

\begin{proof}
See \cite{folland1999real} Proposition 2.6.
\end{proof}

\begin{proposition}
If $\set{h_n}$ is a sequence of $\overline{\R}$-valued Borel measurable functions on $(\Omega, \F)$, then the functions
\begin{align*}
\sup_n h_n(\omega), & \quad \quad \limsup_{n \to \infty} h_n(\omega) \\
\inf_n h_n(\omega), & \quad \quad  \liminf_{n \to \infty} h_n(\omega) \\	
\end{align*}
are all measurable. Thus, if $h(\omega) = \lim_{n \to \infty} h_n(\omega)$ exists for all $\omega \in \Omega$, then $h$ is measurable.
\label{prop:borel_measurability_closed_under_inf_sup_liminf_limsup}
\end{proposition}

\begin{proof}
See \cite{folland1999real} Proposition 2.7.
\end{proof}

\subsection{$\S$ 1.5.2-1.5.3 Integrating  Borel measurable functions}

In this section, we define integral of a Borel measurable function $h : (\Omega, \F) \to (\overline{\R}, \B(\overline{\R}))$ against arbitrary measure $\mu$.  The integral can be written as:
\[ \ds\int_{\Omega} h \wrt{\mu}, \quad \quad \ds\int_{\Omega} h(\omega) \wrt{\mu(\omega)}, \quad \text{ or } \quad \ds\int_{\Omega} h(\omega) \mu(d \, \omega) \]
 
 We proceed in three steps: first, we consider where $h$ is simple, then we consider $h$ non-negative, then we consider $h$ arbitrary. 

\subsubsection{Integrals of simple functions}

\paragraph{Definition of simple functions} 

\begin{definition}
Let $(\Omega, \F)$ be a measurable space, fixed throughout the discussion.  If $h : \Omega \to \overline{\R}$, $h$ is said to be \textit{simple} iff $h$ is measurable and takes on only finitely many distinct values.  That is, $h$ is simple iff it can be written $h = \sum_{i=1}^r y_i I_{A_i}$ where the $A_i$ are disjoint sets in $\F$ and $I_{A_i}$ is the indicator of $A_i$; the $y_i$ need not be distinct. 
\label{def:simple_function}	
\end{definition}

\begin{remark}{\remarktitle{Simple functions generalize step functions}}
A special case of simple functions are the step functions used in Riemann integration. 


For $a,b \in \overline{\R}$ with $a<b$, $f : [a,b] \to \R$ is a \textit{step function} if there exists a partition $a = x_0 < x_1 < ... < x_n = b$ and constants $y_1, ..., y_n \in \R$ such that $f(x)=y_i$ for all $y \in (x_{i-1},x_i)$ and each $i=1,...,n$.  Then $f$ is equal to the following simple function:
\[ y_i I_{(x_{i-1}, x_i)} + f(x_i) I_{\set{x_i}}\]

Note that in this case, the sets $A_i$ take on a specific form, as open intervals or one of finitely many singletons.  In general, simple functions allow more general $A_i$. 

%Some observations:
%\begin{itemize}
%\item In this case, the sets $A_i$ take on a specific form, as open intervals or singletons.  In general, simple functions allow more general $A_i$. 
%\item Simple functions do not require that the domain is totally ordered.  
%\end{itemize}
\label{rk:simple_functions_generalize_step_functions}
\end{remark}

\begin{remark}
Note that the indicator function for a non-Borel set (see Example \ref{ex:indicators_of_non_borel_sets_are_not_borel_measurable}) is \textit{not} a simple function, even though it only takes on values 0 and 1. 
%Note that the term \textit{simple} in simple function refers to properties of \textit{both} the domain and range. So for instance, the indicator function for a non-Borel set (see Example \ref{ex:indicators_of_non_borel_sets_are_not_borel_measurable}) is \textit{not} a simple function, even though it only takes on values 0 and 1.  
\end{remark}

\paragraph{Definition of the integral of simple functions}

\begin{definition}
Let $h$ be simple, say $h = \sum_{i=1}^r y_i I_{A_i}$ where the $A_i$ are disjoint sets in $\F$.  Then
\begin{align*}
\ds\int_{\Omega} h \wrt{\mu} := \ds\sum_{i=1}^r y_i \; \mu(A_i).
\labelit \label{eqn:integral_of_simple_function}	
\end{align*}
 \label{def:integral_of_simple_function}
\end{definition}

The integral of a simple function can also be expressed as 
\[\ds\int_{\Omega} h \wrt{\mu} := \ds\sum_{i=1}^r y_i \; \mu \bigg( h^{-1}(y_i) \bigg) \]

\begin{figure}[H]
\centering 
\includegraphics[width=.5\textwidth]{images/integral_of_simple_function}	
\caption{The Lebesgue integral of a simple function. {\scriptsize (In this case, the simple function is also a step function.)}}
\end{figure}

\begin{remark}{\remarktitle{When does the integral of a simple function exist}}
The integral of a simple function exists whenever $\infty$ and  $-\infty$ do not both appear in the sum.  So in particular, the integral for $h$ does not exist when
\begin{itemize}
\item The finite values it takes on $\set{y_i}_{i=1}^r$ include 	$\infty$ and $-\infty$ on sets that are not of measure zero.
\begin{figure}[H]
\centering
\includegraphics[width=.5\textwidth]{images/when_does_integral_of_simple_function_exist_part_1}
\end{figure}

\item It takes on values of opposite signs on two sets of infinite measure.
\begin{figure}[H]
\centering
\includegraphics[width=.5\textwidth]{images/when_does_integral_of_simple_function_exist_part_2}
\end{figure}
\end{itemize}
 
\label{rk:when_does_integral_of_simple_function_exist}
\end{remark}

\begin{remark}{\remarktitle{Integrating simple functions over arbitrary measurable subsets}}
For any $A \in \F$, we define 
\[ \ds\int_A h \wrt{\mu} := \ds\int_\Omega h \, I_A \wrt{\mu}  \]

This definition is possible because whenever $h$ is a simple function, then so is $h I_A$ for any measurable set $A$.   Indeed, if we express $h = \sum_{i=1}^r y_i I_{B_i}$, then $h I_A = \sum_{i=1}^r y_i I_{A} I_{B_i} = \sum_{i=1}^r y_i I_{A \cap B_i}$, and each $A \cap B_i \in \F$.  
\label{rk:integrating_simple_functions_over_arbitrary_measurable_subsets}
 \end{remark}
 
\paragraph{Comparison to Riemann integration}

\begin{example}{\remarktitle{Integrating a step function}}
Let $h$ be a step function, as defined in Remark \ref{rk:simple_functions_generalize_step_functions}.   So  $a = x_0 < x_1 < ... < x_n = b$ is a partition of $\Omega := \text{dom}(h)$, and $h$ takes on values $y_i$ on $(x_{i-1},x_i)$ for $i=1,...,n$.  Then 
\begin{align*}
\ds\int_{\Omega} h \wrt{\mu} &= \ds\sum_{i=1}^n y_i \; \mu(x_{i-1},x_i) + \ds\sum_{i=1}^n f(x_i) \mu\set{x_i} \\
& \stackreltext{(if $\mu$ is Lebesgue measure)}{=} \; \ds\sum_{i=1}^n y_i \; (x_i - x_{i-1}) + \cancelto{0}{\ds\sum_{i=1}^n f(x_i) \mu\set{x_i}}
\end{align*}

So the Lebesgue integral of the step function agrees with the Riemann integral when $\mu$ is Lebesgue measure (although not for general measure).
\end{example}

Now we integrate a simple function that is not a step function -- in fact, a simple function for which there is not a Riemann integral. 

\begin{example}{\remarktitle{Integrating the Dirichlet function}}
Let $h$ be the Dirichlet function; that is $h = I_{\Q} : \R \to \R$ is the indicator of the rationals.  Let us integrate $h$ against Lebesgue measure $\mu$. 
\begin{align*}
\ds\int_{\Omega} h \wrt{\mu} &= 1 \; \mu(\Q) + 0 \; \mu(\R - \Q) && \tinytext{def. integral of simple function} \\
 &= 1 \; \mu(\Q) && \tinytext{arithmetic of $\overline{\R}$: \; $0 \cdot x = 0$ for $x \in \overline{\R}$} \\
 	&= 1 \; \mu(\bigcupdot_{q \in \Q} \set{q}) && \tinytext{rewrite $\Q$} \\
&= 1 \; \ds\sum_{q \in \Q} \mu(\set{q}) && \tinytext{countable additivity, $\Q$ is countable} \\
& \stackrel{1}{=} 1 \ds\sum_{q \in \Q} 0 && \tinytext{Proposition \ref{prop:properties_of_LS_measures}} \\
&= 0.  
\end{align*}
Note Equation 1 holds for any Lebesgue-Stieljes measure with a continuous distribution function (see Remark \ref{rk:continuity_at_a_point_iffi_measure_zero_at_a_point}).  However, other measures may yield other results.
\label{ex:integrating_the_dirichlet_function}
\end{example}

Now we show that the Dirichlet function does not have a Riemann integral. 

\begin{remark}{\remarktitle{The Dirichlet function does not have a Riemann integral.}}	
Let $h$ be the Dirichlet function; that is $h = I_{\Q} : \R \to \R$ is the indicator of the rationals.  Fix $[a,b] \subset \R$, and let $f=h |_{[a,b]}$; that is $f : [a,b] \to \R$ is the Dirichlet function restricted to $[a,b]$.  

We consider an arbitrary \textit{partition} $P$ of $[a,b]$ into a collection of $n$ subintervals via a finite sequence $P=\set{x_i}_{i=0}^n$ such that $a=x_0 < x_1 < ... < x_n = b$.  Now by Proposition \ref{prop:Riemann_integrable_iff_oscillation_goes_to_zero_as_partition_gets_finer}, a function on $[a,b]$ is Riemann integrable iff $\text{Osc}(f,P) \to 0$ as the maximum interval length of a partition $P$ goes to 0.\footnote{For a refresher on how these terms are defined, see Section \ref{sec:some_info_relevant_to_Riemann_integrals}.}  But for any partition $P$, any subinterval $(x_{k-1}, x_k)$ will contain at least one rational number and at least one irrational number, and so
\begin{align*}
S^+(f,P) &= \ds\sum_{k=1}^n 1 \cdot (x_k - x_{k-1}) = b-a \\	
S^-(f,P) &= \ds\sum_{k=1}^n 0 \cdot (x_k - x_{k-1}) = 0\\
\end{align*}
Thus $\text{Osc}(f,P) = b-a$ for all partitions $P$. In particular $\text{Osc}(f,P) \not\to 0$ 	as the maximum interval length of a partition $P$ goes to 0.\footnote{To be more explicit, the condition of Proposition \ref{prop:Riemann_integrable_iff_oscillation_goes_to_zero_as_partition_gets_finer} is that $\forall \epsilon > 0, \;\exists \delta >0  : \forall P  \text{ where the maximum interval length of } P < \delta, \; \text{Osc}(f,P) < \epsilon$. But since $\text{Osc}(f,P) = b-a$ for all partitions $P$, the condition is contradicted: $\exists \epsilon = \frac{b-a}{2} >0 : \forall P, \text{Osc}(f,P) > \epsilon.$}  Thus $f$ is not Riemann integrable. 

The Riemann integral of $h: \R \to \R$ would be an improper integral defined as the limiting value of the Riemann integrals $h|_{[a,b]}$ as $a \to -\infty, b \to \infty$.  But since the proper Riemann integrals for $h|_{[a,b]}$ don't exist, neither does the improper Riemann integral for $h$. 
\label{rk:dirichlet_function_is_not_Riemann_integrable}
\end{remark}

%Recall that a proper Riemann integral $\int_{a}^b f(x) \, dx$, when it exists,  is defined only for real-valued functions  $f$ whose domain is a compact space $[a,b] \subset \R$.  Recall also that an improper Riemann integral is  defined for functions $h: \R \to \R$ as the limiting value of proper Riemann integrals.  

% Commenting this out because we haven't defined almost everywhere yet.

%\begin{remark}{\remarktitle{The Dirichlet function does not have a Riemann integral}} A function on $[a,b]$ is Riemann integrable if and only if it is bounded and continuous almost everywhere.  However, the Dirichlet function $f$ is continuous nowhere.  For every irrational number $x$, there is a sequence of rational numbers $\{r_n\}$ that converges to it. We have:
%$$
%\lim_{n\to\infty} f(r_n) = 1 \ne 0 = f(x)
%$$
%
%Thus, $f$ isn't continuous at irrational numbers. Rational numbers can be handled similarly.
%	
%\label{rk:dirichlet_function_has_no_Riemann_integral}
%\end{remark}
%\end{document}
%
%Example \ref{ex:integrating_the_dirichlet_function} shows how Lebesgue integration can handle functions not handled by Riemann integration.  As noted in Remark \ref{rk:{rk:dirichlet_function_has_no_Riemann_integral}, a function on $[a,b]$ is Riemann integrable if and only if it is bounded and continuous almost everywhere.  Lebesgue integration can handle functions that do not meet these criteria.

\paragraphnewline{Properties of integrals of simple functions} 

In this section, for now, we only provide properties that come up in our exposition.  For other useful properties, see Proposition 2.13 of \cite{folland1999real}.


\begin{proposition} 
Let $g$ and $h$  be simple functions.  Then 
\begin{alphabate}
\item (monotonicity) If $g \leq h$ then $\ds\int g \wrt{\mu} \leq \ds\int h \wrt{\mu}$.
\item (addivity) $\ds\int (g + h) \wrt{\mu} = \ds\int g \wrt{\mu} + \ds\int h \wrt{\mu}$ .
\item (scalar multiple property) $\ds\int c \, g \wrt{\mu} = c \ds\int g \wrt{\mu}$.
\end{alphabate}
\label{prop:properties_of_integrals_of_simple_functions}
\end{proposition}

\begin{proof}


\begin{alphabate}
\item By definition of simple functions, we write \[g = \ds\sum_{i=1}^r x_i I_{A_i} ,\quad \quad h = \ds\sum_{j=1}^s y_j I_{B_j}  \]	
But if we use a common (finer) partition of $\Omega$ into sets $\set{A_i \cap B_j}$, we can write
\begin{align*}
g = \ds\sum_{i=1}^r \ds\sum_{j=1}^s x_i I_{A_i \cap B_j} ,\quad \quad h = \ds\sum_{i=1}^r \ds\sum_{j=1}^s y_j I_{A_i \cap B_j}  
\labelit \label{eqn:two_simple_functions_with_common_partition}
\end{align*}

where by assumption, $x_i \leq y_j$ on each $A_i \cap B_j$.	
	
So 
\begin{align*}
\ds\int g \wrt{\mu}  = \ds\sum_{i=1}^r \ds\sum_{j=1}^s x_i \, \mu(A_i \cap B_j)  \leq \ds\sum_{i=1}^r \ds\sum_{j=1}^s y_i \, \mu(A_i \cap B_j) = \ds\int h \wrt{\mu}.
\end{align*}

\item We sum the two forms in \eqref{eqn:two_simple_functions_with_common_partition} and apply the definition of integral of simple functions to obtain
\begin{align*}
\ds\int (g+h) \wrt{\mu} = \ds\sum_{i=1}^r \ds\sum_{j=1}^s (x_i + y_j) \, \mu(A_i \cap B_j)
\labelit \label{eqn:intermediate_result_addivity_of_simple_functions}
\end{align*}

But since we have 
\[A_i =\bigcupdot_j (A_i \cap B_j), \quad  B_j =\bigcupdot_i (A_i \cap B_j)\]
Then by finite additivity
\[\mu(A_i) =\sum_{j=1}^s \mu(A_i \cap B_j), \quad  \mu(B_j) =\sum_{i=1}^r \mu(A_i \cap B_j)\]
And so
\begin{align*}
\ds\int g \wrt{\mu} &= \ds\sum_{i=1}^r x_i \mu(A_i) = \ds\sum_{i=1}^r x_i \bigg(\sum_{j=1}^s \mu(A_i \cap B_j)\bigg) \\	
\ds\int h \wrt{\mu} &= \ds\sum_{j=1}^s y_i \mu(B_i) = \ds\sum_{j=1}^s y_i \bigg(\sum_{i=1}^r \mu(A_i \cap B_j)\bigg) \\	
\end{align*}
and summing these together yields \eqref{eqn:intermediate_result_addivity_of_simple_functions}.
\item This follows immediately from the distributive property.
\[ c \ds\int g \wrt{\mu} = c \ds\sum_{i=1}^r x_i \mu(A_i) =  \ds\sum_{i=1}^r c \, x_i \mu(A_i) = \ds\int cg \wrt{\mu} \]
\end{alphabate}

\end{proof}

\begin{proposition}
Let $s$ be a non-negative simple function. Then 
\[ A \mapsto \ds\int_A s \wrt{\mu} \]
is a measure on $\F$.
\label{prop:the_integral_of_a_simple_function_over_a_set_is_one_way_to_measure_that_set} 
\end{proposition}

\begin{proof}
We show  countable additivity.\footnote{Non-negativity is clear from the definition.  See Remark \ref{rk:integrating_simple_functions_over_arbitrary_measurable_subsets}.}  Let $A = \bigcupdot_{i=1}^\infty A_i$.  Then

\begin{align*}
\ds\int_A s \wrt{\mu} &= \ds\sum_{j=1}^n y_j \, \mu(B_j \cap A) && \tinytext{Remark \ref{rk:integrating_simple_functions_over_arbitrary_measurable_subsets}} \\
&= \ds\sum_{j=1}^n \ds\sum_{i=1}^\infty y_i \, \mu(B_j \cap A_i) && \tinytext{countable additivity} \\
&= \ds\sum_{i=1}^\infty  \ds\sum_{j=1}^n y_i \, \mu(B_j \cap A_i) && \tinytext{sum of limit is limit of sum} \\
&= \ds\sum_{i=1}^\infty \ds\int_{A_i} s \wrt{\mu}
\end{align*}
\end{proof}

\begin{remark}
Proposition \ref{prop:the_integral_of_a_simple_function_over_a_set_is_one_way_to_measure_that_set} says that we can measure a set by integrating a simple function over it.  Given some initial measure for $A$, we can get a new measure by breaking $A$ into finitely many (measurable) pieces and giving different weights to the measures of the different pieces.

\begin{figure}[H]
\centering
\includegraphics[width=.5\textwidth]{images/integrals_of_simple_functions_induce_new_measures}
\end{figure}
\end{remark}

\begin{remark}{\remarktitle{Continuity of measure applied to measures given by integrals of simple functions over sets}}
Recall (Theorem \ref{thm:continuity_of_countably_additive_set_functions}) that measure satisfies continuity from below: if $A_n$ are measurable and $A_n \uparrow A$, then $\lim_{n \to \infty} \mu(A_n) = \mu(A)$.    Combining this with Proposition \ref{prop:the_integral_of_a_simple_function_over_a_set_is_one_way_to_measure_that_set}, we have that if $A_n$ are measurable and $A_n \uparrow A$,
\[ \ds\lim_{n \to \infty} \ds\int_{A_n} s \wrt{\mu} =  \ds\int_A s \wrt{\mu} \]
for any simple function $s$.  
\label{rk:continuity_of_measure_applied_to_measures_given_by_integrals_of_simple_functions_over_sets}
\end{remark}



\subsubsection{Integrals of non-negative Borel measurable functions}

\paragraph{Definition of integral of non-negative Borel measurable functions}

\begin{definition}
If $h$ is non-negative Borel measurable, we define 

\begin{align*}
\ds\int_{\Omega} h \wrt{\mu} = \sup \bigg\{ \ds\int_{\Omega} s \wrt{\mu} : s \quad \text{simple,} \quad 0 \leq s \leq h  \bigg\} 
\labelit \label{eqn:def_integral_of_non_negative_Borel_measurable_function}
\end{align*}
\label{def:integral_of_non_negative_Borel_measurable_function}
\end{definition}

When $h$ is simple, this definition agrees with the definition of the integral for simple functions (Definition \ref{def:integral_of_simple_function}). This follows from Proposition \ref{prop:properties_of_integrals_of_simple_functions} (a) and the fact that the family of functions over which the supremum is taken includes $h$ itself.\footnote{Let us show in more detail that when $h$ is simple, the definition of the integral for non-negative Borel measurable functions (Definition \ref{def:integral_of_non_negative_Borel_measurable_function}) agrees with the definition of the integral for simple functions (Definition \ref{def:integral_of_simple_function}).  Let $h$ be simple and take $\int_{\Omega} h \wrt{\mu}$ to be given by Definition \ref{def:integral_of_simple_function}. Then by Proposition \ref{prop:properties_of_integrals_of_simple_functions} (a), $\int_{\Omega} h \wrt{\mu}$ must be an upper bound for  $A$, which we define as the set of integrals on the RHS of  Definition \ref{def:integral_of_non_negative_Borel_measurable_function}.  Moreover, it is the least upper bound by Remark \ref{rk:when_upper_or_lower_bound_is_contained_in_the_set_itself}, since for every $M' < M:= \int_{\Omega} h \wrt{\mu}$ there is an $a \in A$ such that $a>M'$, namely $a=\int_{\Omega} h \wrt{\mu}$.} 

\begin{figure}[H]
\centering
\includegraphics[width=.4\textwidth]{images/simple_function_approximating_non_negative_function}	
\caption{A simple function approximating a non-negative function in terms of its integral}
\end{figure}

\begin{remark}{\remarktitle{When does the integral of a non-negative Borel measurable function exist?}}
The integral of a non-negative Borel measurable function \textit{always} exists (although it may take on the value $+\infty$).  Note that neither case discussed in Remark \ref{rk:when_does_integral_of_simple_function_exist} apply, since the supremum is simply taken over the set of simple functions that never take on negative values. 
\label{rk:when_does_integral_of_non_negative_Borel_measurable_function_exist}
\end{remark}


\paragraphnewline{Properties of integral of non-negative Borel measurable functions (Part I)}

We will use these basic properties below:
\begin{proposition}
Let $f,g$ be non-negative Borel measurable functions. Then
\begin{alphabate}
\item (monotonicity) $\ds\int f \leq \ds\int g \text{ whenever } f \leq g$
\item (non-negative constant multiples) $\ds\int cf = c \ds\int f \text{ for all } c \geq 0.$	
\end{alphabate}
\label{prop:properties_of_integrals_of_non_negative_borel_measurable_functions}
\end{proposition}

\begin{proof}
\begin{alphabate}
\item 
\begin{align*}
f \leq g & \implies \set{s : s \text{ simple } , 0 \leq s \leq f} \subset \set{s:  s \text{ simple } , 0 \leq s \leq g} \\
& \implies 	\set{ \ds\int s \wrt{\mu}  :   s \text{ simple } , 0 \leq s \leq f} \subset \set{ \ds\int s \wrt{\mu} :  s \text{ simple } , 0 \leq s \leq g} \\
& \stackrel{Prop. \ref{prop:sup_and_inf_for_subsets_are_tighter}}{\implies} \sup \set{ \ds\int s \wrt{\mu}  :  s \text{ simple } , 0 \leq s \leq f} \leq  \sup \set{ \ds\int s \wrt{\mu} :   s \text{ simple } , 0 \leq s \leq g} \\
& \implies \ds\int f \wrt{\mu} \leq \ds\int g \wrt{\mu} 
\end{align*}
\item 
\begin{align*}
\ds\int c f \wrt{\mu} &= \sup \set{\ds\int s' \wrt{\mu} : s' \text{ simple } , 0 \leq s' \leq cf} \\
&=  \sup  \set{\ds\int cs \wrt{\mu}   : s\text{ simple } , 0 \leq s \leq f} && \tinytext{Let $s' = cs$} \\
&= \sup  \set{c \ds\int s \wrt{\mu}   : s\text{ simple } , 0 \leq s \leq f} && \tinytext{Linearity of integral of simple functions} \\
&= c \set{ \ds\int s \wrt{\mu}   : s\text{ simple } , 0 \leq s \leq f} && \tinytext{Prop. \ref{prop:supremum_and_infimum_under_constant_multiples_of_sets}}\\
&= c \ds\int f \wrt{\mu} 
\end{align*}
% By Proposition \ref{prop:borel_measurability_closed_under_multiplication_and_addition} and Example \ref{ex:constant_functions_are_borel_measurable},  $cf$ is a measurable function. Now 
\end{alphabate}

\end{proof}

\paragraphnewline{Computing the integral of non-negative Borel measurable functions}

The following proposition may provide additional confidence in Definition \ref{def:integral_of_non_negative_Borel_measurable_function}, since simple functions approximate non-negative Borel measurable functions.

\begin{proposition}
Let $h$ be a non-negative Borel measurable function.  Then there is a sequence $\set{s_n}$ of simple functions such that $0 \leq s_1 \leq s_2 \leq ... \leq h$, $s_n \to h$ pointwise, and $s_n \to h$ uniformly on any set on which $h$ is bounded.	
\label{prop:there_is_a_sequence_of_simple_fucntions_that_increases_to_any_non_negative_borel_measurable_function}
\end{proposition}

\begin{proof}
Define 
\[ s_n(\omega) = 
\begin{cases}
\df{k-1}{2^n}, & \text{ if } \quad \df{k-1}{2^n} \leq h(\omega) \leq \df{k}{2^n},\quad k=1,2,...,n2^n \\
n, & \text{ if } \quad h(\omega) \geq n 
\end{cases}
\]	

\begin{figure}[H]
\centering
\includegraphics[width=.7\textwidth]{images/approximate_nonnegative_with_simple}	
\caption{An element of an increasing sequence of simple functions approximating an arbitrary non-negative Borel measurable function. The $n$th function in the sequence has a maximum value of $n$ and divides the range into bins of size $2^{-n}$.}
\end{figure}


Then 
\begin{itemize}
\item $s_n \leq s_{n+1}$ for all $n$
\item $0 \leq h - s_n \leq 2^{-n}$ on the set where $h \leq n$.
\end{itemize}


\end{proof}

\begin{question}
When working with $\overline{\R}$, how does one check convergence of a function at a point $\omega$ such that $h(\omega)=\infty$?  Does the proof of Proposition \ref{prop:there_is_a_sequence_of_simple_fucntions_that_increases_to_any_non_negative_borel_measurable_function} still work at such points?
\end{question}

Now we establish one of the fundamental convergence theorems. 

\begin{theorem}{\textbf{The Monotone convergence theorem.}}
If $\set{h_n}$ is a sequence of non-negative Borel measurable functions such that $h_n \leq h_{n+1}$ for all $n$ and $h =\lim_{n \to \infty} h_n (= \sup_n h_n)$, then 
\begin{align*}
\ds \int h_n \wrt{\mu} \uparrow \ds\int h \wrt{\mu}
\labelit \label{eqn:monotone_convergence_theorem_conclusion}	
\end{align*}
\label{thm:monotone_convergence_theorem}
\end{theorem}

\begin{proof}

We break the proof into four parts.  Consider
\begin{align*}
\ds \int h \wrt{\mu} = \lim_{n \to \infty} \ds\int h_n \wrt{\mu}
\labelit \label{eqn:monotone_convergence_theorem_pre_conclusion}	
\end{align*}

\begin{itemize}
\item We first show that both quantities in \eqref{eqn:monotone_convergence_theorem_pre_conclusion} exist. First, recall from Remark \ref{rk:when_does_integral_of_non_negative_Borel_measurable_function_exist} that the integral of a non-negative Borel measurable function always exists. So the LHS exists because $h$ is Borel measurable (by Proposition \ref{prop:borel_measurability_closed_under_inf_sup_liminf_limsup}) and non-negative.  The RHS exists since each $\int h_n$ exists and is increasing (by monotonicity; see Prop. \ref{prop:properties_of_integrals_of_non_negative_borel_measurable_functions}), and therefore has a limit (possibly $\infty$). 

\item Next, we show $\geq$ for \eqref{eqn:monotone_convergence_theorem_pre_conclusion}; that is we show $\lim_{n \to \infty} \int h_n \leq \int h$.
\[ h_n \leq h \stackreltext{monotonicity}{\implies} \ds\int h_n \leq \ds\int h \stackreltext{limits preserve (non-strict) inequalities}{\implies} \ds\lim_{n \to \infty} \ds\int h_n \leq \ds\int h \]

\item Now, we show $\leq$ for \eqref{eqn:monotone_convergence_theorem_pre_conclusion}; that is we show $\lim_{n \to \infty} \int h_n \geq \int h$.   Let $\alpha \in (0,1)$ and $s$ be a simple function such that $0 \leq s \leq h$.  Now define 
\[ A_n := \set{\omega : h_n(\omega) \geq \alpha s(\omega) }\]
And note that $A_n \uparrow \Omega$.

So
\begin{align*}
 \ds\int h_n  \stackreltext{monotonicity}{\geq} \ds\int_{A_n} h_n \stackreltext{def. $A_n$, monotonicity}{\geq} \ds\int_{A_n} \alpha s \stackreltext{linearity}{=} \alpha   \ds\int_{A_n} s 
 \labelit \label{eqn:intermediate_eqn_from_proof_mct} 
 \end{align*}
   Now we recognize the right hand side as a measure on $A_n$, and since $A_n \uparrow \Omega$, we can apply continuity from below (see Remark \ref{rk:continuity_of_measure_applied_to_measures_given_by_integrals_of_simple_functions_over_sets}), so taking the limit as $n \to \infty$, Equation \eqref{eqn:intermediate_eqn_from_proof_mct} becomes
\[  \ds\lim_{n \to \infty} \ds\int h_n  \geq \alpha \ds\int s \]
Now since the equality holds for all $\alpha <1$, it holds for $\alpha =1$, and so we have
\[   \ds\lim_{n \to \infty}  \ds\int h_n  \geq \ds\int s \]
Since the LHS is an upper bound on the set in the RHS, it must be greater than the least upper bound, so 
\[   \ds\lim_{n \to \infty}  \ds\int h_n  \geq \ds\int h \]
\item Now we know that \eqref{eqn:monotone_convergence_theorem_pre_conclusion} holds.  It just remains to show that \eqref{eqn:monotone_convergence_theorem_pre_conclusion} $\implies$ \eqref{eqn:monotone_convergence_theorem_conclusion}.  By monotonicity, $\int h_{n+1} \wrt{\mu}  \geq \int h_{n} \wrt{\mu}$ for all $n$, and since the limit of an increasing sequence is its supremum (Prop. \ref{prop:limit_of_monotone_sequences}), $\int h \wrt{\mu}  \geq \int h_{n} \wrt{\mu}$ for all $n$.
\end{itemize}
\end{proof}


\begin{remark}{\remarktitle{The monotone convergence theorem aids in computation.}}
The monotone convergence theorem can actually be used to make it easier to do computations with integrals of non-negative Borel measurable functions!  Let us quote \cite{folland1999real} (except with changes of notation and references)

\begin{quotation}
 The definition of $\int h$  involves the supremum over a huge (usually uncountable) family of simple functions, so it may be difficult to evaluate $\int h$ directly from the definition (see Definition \ref{def:integral_of_non_negative_Borel_measurable_function}).  The monotone convergence theorem, however, assures us that to compute $\int h$, it is enough to compute $\lim \int s_n$, where $\set{s_n}$ is any sequence of simple functions that increase to $h$, and Proposition \ref{prop:there_is_a_sequence_of_simple_fucntions_that_increases_to_any_non_negative_borel_measurable_function} guarantees that such sequences exist. 
\end{quotation}
\end{remark}

\begin{remark}{\remarktitle{Monotone convergence theorem fails for the Riemann integral.}}
Using an enumeration of the rational numbers between 0 and 1, we define the function $f_n$ (for all nonnegative integer $n$) as the indicator function of the set of the first $n$ terms of this sequence of rational numbers. The increasing sequence of functions $f_n$ (which are nonnegative, Riemann-integrable with a vanishing integral) pointwise converges to the Dirichlet function which is not Riemann-integrable (see Remark \ref{rk:dirichlet_function_is_not_Riemann_integrable}).
\end{remark}

\paragraphnewline{Properties of integral of non-negative Borel measurable functions (Part II)}

With the monotone convergence theorem in hand, we can now provide some additional properties of the integrals of non-negative Borel measurable functions.

\begin{proposition}
Let $f, g$ be non-negative Borel measurable functions. Then
\[ \ds\int f + \ds\int g = \ds\int f+g \]
\label{prop:additivity_of_integral_for_non_negative_Borel_measurable_functions}	
\end{proposition}

\begin{proof}
By Proposition \ref{prop:there_is_a_sequence_of_simple_fucntions_that_increases_to_any_non_negative_borel_measurable_function}, there are sequences of simple functions $\set{s_n}, \set{t_n}$ such that $s_n \uparrow f$ and $t_n \uparrow g$.   Thus, by limit properties, $(s_n + t_n) \uparrow (f+g)$.  So we have
\begin{align*}
	\ds\int f + \ds\int g &=\ds\lim_{n \to \infty} \ds\int s_n + \ds\lim_{n \to \infty} \ds\int t_n && \tinytext{Monotone convergence theorem} \\
	&= \ds\lim_{n \to \infty} ( \ds\int s_n +  \ds\int t_n ) \\
	&=  \ds\lim_{n \to \infty} \ds\int (s_n + t_n)  && \tinytext{Linearity of integral for simple functions}\\
	&= \ds\int (f+g)  && \tinytext{Monotone convergence theorem}
 \end{align*}
\end{proof}

Below we show that Proposition \ref{prop:additivity_of_integral_for_non_negative_Borel_measurable_functions} actually extends to linearity with countably infinite sums. 


\begin{corollary}{\remarktitle{Linearity with countably infinite sums of non-negative measurable functions}}
If $\set{f_n}$ is a sequence of non-negative measurable functions,  and 
\[ f(\omega) = \ds\sum_{n=1}^\infty f_n(\omega), \quad \quad \text{ for all } \omega \in \Omega  \]
Then 
\begin{align*}
 \dint_\Omega f \dmu = \ds\sum_{n=1}^\infty \ds\int_\Omega f_n \dmu 
\labelit \label{eqn:consequence_of_linearity_with_countably_infinite_sums_of_non_negative_measurable_functions}	
\end{align*}
Thus, any series of non-negative Borel measurable functions may be integrated term by term.

% Below is Ash's formulation of the statement.  I've replaced it with Rudin's, as I trust Rudin more :)
% 
%If $h_1, h_2, ...$ are non-negative Borel measurable, 
%\[ \ds\int_\Omega \bigg(  \ds\sum_{n=1}^\infty h_n \bigg) \dmu  = \ds\sum_{n=1}^\infty \ds\int_\Omega h_n \dmu\]
\label{cor:linearity_with_countable_infinite_sums_of_non_negative_functions}
\end{corollary}

\begin{proof}
By induction, the linearity of Proposition \ref{prop:additivity_of_integral_for_non_negative_Borel_measurable_functions} extends to a finite collection $\set{f_n}_{n=1}^N$. Now $\ds\sum_{n=1}^N f_n \uparrow \ds\sum_{n=1}^\infty f_n$, so we apply Monotone Convergence Theorem (MCT)
\[ \explaintermbrace{ $\stackexplain{(additivity)}{=} \dsum_{n=1}^\infty \dint f_n \dmu$}{\dlim_{N \to \infty} \dint \dsum_{n=1}^N f_n \dmu} \stackexplain{(MCT)}{=} \dint \dsum_{n=1}^\infty f_n \dmu \]
\end{proof}

\begin{remark}
If we let $\mu$ be the counting measure on a countable set, the statement of  Corollary \ref{cor:linearity_with_countable_infinite_sums_of_non_negative_functions} becomes a statement about double series of non-negative real numbers (which can be proved by more elementary means) \cite{rudin1987real}:

That is, if $a_{ij} \geq 0$ for $i$ and $j = 1, 2, 3, ...$, then 
\[ \ds\sum_{i=1}^\infty \ds\sum_{j=1}^\infty  a_{ij} = \ds\sum_{j=1}^\infty \ds\sum_{i=1}^\infty  a_{ij} \]

{\tiny More explicitly, on $\Omega =\set{1,2,3,...}$, we define sequence $\set{f_i}$ such that $f_i(j) = a_{ij}$.  Then we define $f = \sum_{i=1}^\infty f_i$, so $f(j) = \sum_{i=1}^\infty f_i(j) = \sum_{i=1}^\infty a_{ij}$.

Then, since $\mu$ is the counting measure, the LHS of  \eqref{eqn:consequence_of_linearity_with_countably_infinite_sums_of_non_negative_measurable_functions} becomes 
\[  \dint_\Omega f(j) \dmu(j) = \dsum_{j=1}^\infty f(j) = \ds\sum_{j=1}^\infty \ds\sum_{i=1}^\infty a_{ij}\]	
and the RHS of \eqref{eqn:consequence_of_linearity_with_countably_infinite_sums_of_non_negative_measurable_functions} is 
\[ \ds\sum_{i=1}^\infty \ds\int_\Omega f_i \dmu = \ds\sum_{i=1}^\infty \ds\sum_{j=1}^\infty a_{ij}. \]
}

\end{remark}



%{rk:continuity_of_measure_applied_to_measures_given_by_integrals_of_simple_functions_over_sets}

\subsubsection{Integrals of arbitrary Borel measurable functions}

Let $h$ be an arbitrary Borel measurable function.   We will express an arbitrary Borel measurable function as as the difference of two non-negative Borel measurable functions.

Define:
\begin{align*}
h^+ &:= \max (h,0) \\
h^- &:= \max (-h,0) \\	
\end{align*}
Then 
\begin{align*}
h &= h^+ - h^- \\
|h| &= h^+ + h^- \\	
\end{align*}

\begin{figure}[H]
\centering
\includegraphics[width=.7\textwidth]{images/arbitrary_borel_measurable_functions_in_terms_of_nonnegative_borel_measurable_functions}
\end{figure}

Now both $h^+$ and $h^-$ are Borel measurable as well.  This holds because if $h_1, h_2$ are Borel measurable, then so are $\max(h_1,h_2)$ and $\min(h_1,h_2)$:

\begin{align*}
\bigg\{ \omega : \max \bigg( h_1(\omega), h_2(\omega) \bigg) < c  \bigg\} &=	\set{\omega :  h_1(\omega) < c } \cap \set{\omega : h_2(\omega) < c } \\
\bigg\{ \omega : \min \bigg( h_1(\omega), h_2(\omega) \bigg)  < c \bigg\} &=	\set{\omega :  h_1(\omega) < c } \cup \set{\omega : h_2(\omega) < c }
\end{align*}


which is sufficient to show measurability by the ``computational definition of measurability" (see Remark \ref{rk:computational_definition_of_Borel_measurability}). 

So we have expressed an arbitrary Borel measurable function as as the difference of two non-negative Borel measurable functions. Therefore, we can define its integral as follows.  

\begin{definition}{\remarktitle{Integral of an arbitrary Borel measurable function}}
\begin{align} 
 \ds\int_\Omega h \wrt{\mu} = \ds\int_\Omega h^+ \wrt{\mu} - \ds\int_\Omega h^- \wrt{\mu} 
\label{eqn:definition_of_integral_of_arbitrary_borel_measurable_function}
\end{align}
\label{def:integral_of_arbitrary_borel_measurable_function}
\end{definition}




\begin{remark}{\remarktitle{When does the integral of an arbitary Borel measurable function exist?}}
Recall from Remark \ref{rk:when_does_integral_of_non_negative_Borel_measurable_function_exist} that the integral of a non-negative Borel measurable function \textit{always} exists (although it may take on the value $+\infty$).  Thus, the integral of an arbitrary non-negative Borel function exists so long as it does not take the form $+\infty - \infty$. 
\label{rk:when_does_integral_of_arbitary_Borel_measurable_function_exist}
\end{remark}

\begin{remark}{\remarktitle{Integrable}}
We say that a function $h$ is $\mu$-integrable (or just integrable if $\mu$ is understood) if $
\ds\int_\Omega h \wrt{\mu}$ is finite, that is, iff $
\ds\int_\Omega h^+ \wrt{\mu}$ and $
\ds\int_\Omega h^- \wrt{\mu}$ are both finite.   %We can express this condition as 
%\[ \bigg| \dint h \dmu \bigg| \stackrel{def. integral}{=} \bigg| \dint h^+ \dmu - \dint h^- \dmu \bigg| < \infty \]
\label{rk:integrable}
\end{remark}

\begin{remark}{\remarktitle{Integrals on subsets}}
For $A \in \F$, we define 
\[ \ds\int_A h \wrt{\mu} = \ds\int_\Omega  h I_A \wrt{\mu} \]
This definition works because whenever $h$ is measurable, then so is $h I_A$:
\[\set{ \omega : h I_A (\omega) < c } =	\explaintermbrace{$\in \F$ since $h$ measurable}{\set{\omega :  h(\omega) < c }} \cap \explaintermbrace{$\in \F$ by assumption}{\set{\omega : \omega \in A }} \\  \]
\end{remark}

\paragraphnewline{Properties of the integral of arbitrary Borel measurable functions}

\begin{proposition}
Let $f,g,h$ arbitrary Borel measurable functions. Then
\begin{alphabate}
\item \label{item:scalar_multiple}  (scalar multiple) If $\int f \wrt{\mu}$ exists and $c \in \R$, then $\int cf$ exists and $\int cf \wrt{\mu} = c \int f \wrt{\mu} $. %$\ds\int cf \wrt{\mu} = c \ds\int f \wrt{\mu} \text{ for all } c \in \R.$ \quad {\tiny (More explicitly, if $\int f \wrt{\mu}$ exists and $c \in \R$, then $\int cf$ exists and $\int cf \wrt{\mu} = c \int f \wrt{\mu} $.)}
\item \label{item:monotonicity} (monotonicity)  If $g \geq h$ and both integrals exist, then $\ds\int g \wrt{\mu} \geq  \ds\int h \wrt{\mu}$. Moreover, if  $g \geq h$,  $\ds\int h \wrt{\mu}$ exists and $\ds\int h \wrt{\mu} > -\infty$, then $\ds\int g \wrt{\mu}$ exists.  And if  $g \geq h$, $\ds\int g \wrt{\mu}$ exists and $\ds\int g \wrt{\mu} < \infty$, then $\ds\int h \wrt{\mu}$ exists.\footnote{We might consider this as a ``dominance criterion for existence."  For more on why the monotonicity statement is concerned with existence, see Remark \ref{rk:why_does_existence_matter_for_monotonicity}.} 
\item \label{item:delayed_truncation_of_simple_functions} (delayed truncation of simple functions) If $h \geq 0$ and $B \in \F$, then\footnote{For why this needs to be proven, see Remark \ref{rk:why_delayed_truncation_of_simple_functions_is_something_that_needs_to_be_proven}.} 
\[ \ds\int_B h \wrt{\mu} = \sup \biggset{ \ds\int_B s \wrt{\mu} : \; 0 \leq s \leq h, \; s \text{ simple }} \]
\item \label{item:existence_transfers_to_subsets}(existence of integral transfers to subsets) 
\begin{align}
\ds\int_{\Omega} h \wrt{\mu} \text{ exists } &\implies 	\ds\int_{A} h \wrt{\mu} \text{ exists} \quad \forall A \in \F \\
\ds\int_{\Omega} h \wrt{\mu} \text{ finite } &\implies 	\ds\int_{A} h \wrt{\mu} \text{ finite} \quad \forall A \in \F
\end{align}

\end{alphabate}
\label{prop:properties_of_integrals_of_arbitrary_borel_measurable_functions}
\end{proposition}

\begin{proof}
\begin{alphabate}
\item Since $cf$ is a Borel measurable function\footnote{The function $cf$ is a Borel measurable fucntion by Proposition \ref{prop:borel_measurability_closed_under_multiplication_and_addition} and Example \ref{ex:constant_functions_are_borel_measurable}.  Alternatively, we could verify this directly.  If $c \geq 0$, then $\set{\omega : c f(\omega) \leq k} = \set{\omega : f(\omega) \leq k/c} \in \F$ by the Borel measurability of $f$.  Similarly if  $c < 0$, then $\set{\omega : c f(\omega) \leq k} = \set{\omega : f(\omega) \geq k/c} \in \F$ by the Borel measurability of $f$.}, we apply Definition \ref{def:integral_of_arbitrary_borel_measurable_function}.

We have 
\begin{subequations}
\begin{align}
\text{if $c \geq 0$}, && (cf)^+ &= cf^+  & (cf)^- &= cf^-   \label{eqn:decomposing_scalar_multiple_of_borel_measurable_function_into_two_nonnegative_functions_when_scalar_multiple_is_nonnegative} \\
\text{if $c < 0$}, && (cf)^+ &= -cf^-  & (cf)^- &= -cf^+. \label{eqn:decomposing_scalar_multiple_of_borel_measurable_function_into_two_nonnegative_functions_when_scalar_multiple_is_negative} 
\end{align}
\end{subequations}

\begin{figure}[H]
\centering
\includegraphics[width=.5\textwidth, angle=90]{images/decomposing_scalar_multiple_of_borel_measurable_function_into_two_nonnegative_functions_when_scalar_multiple_is_negative}	
\end{figure}


Now we will use the fact that if $f$ is non-negative Borel measurable and $c \geq 0$, then we already know the identity holds (see Prop. \ref{prop:properties_of_integrals_of_non_negative_borel_measurable_functions} (b)).


So if $c\geq 0$
\begin{align*}
\ds\int cf \wrt{\mu} &= \ds\int (cf)^+ \wrt{\mu} - \ds\int (cf)^- \wrt{\mu} && \tinytext{Def. \ref{def:integral_of_arbitrary_borel_measurable_function}} \\
&= \ds\int cf^+ \wrt{\mu} - \ds\int cf^- \wrt{\mu} && \tinytext{\eqref{eqn:decomposing_scalar_multiple_of_borel_measurable_function_into_two_nonnegative_functions_when_scalar_multiple_is_nonnegative}} \\ 
& \stackrel{*}{=} c \ds\int f^+ \wrt{\mu} - c \ds\int f^- \wrt{\mu} && \tinytext{ Prop. \ref{prop:properties_of_integrals_of_non_negative_borel_measurable_functions} (b)} \\ %\labelit \label{eqn:expanding_integral_of_nonnegative_scalar_times_function} \\
& = c \ds\int f \wrt{\mu} && \tinytext{Def. \ref{def:integral_of_arbitrary_borel_measurable_function}} 
\end{align*}

Likewise if $c < 0$
\begin{align*}
\ds\int cf \wrt{\mu} &= \ds\int (cf)^+ \wrt{\mu} - \ds\int (cf)^- \wrt{\mu} && \tinytext{Def. \ref{def:integral_of_arbitrary_borel_measurable_function}} \\
&= \ds\int -cf^- \wrt{\mu} - \ds\int -cf^+ \wrt{\mu} && \tinytext{\eqref{eqn:decomposing_scalar_multiple_of_borel_measurable_function_into_two_nonnegative_functions_when_scalar_multiple_is_negative}} \\ 
& \stackrel{**}{=} -c \ds\int f^- \wrt{\mu} + c \ds\int f^+ \wrt{\mu} && \tinytext{ Prop. \ref{prop:properties_of_integrals_of_non_negative_borel_measurable_functions} (b)}  \\ %\labelit \label{eqn:expanding_integral_of_positive_scalar_times_function} \\
& = c \ds\int f \wrt{\mu} && \tinytext{Def. \ref{def:integral_of_arbitrary_borel_measurable_function}} \\
\end{align*}	

Equations (*) and (**) reveal that $\int cf \wrt{\mu}$ exists whenever $\int f \wrt{\mu}$ exists.

\item First we show that $g \geq h \implies \ds\int g \wrt{\mu} \geq \ds\int h \wrt{\mu}$ when both integrals exist.  We decompose each function into its positive and negative parts
\[ g = g^+ - g^-, \quad h = h^+ - h^-. \]
By hypothesis,
\[ g^+ \geq h^+, \quad g^- \leq h^-. \]
So by monotonicity for non-negative functions (Prop. \ref{prop:properties_of_integrals_of_non_negative_borel_measurable_functions} (a)), we have 
\begin{align} \ds\int g^+ \wrt{\mu} \geq \ds\int h^+ \wrt{\mu}, \quad \ds\int g^- \wrt{\mu}  \leq \ds\int h^- \wrt{\mu}. 
\label{eqn:monotonicity_for_positive_and_negative_parts_separately}
\end{align}

So
\begin{align*}
\ds\int g \wrt{\mu} &= 	\ds\int g^+ \wrt{\mu} - \ds\int g^- \wrt{\mu} && \tinytext{(def. integral; existence assumed)} \\
&\geq \ds\int h^+ \wrt{\mu} - \ds\int h^- \wrt{\mu} &&  \tinytext{\eqref{eqn:monotonicity_for_positive_and_negative_parts_separately}} \\
&=\ds\int g \wrt{\mu} && \tinytext{(def. integral;  existence assumed)}
\end{align*}

Now we consider the ``dominance criterion for existence".  We prove the second sentence of (b), as the third is proved similarly. 

If $\ds\int h \wrt{\mu}$ exists and $\ds\int h \wrt{\mu} > -\infty$, then by definition of the integral, $\ds\int h^- \wrt{\mu} < \infty$.  Since $g \geq h$, then $g^- \leq h^-$, so 
\[ \ds\int g^- \wrt{\mu} \leq \ds\int h^- \wrt{\mu} < \infty \]
Thus, $\ds\int g \wrt{\mu}$ exists.\footnote{Recall that for $\ds\int f \wrt{\mu}$ to exist, at least one of  $\ds\int f^- \wrt{\mu}$, $\ds\int f^+ \wrt{\mu}$ must be finite.}
\item  We want to prove that if $h \geq 0$ and $B \in \F$, then
\[ \ds\int_B h \wrt{\mu} = \sup \biggset{ \ds\int_B s \wrt{\mu} : \; 0 \leq s \leq h, \; s \text{ simple }}. \] 
We prove \framebox{$\geq$}, \framebox{$\leq$}  separately, using the strategy of Remark \ref{rk:one_way_to_show_two_supremums_are_equal}.

\begin{itemize}
\item \framebox{$\geq$}.  For $0 \leq s \leq h$, $s$ simple,
\begin{align*}  
\ds\int_B h \wrt{\mu} \geq \ds\int_B s \wrt{\mu}  && \tinytext{monotonicity}
\end{align*}
Since the LHS is an upper bound on the set of the integrals on the RHS, \framebox{$\geq$} holds. 

\item \framebox{$\leq$} 
\begin{align*}
\set{t: t \text{ simple}, 0 \leq t \leq h \indicate{B}}  & \subseteq \set{s \indicate{B} : s \text{ simple }, 0 \leq s \leq h }  \\
\implies \explaintermbrace{:=$\ds\int_B h \wrt{\mu}$}{\sup \biggset{\ds\int t  \wrt{\mu} : \; t \text{ simple}, \; 0 \leq t \leq h \indicate{B} }} & \leq \sup \biggset{\ds\int s \indicate{B} \wrt{\mu} : \; s \text{ simple}, \; 0 \leq s \leq h } 
\end{align*}

\end{itemize}

\item 
\[ (h \indicate{A})^+ = h^+\indicate{A} \, \leq h^+, \quad  (h \indicate{A})^- = h^- \indicate{A}  \, \leq h^- \]
So by monotonicity,
\begin{align*}
\explaintermbrace{A1}{\ds\int (h \indicate{A})^+ \wrt{\mu}} \leq \explaintermbrace{B1}{\ds\int h^+ \wrt{\mu}} \\
\explaintermbrace{A2}{\ds\int (h \indicate{A})^- \wrt{\mu}} \leq \explaintermbrace{B1}{\ds\int h^- \wrt{\mu}} \\
\end{align*}
So $B_i < \infty \implies A_i < \infty$.

By assuming the conditional holds for at least one $i \in \set{1,2}$, we prove transfer of existence. By assuming the conditional holds for both $i$, we prove transfer of finiteness. 

\end{alphabate}
\end{proof}


\begin{remark}{\remarktitle{Why the monotonicity property is concerned with existence}}
Why is Proposition \ref{prop:properties_of_integrals_of_arbitrary_borel_measurable_functions} \ref{item:monotonicity} concerned with monotonicity? Answer: even if $\ds\int g \wrt{\mu}$ exists and $g \geq h$, we can still have $\ds\int h \wrt{\mu}$ not exist, because of \eqref{eqn:monotonicity_for_positive_and_negative_parts_separately}.  For example, we can have 
\begin{align}
\ds\int g^+ \wrt{\mu} &= \ds\int h^+ \wrt{\mu} = \infty  \\
\ds\int g^- \wrt{\mu} & < \ds\int h^- \wrt{\mu} = \infty 	
\end{align}
and so $\ds\int h \wrt{\mu}$ DNE.
\label{rk:why_does_existence_matter_for_monotonicity}
\end{remark}

\begin{remark}{\remarktitle{Why delayed truncation of simple functions is something that needs to be proven}}
Proposition \ref{prop:properties_of_integrals_of_arbitrary_borel_measurable_functions} \ref{item:delayed_truncation_of_simple_functions} needs to be proven because it is \textit{not} what is given by the definition of the integral for an arbitrary Borel measurable function (after observing that $h \indicate{B}$ is still measurable).   Note that
\begin{subequations}
\begin{align}	
\ds\int_\Omega h \wrt{\mu} &= \sup \biggset{ \ds\int s \wrt{\mu} : \; 0 \leq s \leq h \indicate{B}, \; s \text{ simple} } && \tinytext{def. integral} \label{eqn:integral_over_subset_according_to_definition} \\
\ds\int_\Omega h \wrt{\mu} &= \sup \biggset{ \ds\int s \indicate{B} \wrt{\mu} : \; 0 \leq s \leq h, \; s \text{ simple}  }&& \tinytext{Prop. \ref{prop:properties_of_integrals_of_arbitrary_borel_measurable_functions}  \ref{item:delayed_truncation_of_simple_functions}. } \label{eqn:integral_over_subset_according_to_delayed_truncation_property}
\end{align}
\end{subequations}

\begin{figure}[H]
\centering 
\includegraphics[width=.2\linewidth, angle=90]{images/function_and_truncated_function}	
\end{figure}

What does each say?
\begin{itemize}
\item \eqref{eqn:integral_over_subset_according_to_definition} : truncate first, then ``simplify"
\item \eqref{eqn:integral_over_subset_according_to_delayed_truncation_property} ``simplify" first, then truncate
\end{itemize}


\label{rk:why_delayed_truncation_of_simple_functions_is_something_that_needs_to_be_proven}.
\end{remark}
 
 
\section{$\S$ 1.6 Basic Integration Theorems}

Here we prove some basic integration theorems, and further properties of integration that can be derived thereof.  %Note that we have already provided the Monotone Convergence Theorem and Fatou's lemma in the previous section (since we give statements that apply to non-negative functions). 

\begin{theorem}{\textbf{Integrals as measures.}}
Let $f$ be a Borel measurable function such that $\int_\Omega f \wrt{\mu}$ exists.  Define $\lambda(B) = \int_B f \wrt{\mu}$, $B \in \F$.  Then $\lambda$ is countably additive on $\F$; thus if $f \geq 0$, $\lambda$ is a measure.	
\label{thm:integrals_as_measures}
\end{theorem}

\begin{proof}
Recall that Prop. \ref{prop:the_integral_of_a_simple_function_over_a_set_is_one_way_to_measure_that_set}  proved this for non-negative simple functions.


So let $f$ be any non-negative Borel measurable function.   We want to show that if $\lambda(B) = \int_B f \wrt{\mu}$,  $B = \bigcupdot_{n=1}^\infty B_n$, then $\lambda(B) = \ds\sum_{n=1}^\infty \lambda(B_n)$.

\begin{itemize}
\item \framebox{$\leq$} Let $s$ be simple, $0 \leq s \leq f$.   Then 
\begin{align*}
\ds\int_B s \wrt{\mu} &= \ds\sum_{n=1}^\infty \ds\int_{B_n} s \wrt{\mu} && \tinytext{Prop. \ref{prop:the_integral_of_a_simple_function_over_a_set_is_one_way_to_measure_that_set}} \\
&\leq \ds\sum_{n=1}^\infty \ds\int_{B_n} f \wrt{\mu}  && \tinytext{monotonicity} \\ 
&:= \ds\sum_{n=1}^\infty \lambda(B_n) 	
\end{align*}
Since the RHS is an upper bound, the supremum (over s) cannot exceed it.  Thus, applying Prop. \ref{prop:properties_of_integrals_of_arbitrary_borel_measurable_functions} \ref{item:delayed_truncation_of_simple_functions}, we have 
\begin{align*}
\ds\int_B f \wrt{\mu} & \leq \ds\sum_{n=1}^\infty \lambda(B_n)  \\ 
\implies \lambda(B) &\leq \ds\sum_{n=1}^\infty \lambda(B_n) && \tinytext{def. $\lambda$}
\end{align*}

\item \framebox{$\geq$}	By monotonicity of the integral, 
\begin{align*}
B \supset B_n \implies \indicate{B} \geq \indicate{B_n} \implies  f\indicate{B}   \geq f\indicate{B_n} \implies \lambda(B) \geq \lambda(B_n) && \tinycircled{1}
\end{align*} 
If $\lambda(B_n) =\infty$ for one $n$, we are done. {\tiny (Why? Since $f \geq 0$, by monotonicity, $\int_A f \wrt{\mu} \geq 0$ for any $A \in \F$.  So each $\lambda(B_n) \geq 0$.  So if one $\lambda(B_n) = \infty$, then $\sum_{n=1}^\infty \lambda(B_n) = \infty$, and \tinycircled{1} and $\lambda(B) \geq \ds\sum_{n=1}^\infty \lambda(B_n)$ are saying the same thing, that $\lambda(B) = \infty$.)}
 
 So let each $\lambda(B_n) < \infty$.  
 
 Fix $N$.  Consider $\bigcupdot_{n=1}^N B_n$.  By Prop. \ref{prop:properties_of_integrals_of_arbitrary_borel_measurable_functions} \ref{item:delayed_truncation_of_simple_functions} and properties of the supremum {\tiny (if we subtract $\epsilon$ from it, there $\exists$ a member of the set exceeding that)}, for all $\epsilon>0$, we have simple functions $s_n : 0 \leq s_n \leq f$ for each $n$ so that 
 
\begin{align*}
\ds\int_{B_n} s_n \wrt{\mu} \geq \ds\int_{B_n} f \wrt{\mu} - \frac{\epsilon}{N} \quad \text{ for all } n  && \tinycircled{2} 
\end{align*}
Let $s^*$ be the pointwise maximum of $\set{s_n}_{n=1}^N$.  This is still a simple function, and $s^* \indicate{B_n} \geq s_n \indicate{B_n}$ for each $n$, so 
   
\begin{align*}
\ds\int_{B_n} s^* \wrt{\mu} \geq \ds\int_{B_n} s_n \quad \text{ for all } n && \tinycircled{3}
\end{align*}

So \tinycircled{2} and \tinycircled{3} gives that 
 
\begin{align*}
\ds\int_{B_n} s^* \wrt{\mu} \geq \ds\int_{B_n} f \wrt{\mu} - \frac{\epsilon}{N} \quad \text{ for all } n  && \tinycircled{4} 
\end{align*}

Thus, for any $N$, $\epsilon>0$, we have  
\begin{align*}
\lambda(B) &\geq \lambda(\bigcupdot_{n=1}^N B_n) && \tinytext{By monotonicity; need argument like \tinycircled{1}; we don't know it's a measure yet!} \\
&:= \ds\int_{\bigcupdot_{n=1}^N B_n} f \wrt{\mu} \\
& \geq \ds\int_{\bigcupdot_{n=1}^N B_n} s^* \wrt{\mu} && \tinytext{monotonicity} \\
&= \ds\sum_{n=1}^N \ds\int_{B_n} s^* \wrt{\mu} && \tinytext{what's we're trying to prove holds for simple functions (Prop. \ref{prop:the_integral_of_a_simple_function_over_a_set_is_one_way_to_measure_that_set}) } \\
&\geq \ds\sum_{n=1}^N \ds\int_{B_n} f_n \wrt{\mu} - \epsilon && \tinytext{see \tinycircled{4}} \\
&:= \ds\sum_{n=1}^N  \lambda(B_n) -\epsilon \\
\implies \lambda(B) &\geq \ds\sum_{n=1}^\infty \lambda(B_n) && \tinytext{justified below}
\end{align*}

{\tiny What justifies the last line above?  \textbf{Claim.} Let $\set{a_n}_{n=1}^\infty : 0 \leq a_n < \infty$.  Then $M \stackrel{*}{\geq} \ds\sum_{n=1}^N a_n - \epsilon \; \text{ for any } N, \epsilon>0 \implies M \geq \ds\sum_{n=1}^\infty a_n.$ \textbf{Proof}. If $\ds\sum_{n=1}^\infty a_n = \infty$ then the claim obviously holds.  If $\ds\sum_{n=1}^\infty a_n < \infty$ then for all $\epsilon >0$, the tail of the series is less than $\epsilon$ for some $N^*$.  So write $\sum_{n=1}^{N^*} a_n < \ds\sum_{n=1}^\infty a_n - \epsilon$, and equation (*) becomes $M \geq \ds\sum_{n=1}^\infty a_n - 2\epsilon = \ds\sum_{n=1}^\infty a_n -\tilde{\epsilon}$ for all $\tilde{\epsilon} > 0$.  Take the limit as $\tilde{\epsilon} \to 0$, and the non-strict inequality is preserved in the limit.}

So now assume $f$ is an arbitrary Borel-measurable function.  Since we have assumed $\ds\int f \wrt{\mu}$ exists, we have $\ds\int f^+ \wrt{\mu}, \ds\int f^- \wrt{\mu} < \infty$.  So by what we have shown for non-negative functions, there exists measures $\lambda^+, \lambda^-$ corresponding to each of these integrals.  So if $B = \bigcupdot_{n=1}^\infty B_n$, 
\begin{align*}
\ds\int_B f \wrt{\mu} &= \ds\int_B f^+ \wrt{\mu} - \ds\int_B f^- \wrt{\mu} && \tinytext{def. integral} \\
\implies \lambda(B) &= \lambda^+(B) - \lambda^-(B) && \tinytext{by def. of $\lambda$, $\lambda^+$, $\lambda^-$ } \\
\implies \lambda(B) &= \ds\sum_{n=1}^\infty \lambda^+(B_n) - \ds\sum_{n=1}^\infty \lambda^-(B_n) && \tinytext{by result with non-negative functions } \\
\end{align*}
 and this expression is \textit{NOT} of the form $\infty - \infty$, since the first line isn't, by the existence of $\int_\Omega f \wrt{\mu}$ {\tiny (and the fact that, by monotonicity, $\int_\Omega f \wrt{\mu} < \infty \implies \int_B f \wrt{\mu} < \infty  $) }.

\end{itemize}

\end{proof}

\begin{remark}{\remarktitle{Change of measure}} Rudin \cite{rudin1987real} points out an important implication of Theorem \ref{thm:integrals_as_measures}: if $f \geq 0$, and so $\lambda$ (as defined as in the theorem statement) is a measure, then
\begin{align*}
\dint_\Omega g \wrt{\lambda} = \dint_\Omega g f \dmu
\labelit \label{eqn:change_of_measure}
\end{align*}
for every measurable $g$ on $\Omega$ such that $g \geq 0$. 

The change of measure statement \eqref{eqn:change_of_measure} is sometimes written in the form
\begin{align*}
d\lambda = f \; d\mu 
\labelit \label{eqn:change_of_measure_as_change_in_differentials}
\end{align*}

Rudin assigns no independent meaning to the symbols 
$d\lambda$ and $d\mu$; \eqref{eqn:change_of_measure_as_change_in_differentials} simply means that \eqref{eqn:change_of_measure} holds for every measurable non-negative $g$. 

The Radon-Nikodym theorem (to be covered later in the document) provides an important converse:  instead of obtaining new measure $\lambda$ given original measure $\mu$ and function $f$, we will be given two measures $\lambda$ and $\mu$, and will obtain the \textit{Radon-Nikdoym derivative} $f$.

{\tiny Let us prove \eqref{eqn:change_of_measure} from Theorem \ref{thm:integrals_as_measures}.

\begin{itemize}
	\item First let $g$ be a simple function, which we write as $s= \sum_{i=1}^r x_i \indicate{E_i}$.   Then 
\[ \int s \wrt{\lambda} \stackexplain{simple f'n}{=} \sum_{i=1}^r x_i \lambda(E_i) \stackexplain{hypothesis}{=}  \sum_{i=1}^r x_i \int_{E_i} f \dmu \stackexplain{linearity}{=} \int \sum_{i=1}^r x_i \indicate{E_i} f \dmu \stackexplain{def. $s$}{=} \int sf \dmu    \]
\item Now let $g$ be a non-negative measurable function. By Prop \ref{prop:there_is_a_sequence_of_simple_fucntions_that_increases_to_any_non_negative_borel_measurable_function}, there exists a sequence of simple functions $\set{s_n}$ such that $s_n \uparrow g$.  Since  $s_n \uparrow g$, then also $s_n f \uparrow fg$.  So applying Monotone Convergence Theorem to both, we obtain $\int s_n d\lambda \uparrow \int g d\lambda$ and  $\int s_n f d\mu \uparrow \int fg d\mu$.  But since $\int s_n d\lambda  =\int s_n f d\mu$ for all $n$ by the previous bullet point, the sequences must have the same limit (by uniqueness of limits), so $\int g d\lambda = \int gf d\mu$.
\end{itemize}
} 
\end{remark}


 
\begin{theorem}{\textbf{Additivity theorem.}}
Let $f$ and $g$ be Borel measurable, and assume that $f+g$ is well-defined.  If $\dint_\Omega f \dmu$ and $\dint_\Omega g \dmu$ exist and $\dint_\Omega f \dmu$ + $\dint_\Omega g \dmu$ is well-defined (not of the form $+ \infty - \infty$ or $- \infty +\infty$), then 
\[ \dint_\Omega f +g \dmu = \dint_\Omega f \dmu + \dint_\Omega f \dmu \]
In particular, if $f$ and $g$ are integrable, so is $f+g$.
\label{thm:additivity}
\end{theorem}

\begin{proof}
See \cite{ash2000probability}, Theorem 1.6.3.	
\end{proof}



\begin{remark}{\remarktitle{Additivity holds automatically for integrable functions.}}
If $f$ and $g$ are integrable, the conditions of Theorem \ref{thm:additivity} are always met.    

Moreover, in this situation, the proof of Theorem \ref{thm:additivity} is straightforward. Suppose $f$ and $g$ are integrable. Let $h=f+g$.  Then 
\[ h^+ - h^- = f^+ - f^- + g^+ - g^- \]
Rearranging, we have 
\[ h^+ + f^- + g^- = f^+ + g^+ + h^- \]
Applying additivity for non-negative functions (see Prop. \ref{prop:additivity_of_integral_for_non_negative_Borel_measurable_functions}) twice, we get 
\[ \int h^+ + \int f^- + \int g^- =  \int f^+ + \int g^+ + \int h^- \]
Rearranging (possible by integrability), we get 
\begin{align*} 
\int h^+ -  \int h^- &=  \int f^+ - \int f^- + \int g^+ - \int g^- \\
\stackexplain{def. integral, def. h}{\implies} \int f+g &= \int f + \int g 
\end{align*}
\label{rk:additivity_holds_automatically_for_integrable_functions}	
\end{remark}

\begin{remark}
The conditions of the additivity theorem imply the conditions of the scalar multiple property (Prop \ref{prop:properties_of_integrals_of_arbitrary_borel_measurable_functions} (a)).  Thus, linearity holds whenever additivity holds.
\label{rk:linearity_holds_if_additivity_holds}	
\end{remark}


\begin{corollary}{\remarktitle{Additivity corollaries}}
\begin{alphabate}
\item If $h$ is Borel measurable, $h$ is integrable iff $|h|$ is integrable.
\item If $g$ and $h$ are Borel measurable with $|g| \leq h$, $h$ integrable, then $g$ is integrable.	
\end{alphabate}
\label{cor:additivity_corollaries}
\end{corollary}

\begin{proof}
\begin{alphabate}
\item  If $h$ is integrable, then by assumption we have 
\[ \bigg| \dint h \dmu \bigg| \stackexplain{def. \, integral}{=} \bigg| \dint h^+ \dmu - \dint h^- \dmu \bigg| < \infty \]
which is true iff BOTH of $\biggset{\dint h^+ \dmu , \dint h^- \dmu } < \infty$

If $|h|$ is integrable, then by assumption we have 
\[ \bigg| \dint |h| \dmu \bigg| \stackexplain{additivity  (Theorem \ref{thm:additivity})}{=} \bigg| \dint h^+ \dmu + \dint h^- \dmu \bigg| < \infty \]
which is also true iff BOTH of $\biggset{\dint h^+ \dmu , \dint h^- \dmu } < \infty$
\item 
\begin{align*}
\dint h \dmu &< \infty &&\tinytext{by hypothesis} \\
\implies \dint |g| \dmu &< \infty &&\tinytext{by monotonicity}	\\
\implies g &\text{ integrable } && \tinytext{by item b) above}	
\end{align*}
\end{alphabate}
\end{proof}


\begin{definition}{\textbf{Almost everywhere}}
A condition is said to hold \textit{almost everywhere} with respect to the measure $\mu$ (written a.e $[\mu]$ or simply a.e. if $\mu$ is understood) if there exists a set $B \in \F$ of $\mu$-measure 0 such that the condition holds outside $B$.
\label{def:almost_everywhere}
\end{definition}

From the point of view of integration theory, functions that differ only on a set of measure zero may be identified, as is established by the following result.

\begin{theorem}{\textbf{Almost everywhere}.}
Let $f,g,h$ be Borel measurable functions.
\begin{alphabate}
\item If $f=0$ a.e. $[\mu]$, then $\dint_\Omega f \dmu =0$.
\item If $g=h$ 	a.e. $[\mu]$, and $\dint_\Omega g \dmu$ exists, then so does $\dint_\Omega h \dmu$, and $\dint_\Omega g \dmu  = \dint_\Omega h \dmu$. 
\end{alphabate}
\label{thm:almost_everywhere}
\end{theorem}

\begin{proof}
\begin{alphabate}
\item  

	\begin{enumerate}
	\item[i)] \underline{$f$ simple}.	 If $f$ is simple, we can write $f=\sum_{i=1}^n x_i \indicate{A_i}$.  By hypothesis, $\forall$ i, $x_i=0$ or $\mu(A_i)=0$.  Thus, $\int f \dmu = \sum_{i=1}^n x_i \indicate{A_i} =0.$
	\item[ii)] \underline{$f$ non-negative}. Since $f=0$ a.e. $[\mu]$, then $\forall$ $s \in \set{s \text{ simple } : 0 \leq s \leq f}, s=0$ a.e. $[\mu]$.  So by item i), $\int s \dmu =0 \, \forall s$.  So by definition of the integral for non-negative functions
	\[ \int f \dmu = \sup \set{ \int s \dmu : s \text{ simple }, 0 \leq s \leq f}  = \sup \set{0} = 0\]
	\item[iii)]\underline{$f$ arbitrary}. $f=0$ a.e. $[\mu] \implies f^+=0, f^-=0$ a.e. $[\mu]$.  So by item ii), $\int f^+ \dmu =0, \int f^- \dmu =0.$. So by definition of the integral $ \int f \dmu = \int f^+ \dmu - \int f^- \dmu =0$.
	\end{enumerate}
\item We prove i) $\int h \dmu$ exists and then that ii) $\int h \dmu = \int g \dmu$

	\begin{enumerate}
	\item[i)] $\int g \dmu$ exists means that $\int g^+ \dmu, \int g^- \dmu$ are not BOTH $\infty$.  WLOG, suppose that $\int g^+ \dmu < \infty 	 \quad \tinycircled{1}$.  
	
	Now $h=g$ a.e. $\implies h^+=g^+, h^-=g^-$ a.e. $\implies h^+ - g^+ = 0 \text{ a.e. } \quad \tinycircled{2}$.   So
\begin{align*}
0 \stackexplain{by part (a) and \tinycircled{2}}{=} \ds\int (h^+ - g^+) \dmu \stackexplain{linearity}{=} 	\ds\int h^+ \dmu  - \ds\int g^+ \dmu && \tinycircled{3}
\end{align*}
where we can apply linearity (see Remark \ref{rk:linearity_holds_if_additivity_holds}) because
	\begin{itemize}
	\item Integrals of non-negative functions always exist, and multiplication by a scalar doesn't change existence (see Prop. \ref{prop:properties_of_integrals_of_arbitrary_borel_measurable_functions} \ref{item:scalar_multiple}).
	\item The difference can't be of the form $\infty - \infty$ by \tinycircled{1}.
	\end{itemize}
So again by \tinycircled{1}, we can add to  sides of \tinycircled{3} to get
\[ \dint h^+ = \dint g^+ < \infty \]
so $\int h \dmu$ exists.
\item[ii)] Let $A:=\set{\omega : h(\omega) = g(\omega)}$.  By hypothesis, $\mu(A^c)=0$. Now we decompose each function by partitioning their domains
\begin{align*}
h&=h\indicate{A} + h\indicate{A^c}  \stackexplain{def. $A$}{=} g \indicate{A} + h \indicate{A^c} \labelit \label{eqn:decompose_h_by_domain}\\
g&= g\indicate{A} + g\indicate{A^c}  \labelit \label{eqn:decompose_g_by_domain}\\	
\end{align*}
 Now since $g \indicate{A^c}, h \indicate{A^c}$ equal 0 except on a set of measure 0, by part (a),
\begin{align*}
\int_{A^c} g \dmu =0, \quad  \int_{A^c} h \dmu =0
\labelit\label{eqn:integrals_on_set_of_measure_zero}	
\end{align*}
And so we can apply additivity to \eqref{eqn:decompose_h_by_domain} and \eqref{eqn:decompose_g_by_domain}, since:
	\begin{itemize}
	\item $\int g \dmu, \int h \dmu$ exist, so since existence transfers to subsets (see Prop. \ref{prop:properties_of_LS_measures}\ref{item:existence_transfers_to_subsets}), $\int_A g \dmu, \int_{A^c} g \dmu, \int_A h \dmu, \int_{A^c} h \dmu $ exist.  
	\item By \eqref{eqn:integrals_on_set_of_measure_zero},
	\begin{align*}
	\int_A g \dmu + \int_{A^c} g \dmu & \neq \infty - \infty \\
	\int_A h \dmu + \int_{A^c} h \dmu  & \neq \infty - \infty \\	
	\end{align*}
	\end{itemize}
	So applying linearity to \eqref{eqn:decompose_h_by_domain} and \eqref{eqn:decompose_g_by_domain}, we get 
	\begin{align*}
	\int h \dmu &= 	\int_A g \dmu + 	\cancelto{0}{\int_{A^c} h \dmu} && \tinytext{cancelation by \eqref{eqn:integrals_on_set_of_measure_zero}.} \\
	\int g \dmu &= 	\int_A g \dmu + 		\cancelto{0}{\int_{A^c} g \dmu} && \tinytext{cancelation by \eqref{eqn:integrals_on_set_of_measure_zero}.} \\
	\end{align*}
	And so $\int h \dmu = \int g \dmu$
	\end{enumerate}
\end{alphabate}

\end{proof}

\begin{remark}
	
Thanks to Theorem \ref{thm:almost_everywhere}, in any integration theorem, we may freely use the phrase ``almost everywhere" in the hypotheses, and the conclusions will still follow.  For example
\begin{itemize}
\item If $g,h$ are Borel measurable and $g \geq h$ a.e., then $\int g \dmu \geq \int h \dmu$.  {\tiny (This is the monotonicity property from Prop. \ref{prop:properties_of_integrals_of_arbitrary_borel_measurable_functions} \ref{item:monotonicity}, but with the condition weakened to a.e.). }
\item If $\set{h_n}$ is a sequence of non-negative Borel measurable functions such that $h_n \to h$ a.e., then $\int_\Omega h_n \dmu \to \int_\Omega h \dmu$. {\tiny (This is the Monotone Convergence Theorem but with the condition weakened to a.e.  In more detail: we can simply define $h^*_n$ such that it equals $h_n$ almost everywhere and $h$ on the set of measure 0.  Then $h^*_n \to h$.  So by MCT,  $\int_\Omega h^*_n \dmu \to \int_\Omega h \dmu$.  But by Theorem \ref{thm:almost_everywhere} b), $\int_\Omega h^*_n \dmu  = \int_\Omega h_n \dmu$ for all $n$, and so the conclusion holds.)  }
\end{itemize}
\end{remark}

\begin{theorem}
Let $h$ be Borel measurable
\begin{alphabate}
\item If $h$ is integrable, then $h$ is finite a.e. 
\item If $h \geq 0$ and $\int_\Omega h \dmu =0$ then $h=0$ a.e.
\end{alphabate}
\label{thm:properties_of_functions_derived_from_properties_of_integrals}
\end{theorem}

\begin{proof}
\begin{alphabate}
\item By contraposition.  If h is not finite a.e., then $\exists B \in \F : \mu(B) >0$ and $|h \indicate{B}| = \infty$.  Then 
\[ \ds\int_\Omega |h| \dmu \stackexplain{monotonicity}{\geq} \ds\int_B |h| \dmu \stackexplain{simple function} = \infty \, \mu(B) = \infty. \]
So $|h|$ is not integrable. So by Corollary \ref{cor:additivity_corollaries} b), $h$ is not integrable. 
\item Let $B_n := \set{\omega : h(\omega) \geq \frac{1}{n}}$.  Then  $ B_n \uparrow B := \set{\omega : h(\omega) > 0}.\footnote{Recall that $\cup_{n=1}^\infty [\frac{1}{n}, \infty) = (0, \infty)$.} \quad \tinycircled{1}$

Now
\begin{align*} 
 0 \stackexplain{first hypothesis}{\leq} h \indicate{B_n} \stackexplain{$B_n \subset B$ }{\leq} h \indicate{B} \stackexplain{def. $B$}{=} h \\
\implies \dint_{B_n} h \dmu \stackexplain{monotonicity}{\leq} \dint_\Omega h \dmu \stackexplain{second hypothesis}{=} 0 \\
\stackexplain{first hypothesis, monotonicity}{\implies} \dint_{B_n} h \dmu =0 && \tinycircled{2}
\end{align*}
Now \tinycircled{1} and monotonicity again give
\begin{align*}
\dint_{B_n} h \dmu \stackexplain{def. $B_n$, monotonicity}{\geq} \dint \frac{1}{n} \indicate{B_n} \dmu \stackexplain{simple function}{=} \frac{1}{n} \mu(B_n) && \tinycircled{3} 	
\end{align*}
Now \tinycircled{2} and \tinycircled{3} together give $\mu(B_n) =0 \; \forall n$.  So by continuity of measure
\[ \mu(B) = \ds\lim_{n \to \infty} \mu(B_n) =0 \]

\end{alphabate}
	
\end{proof}

The monotone convergence theorem as stated earlier only applies to non-negative functions and only to increasing sequences. We relax those assumptions below.

\begin{theorem}{\textbf{Extended Monotone Convergence Theorem.}}
Let $f_1, f_2, ..., f, g$ be Borel measurable
\begin{alphabate}
\item If $f_n \uparrow f$ and $f_n \geq g$ for all $n$, where $\int_\Omega g \dmu > -\infty$, then 
\[ \ds\int_\Omega f_n \dmu \uparrow \ds\int_\Omega f \dmu  \]
\item If $f_n \downarrow f$ and $f_n \leq g$ for all $n$, where $\int_\Omega g \dmu < \infty$, then 
\[ \ds\int_\Omega f_n \dmu \downarrow \ds\int_\Omega f \dmu  \]	
\end{alphabate}
\label{thm:extended_monotone_convergence_theorem}
\end{theorem}

\begin{proof}
\begin{alphabate}
\item If $\int g \dmu = \infty$, then by monotonicity {\tiny (and the fact that the limit of an increasing sequence equals its supremum)}, $\int f \dmu \geq \int f_n \dmu \geq \int g \dmu$, and the conclusion holds.  So assume $\int g \dmu < \infty$.  Along with the hypothesis, we have that $\int g \dmu$ is finite.

%Now we have $f_n - g \geq 0$ and $f_n -g \uparrow f-g$, so by Monotone Convergence Theorem, 
Now
\begin{align*}
& f_n - g \geq 0 \quad \text{ and } \quad f_n -g \uparrow f-g && \tinytext{Hypothesis (and Prop \ref{prop:limit_of_monotone_sequences})} \\
\implies & \ds\int (f_n - g) \dmu \uparrow \ds\int (f-g) \dmu && \tinytext{Monotone Convergence Theorem}\\
\stackrel{\tinycircled{1}}{\implies} & \ds\int f_n \dmu - \ds\int g \dmu \uparrow \ds\int f \dmu - \ds\int g \dmu && \tinytext{Linearity}\\
\implies & \dint f_n \dmu \uparrow \dint f \dmu && \tinytext{Since $\int g$ is finite} 
\end{align*}	
To check that linearity holds in \tinycircled{1}, note that $\int f \dmu$ and $\int f_n \dmu$ exist by monotonicity (Prop \ref{prop:properties_of_integrals_of_arbitrary_borel_measurable_functions} a), and the sum cannot be of form $\infty - \infty$ or $-\infty + \infty$ since $\int g \dmu$ is finite.
\item We have
\begin{align*}
& -f_n \geq -g \quad \text{ and } \quad -f_n \uparrow -g && \tinytext{Hypothesis} \\
\implies & - \int f_n \dmu \uparrow - \int f \dmu && \tinytext{Part (a) (and constant multiple property; Prop \ref{prop:properties_of_integrals_of_arbitrary_borel_measurable_functions} a) } \\
\implies & \int f_n \dmu \downarrow  \int f \dmu
\end{align*} 
\end{alphabate}
\end{proof}




\paragraphnewline{Fatou's Lemma}


\begin{theorem}{\textbf{Extended Fatou's Lemma}\footnote{We refer to Theorem \ref{thm:extended_fatous_lemma} as \textit{extended} Fatou's lemma in parallel with the extended monotone convergence theorem (Theorem \ref{thm:extended_monotone_convergence_theorem}).  Some presentations, e.g. \cite{folland1999real}, present a (non-extended) version of Fatou's lemma that only gives part (a) and which only applies to non-negative measurable functions.  We prefer the extended formulation due to its greater generality and supporting of intuition from the ``big picture view".  Note that in the case of non-negative functions, the hypotheses reduce to simply $f_n \uparrow f$, as there is automatically a measurable $g$ satisfying the remaining conditions, namely $g \equiv 0$. }}
Let $f_1, f_2, ..., g$ be Borel measurable for each positive integer $n$. 
\begin{alphabate}
\item If $f_n \geq g$ for all $n$ where $\int_\Omega g \dmu > -\infty$ then 
\begin{align} 
\ds\int_\Omega \bigg( \liminf_{n \to \infty} f_n \bigg) \dmu \leq \liminf_{n \to \infty} \dint_\Omega f_n \dmu
\label{eqn:fatous_lemma_with_infs}
\end{align}
\item If $f_n \leq g$ for all $n$ where $\int_\Omega g \dmu < \infty$ then 
\begin{align} 
\ds\int_\Omega \bigg( \limsup_{n \to \infty} f_n \bigg) \dmu \geq \limsup_{n \to \infty} \dint_\Omega f_n \dmu
\label{eqn:fatous_lemma_with_sups}
\end{align}
\end{alphabate}
\label{thm:extended_fatous_lemma}
\end{theorem}

\begin{proof}
\begin{alphabate}
\item By definition of the limit inferior,
\[ \explaintermbrace{$:=h$}{\liminf_{n \to \infty} f_n} = \lim_{n \to \infty}  \explaintermbrace{$:=h_n$}{\inf_{m \geq n} f_n} \]	
Now $h_n \uparrow h$ {\tiny (due to taking the infimum over successively smaller sets; see Prop. \ref{prop:sup_and_inf_for_subsets_are_tighter})}, $h_n \geq g$ {\tiny (since $g$ is a lower bound by hypothesis and the infimum is the \textit{greater} lower bound)} where $\int_\Omega g \dmu > - \infty$ {\tiny (by hypothesis)}. \\

Hence, by the extended Monotone Convergence Theorem (Thm. \ref{thm:extended_monotone_convergence_theorem})
\begin{align*} 
  \explaintermbrace{$=\liminf_{n \to \infty} \dint h_n \dmu$}{\dlim_{n \to \infty} \dint h_n \dmu} \stackexplain{(MCT)}{=} \dint \dlim_{n \to \infty} h_n \dmu  && \tinycircled{1} 
\end{align*}
So
\[ \liminf_{n \to \infty} \dint f_n \dmu \stackexplain{(monotonicity, $f_n \geq h_n$)}{\geq}  \liminf_{n \to \infty} \dint h_n \dmu \stackexplain{\tinycircled{1}}{=} \dint \lim_{n \to \infty} h_n \dmu \stackexplain{(def. $h_n$)}{=} \dint \liminf_{n \to \infty} f_n \dmu \]
\item 
\begin{align*}
\ds\int_\Omega \limsup_{n \to \infty} f_n \dmu \stackrel{*}{=} - \ds\int_\Omega \liminf_{n \to \infty} (-f_n) \dmu \\
 \geq - \liminf_{n \to \infty} \ds\int_\Omega  (-f_n) \dmu && \tinytext{part (a)}\\
 \stackrel{*}{=} - \limsup_{n \to \infty} \ds\int_\Omega  (f_n) \dmu \\
\end{align*}
Equality (*) holds by the constant multiple property of the infimum and supremum (Prop \ref{prop:supremum_and_infimum_under_constant_multiples_of_sets}), which gives that $\limsup_{n \to \infty} f_n = - \liminf_{n \to \infty} (-f_n)$.  {\tiny (Part (a) applies because $f_n \leq g$ where $\int g \dmu < \infty$ implies that $-f_n \geq -g$, where $- \int g \dmu > -\infty$.  Note also that multiplying by a negative reverses the order of the inequality.)}
\end{alphabate}

\end{proof}




\begin{remark}{\remarktitle{Big picture view of Fatou's Lemma}}
We can interpret Fatou's lemma as \textit{integrals of asymptotics give more extreme values than asymptotics of integrals}.

If $|f_n| \leq g$ where $\int_\Omega g \dmu$ is finite, we have 

\begin{align} 
\ds\int_\Omega \bigg( \liminf_{n \to \infty} f_n \bigg) \dmu  \stackexplain{\eqref{eqn:fatous_lemma_with_infs}}{\leq} \liminf_{n \to \infty} \dint_\Omega f_n \dmu \stackexplain{\eqref{eqn:liminf_upper_bounded_by_limsup_for_functions}}{\leq} \limsup_{n \to \infty} \dint_\Omega f_n \dmu \stackexplain{\eqref{eqn:fatous_lemma_with_sups}}{\leq} \ds\int_\Omega \bigg( \limsup_{n \to \infty} f_n \bigg) \dmu  
\label{eqn:fatous_lemma_big_picture_view}
\end{align}

\end{remark}

\begin{example}{\remarktitle{Strict inequalities can occur in Fatou's lemma}}
We show that that strict inequalities can occur in the expanded view of Fatou's lemma, \eqref{eqn:fatous_lemma_big_picture_view}.  

Consider a measure space $(\Omega, \F, \mu)$ and set $B \in \F$ such that $0 < \mu(B^c) < \mu(B) < \mu(\Omega)$. 
Define a sequence of functions $\set{f_n}$ such that
\[ f_n = 
\begin{cases}
\indicate{B}, & \text{n odd} \\ 
\indicate{B^c}, & \text{n even} \\ 	
 \end{cases}
 \]	
 
 \begin{figure}[H]
 \centering 
 \includegraphics[width=.4\textwidth, angle=90]{images/fatous_lemma_example}	
 \end{figure}

 \begin{table}[htp!]
 \begin{tabular}{rl|l}
 & \textbf{Integrate first} & \textbf{Asymptotics first} \\
 \hline 
\textbf{Observation} & $\dint f_n  \dmu = 
\begin{cases}
\mu(B), & \text{n odd} \\ 
\mu(B^c), & \text{n even} \\ 	
 \end{cases}$	 &  $\liminf_{n \to \infty} f_n =0$ \\
 & & $\limsup_{n \to \infty} f_n =1$\\
 & & \\
 %\hline 
\textbf{Implication} & $\liminf_{n \to \infty} \dint f_n \dmu = \mu(B^c)$ & $\dint \liminf_{n \to \infty} f_n \dmu = 0$ \\
& $\limsup_{n \to \infty} \dint f_n \dmu = \mu(B)$ & $\dint \limsup_{n \to \infty} f_n \dmu = \mu(\Omega)$ \\
 \end{tabular}
 \end{table}

And so we see that strict inequalities occur in the expanded view of Fatou's lemma, \eqref{eqn:fatous_lemma_big_picture_view}. 

\begin{align*}
\explaintermbrace{0}{\ds\int_\Omega \bigg( \liminf_{n \to \infty} f_n \bigg) \dmu}  < \explaintermbrace{$\mu(B^c)$}{\liminf_{n \to \infty} \dint_\Omega f_n \dmu} < \explaintermbrace{$\mu(B)$}{\limsup_{n \to \infty} \dint_\Omega f_n \dmu} <  \explaintermbrace{$\mu(\Omega)$}{\ds\int_\Omega \bigg( \limsup_{n \to \infty} f_n \bigg) \dmu}  
%\labelit \label{eqn:fatous_lemma_big_picture_view_applied_to_example_with_strict_inequalities}
\end{align*}
The example captures the fact that \textit{integrals of asymptotics give more extreme values than asymptotics of integrals}.

\end{example}

\paragraphnewline{Dominated Convergence Theorem}

\begin{theorem}{\textbf{Dominated Convergence Theorem.}}. If $f_1,f_2,...,f,g$ are Borel measurable, $|f_n| \leq g$ for all $n$, where $g$ is $\mu$-integrable, and $f_n \to f$ a.e. $[\mu]$, then $f$ is $\mu$-integrable, and $\int_\Omega f_n \dmu \to \int_\Omega f \dmu$.
\label{thm:dominated_convergence}
\end{theorem}

\begin{proof}
We have $|f| \leq g$ a.e. {\tiny (In detail, $|f_n| \leq g$ can be unpacked into $f_n \leq g$ and $f_n \geq -g$.  Since limits preserve non-strict inequalities, we have ($f \leq g$ and $f \geq -g$) a.e.   So repacking the absolute value operator, the conclusion follows.)}, hence $f$ is integrable by Cor. \ref{cor:additivity_corollaries} (b).   

By hypothesis, both sides of the expanded Fatou's lemma apply, and so we have \eqref{eqn:fatous_lemma_big_picture_view}:

\begin{align*} 
\explaintermbrace{\tinycircled{1}}{\ds\int_\Omega \bigg( \liminf_{n \to \infty} f_n \bigg) \dmu}  \leq \explaintermbrace{\tinycircled{2}}{\liminf_{n \to \infty} \dint_\Omega f_n \dmu} \leq  \explaintermbrace{\tinycircled{3}}{\limsup_{n \to \infty} \dint_\Omega f_n \dmu} \leq \explaintermbrace{\tinycircled{4}}{\ds\int_\Omega \bigg( \limsup_{n \to \infty} f_n \bigg) \dmu}   
\end{align*}
But since $f_n \to f$ a.e, $\liminf_{n \to \infty} f_n = \limsup_{n \to \infty} f_n = \lim_{n \to \infty} f_n$ a.e., and so by the a.e. theorem (Thm. \ref{thm:almost_everywhere}), they have the same integrals: $\int_\Omega \liminf_{n \to \infty} f_n \dmu = \int_\Omega \limsup_{n \to \infty} f_n \dmu = \int_\Omega \lim_{n \to \infty} f_n \dmu $.   In other words, \tinycircled{1}=\tinycircled{4}, and so by sandwiching \tinycircled{2}=\tinycircled{3}.  Since the limit inferior and limit superior of the integrals are equal, the limit of the integrals exists as well, and all together we have
\[ \ds\lim_{n \to \infty} \dint_\Omega f_n \dmu = \dint_\Omega \ds\lim_{n \to \infty} f_n \dmu.\]
\end{proof}

\begin{remark}{\remarktitle{Example where limits and integrals cannot be exchanged.}} Let $f_n = \frac{1}{n} \indicate{[0,n]}$.  Then $\int_{\R} f_n = 1$ for all $n$, and so $\lim_{n \to \infty} \int_{\R} f_n =1$.  But the pointwise limit $f := \lim_{n \to \infty} f_n = 0 $ and so $\int_{\R} f = \int_{\R}  0 = 0$.  %Note that the conditions of the Dominated Convergence Theorem cannot be met; there cannot be an integrable $g$ such that $|f_n| \leq g$, since $\sup_n f_n = f$ (see Remark \ref{rk:when_upper_or_lower_bound_is_contained_in_the_set_itself}) and $f$ is not integrable.  
\end{remark}


\paragraphnewline{Continuity and differentiability of functions defined with an integral}

We now consider \textit{dependence on a parameter}.  Specifically, we consider integrals where the integrand depends on a real parameter.\footnote{Here, a ``parameter" refers to a variable in the domain of the function that is not integrated over.}  The following theorem describes continuity and the computation of derivative for such functions. 

\begin{theorem}{\textbf{Continuity and differentiability of functions defined with an integral.}}
Let 
%$f : \mathcal{X} \times [a,b] \to \R$, where $(-\infty < a < b < \infty)$.  
\begin{align*}
& f : \mathcal{X} \times [a,b] \to \R, && \text{ where } (-\infty < a < b < \infty) \\
& f(\cdot, t) : \mathcal{X} \to \R \text{ be integrable} && \forall t \in [a,b] \\
&F(t) := \ds\int_{\mathcal{X}} f(x,t) \dmu(x)  
\end{align*}
\begin{alphabate}
\item Suppose
\[ |f(x,t)| \leq g(x) \quad \quad \forall x,t \]
for some integrable $g$.   If $f(x,\cdot)$ is continuous for each $x$, then $F$ is continuous.
\item Suppose $\partial f / \partial t$ exists and 
\[ \bigg|\df{\partial f}{\partial t}(x,t)\bigg| \leq g(x) \quad \quad \forall x,t \]
for some integrable $g$.  Then $F$ is differentiable and 
\[ F'(t) = \ds\int_{\mathcal{X}} \df{\partial f}{\partial t}(x,t) \dmu(x) \]
\end{alphabate}
\label{thm:continuity_and_differentiability_of_functions_defined_with_an_integral}
\end{theorem}
	
\begin{proof}
\begin{alphabate}
\item We need to show that
\[ \ds\lim_{t \to t_0} f(x,t) = f(x,t_0) \implies  \ds\lim_{t \to t_0} F(t) = F(t_0)  \]	
So 
\begin{align*}
\ds\lim_{t \to t_0} F(t) &=   \ds\lim_{t \to t_0} \ds\int_{\mathcal{X}} f(x,t) \dmu(x) && \tinytext{definition of $F$}\\
&= \ds\int_{\mathcal{X}}  \ds\lim_{t \to t_0}  f(x,t) \dmu(x) && \tinytext{Dominated Convergence Thm}\\
&= \ds\int_{\mathcal{X}}  f(x,t_0) \dmu(x) && \tinytext{hypothesis}\\
&= F(t_0) && \tinytext{definition of $F$}
\end{align*}
\item First we note that $\frac{\partial f}{\partial t}$ is measurable.  This is true by the closure properties of measurable functions (Sec. \ref{sec:closure_properties_of_measurable_functions}), since
\[ \df{\partial f}{\partial t}(x,t_0) = \ds\lim_{n \to \infty} \explaintermbrace{$:=h_n(x)$}{\df{f(x, t_n) - f(x,t_0)}{t_n - t_0}} \]
for any sequence $\set{t_n}$ converging to $t_0$.

Next we note that $h_n(x)$ is bounded uniformly in $n$.  For all $n$, there is an $s_n$ between $t_0$ and $t_n$ such that
\[  |h_n| \stackexplain{(def)}{=} \bigg|\df{f(x, t_n) - f(x,t_0)}{t_n - t_0} \bigg| \stackexplain{(MVT)}{=} \bigg| \df{\partial f}{\partial t}(x,s_n) \bigg| \stackexplain{(hypothesis)}{\leq} g(x)\]
where MVT stands for the Mean Value Theorem.

Thus, we can apply the Dominated Convergence Theorem to $h_n$, i.e. $\lim_{n \to \infty} \int h_n(x) \dmu(x) = \int \lim_{n \to \infty} h_n(x) \dmu(x)$.  Using this, we obtain
\begin{align*}
F'(t_0) &= \ds\lim_{n \to \infty} \df{F(t_n) - F(t_0)}{t_n-t_0} && \tinytext{def. derivative} \\
&= \ds\lim_{n \to \infty }	\df{ \int f(x,t_n) \dmu(x)  - \int f(x,t_0) \dmu(x)}{t_n-t_0} && \tinytext{def. $F$} \\
&= \ds\lim_{n \to \infty }	\ds\int \df{ f(x,t_n)  -  f(x,t_0) }{t_n-t_0} \dmu(x) && \tinytext{linearity, applies since $f$ integrable} \\
&= \ds\int \df{\partial}{\partial t} f(x,t) \dmu(x) && \tinytext{Dominated Convergence Theorem, def. derivative}
\end{align*}

\end{alphabate}
	
\end{proof}

\begin{remark}{\remarktitle{Extensions to real-valued parameters with unbounded support}}
Theorem \ref{thm:continuity_and_differentiability_of_functions_defined_with_an_integral}  may seem overly restrictive, since the real-valued parameter has bounded support.  However, as noted by \cite{folland1999real} pp. 56, continuity and differentiability are \textit{local} in nature.  Thus, if the hypotheses of (a) or (b) hold for all $[a,b] \subset I$ of an open interval $I$ (which is perhaps $\R$ itself), perhaps with the dominating function $g$ depending on $a$ and $b$, one obtains the continuity and differentiability of the integrated function $F$ on all of $I$! 	
\end{remark}


\section{$\S$ 1.7 Comparison of Lebesgue and Riemann integrals}

In this section, we show that integration with respect to Lebesgue measure is more general than Riemann integration, and we give a precise criterion for Riemann integration.

\paragraph{Review of Riemann integration.} Let $[a,b]$ be a bounded closed subset of the reals, and $f$ be a bounded real valued function on $[a,b]$. We assume $f$ is fixed throughout the discussion (i.e., we suppress dependence on $f$ in the notation).  Let $P: a=x_0 < x_1 < ... < x_n =b$ be a partition of $[a,b]$.  We construct the upper and lower sums as follows.  Let 
\begin{align*}
M_i &:= \sup \set{f(y) : x_{i-1} < y \leq x_i}, && i=1,...,n \\	
m_i &:= \inf \set{f(y) : x_{i-1} < y \leq x_i}, && i=1,...,n 
\end{align*}
And define step functions $\alpha$ and $\beta$, called the \textit{upper} and \textit{lower} functions for $f$ via 
\begin{align*}
\alpha(x) &= M_i && \text{ if } x_{i-1} < x \leq x_{i}   && i=1,...,n \\	
\beta(x) &= m_i && \text{ if } x_{i-1} < x \leq x_{i}  && i=1,...,n 	
\end{align*}
[$\alpha(a)$ and $\beta(a)$ may be chosen arbitrarily].   The upper and lower sums are defined as
\begin{subequations}
\begin{align}
U(P) &= \ds\sum_{i=1}^n M_i (x_i - x_{i-1}) \\	
L(P) &= \ds\sum_{i=1}^n m_i (x_i - x_{i-1}) 
\end{align}
\label{eqn:upper_and_lower_sums}	
\end{subequations}


Now let $P_1, P_2, ...$ be a sequence of partitions such that $P_{k+1}$ is a refinement of $P_k$ for each $K$, and such that $|P_k|$ (the length of the largest subinterval of $P_k$) approaches 0 as $k \to \infty$.  

If 
\begin{align}
 \lim_{k \to \infty} L(P_k) =  \lim_{k \to \infty} U(P_k) = r,
 \label{eqn:criterion_for_riemann_integrability}	
\end{align}
 independent of the particular sequence of partitions, then $f$ is said to be \textit{Riemann integrable} on $[a,b]$, and $r$ is the value of the \textit{Riemann integral}.\redfootnote{TODO: integrate this with my review of the Riemann integral in the appendix.} 

\paragraph{The criterion for Riemann integrability criterion in terms of Lebesgue integration.}

Now consider the measure space $(\Omega, \F, \mu) = ([a,b], \overline{\B}([a,b]), \text{Lebesgue measure})$, where $\overline{\B}([a,b])$ are the Lebesgue measurable sets (see Section \ref{sec:Lebesgue measurable sets}).  Let $P_k$ be a sequence of partitions described earlier, with $\alpha_k$ and $\beta_k$ the corresponding upper and lower functions.  Now since $\alpha_k$ and $\beta_k$ are simple functions, we can express the upper and lower sums \eqref{eqn:upper_and_lower_sums} as integrals with respect to Lebesgue measure $\mu$:
\begin{align*}
U(P_k) &= \ds\int_{[a,b]} \alpha_k \dmu \\
L(P_k) &= \ds\int_{[a,b]} \beta_k \dmu \\		
\end{align*}
Now we can bound the upper and lower functions by an integrable function. {\tiny (In detail, since we assumed $f$ is bounded,  we can write $|f| \leq M$, and therefore $|\alpha_k|,|\beta_k| \leq M$.  Moreover $M$ is integrable, since $\int_{[a,b]} M \dmu = M(b-a) < \infty$.)} Moreover, {\tiny (by Proposition \ref{prop:sup_and_inf_for_subsets_are_tighter})}, we have 
\[ \alpha_1 \geq \alpha_2 \geq ... \geq f \geq ... \geq \beta_2 \geq \beta_1 \]
so $\alpha_k$ and $\beta_k$ approach limit functions $\alpha$ and $\beta$.   Thus, we can apply Lebesgue dominated convergence theorem to obtain
\begin{align*}
\ds\lim_{k \to \infty} U(P_k) &= \ds\lim_{k \to \infty} \ds\int_{[a,b]} \alpha_k \dmu \stackexplain{(LDCT)}{=}  \ds\int_{[a,b]} \alpha \dmu  \\
\ds\lim_{k \to \infty} L(P_k) &= \ds\lim_{k \to \infty} \ds\int_{[a,b]} \beta_k \dmu \stackexplain{(LDCT)}{=}  \ds\int_{[a,b]} \beta \dmu   \\	
\end{align*}
Thus, we can write the criterion for Riemann integrability \eqref{eqn:criterion_for_riemann_integrability} in terms of the Lebesgue integral.  In particular, $f$ is Riemann integrable over $[a,b]$ with value $r$ iff 
\begin{align}
\ds\int_{[a,b]} \alpha \dmu = \ds\int_{[a,b]} \beta \dmu  = r
\label{eqn:criterion_for_riemann_integrability_in_terms_of_lebesgue_integral}
\end{align}
independent of the sequence of partitions $\set{P_k}$.


\paragraph{Continuity at a point as equality of the upper and lower functions.}  Here we provide a key observation which will help us to relate the Riemann integral and the Lebesgue integral. 

\begin{lemma}
If $x$ is not an endpoint of any subintervals of $P_k$, then 
\[ f \text{ is continuous at } x \quad \text{iff} \quad \alpha(x) = f(x) = \beta(x)\]	
\label{lemma:continuity_at_a_point_as_equality_of_upper_and_lower_functions}
\end{lemma}

\begin{proof}
\begin{itemize}
\item $\boxed{\implies}$.  $f$ is continuous at $x$ means that $\forall \epsilon>0, \exists \delta >0 :$
\begin{align*}
|y-x| < \delta \implies & |f(y) - f(x) | < \epsilon && \\
\implies &f(y) \leq f(x) + \epsilon  && \forall y \in B_x(\delta) \\ 
\implies &\sup_{y \in B_x(\delta)} f(y) \leq f(x) + \epsilon && \tinycircled{1}. 
\end{align*}
where $B_x(\delta)$ refers to a ball centered at $x$ with radius $\delta$.

Now let $I_k(x)$ be the subinterval in the $k$th partition to which $x$ belongs.  Since $|P_k| \to 0$, $|I_k(x)| \to 0$, and so
\[ \forall \delta>0, \exists K : \forall k \geq K, \quad  |y-x| < \delta \quad \forall y \in I_k(x) \quad \quad  \tinycircled{2} \]
Combining \tinycircled{1} and \tinycircled{2}, we obtain
\[ \forall \delta>0, \exists K : \forall k \geq K, \quad  \sup_{y \in I_k(x)} f(y) \leq f(x) + \epsilon \quad \quad  \tinycircled{3}\]
And of course, since the supremum is an upper bound and $x \in I_k(x)$, 
\[ \sup_{y \in I_k(x)} f(y) \geq f(x). \quad \quad  \tinycircled{4}\]
So combining \tinycircled{3} and \tinycircled{4}, and recalling that $\alpha_k(x) :=  \sup_{y \in I_k(x)} f(y)$, we have 
\[ \forall \delta>0, \exists K : \forall k \geq K, \quad  | \alpha_k(x) - f(x) | \leq  \epsilon\]
which is the definition of the limit.   That is,
\[ \ds\lim_{k \to \infty} \alpha_k(x) = f(x)\]
A similar argument holds for $\beta_k$.
\item $\boxed{\impliedby}$.  By hypothesis, 
\begin{align*}
\forall \epsilon>0, \exists K : \forall k \geq K, \\
 & | \sup_{y \in I_k(x)} f(y) - f(x) | \leq  \epsilon & \text{ and } && | \inf_{y \in I_k(x)} f(y) - f(x) | \leq  \epsilon  && \\	
 \stackrel{1}{\implies} & f(y) - f(x) < \epsilon & \text{ and } && f(y) - f(x) > -\epsilon && \forall y \in I_k(x) \\
\end{align*}
where (1) holds since the supremum is an upper bound and the infimum is a lower bound.  So 
\[ \forall \epsilon>0, \exists K : \forall k \geq K, \quad |f(y) - f(x) | < \epsilon \quad  \forall y \in I_k(x) \]
and taking $\delta$ to be the radius of $I_k(x)$, the definition of the continuity of $f$ at $x$ holds. 
\begin{figure}[H]
\centering
\includegraphics[width=.4\textwidth, angle=90]{images/continuity_from_equality_of_limits_of_upper_and_lower_functions}	
\end{figure}

\end{itemize}
\end{proof}

\paragraph{The theorem.}

\begin{theorem}
Let $f$ be a bounded real-valued function on $[a,b]$.	
\begin{alphabate}
\item The function $f$ is Riemann integrable on $[a,b]$ iff $f$ is continuous almost everywhere on $[a,b]$ (with respect to Lebesgue measure).
\item If $f$ is Riemann integrable on $[a,b]$, then $f$ is integrable with respect to Lebesgue measure on $[a,b]$, and the two integrals are equal.	
\end{alphabate}
\end{theorem}

\begin{proof}
\begin{alphabate}
\item
\begin{itemize}
\item $\boxed{\implies}$.  By \eqref{eqn:criterion_for_riemann_integrability_in_terms_of_lebesgue_integral}, if $f$ is Riemann integrable, then 
\[ \ds\int_{[a,b]} \alpha \dmu = \ds\int_{[a,b]} \beta \dmu = r\]
By linearity {\tiny (which holds immediately since $\alpha$, $\beta$ are integrable by the above equation; see Remark \ref{rk:additivity_holds_automatically_for_integrable_functions})}, 
\[  \ds\int_{[a,b]} (\alpha-\beta) \dmu =0  \]
Since $\beta \leq f \leq \alpha$ {\tiny (since each $\beta_k$ and $\alpha_k$ are lower and upper bounds by construction, and limits preserve non-strict inequalities)}, we have $\alpha-\beta \geq 0$, so by Theorem \ref{thm:properties_of_functions_derived_from_properties_of_integrals} (b), $\alpha-\beta =0$ a.e.  So {\tiny (by sandwiching)} $\alpha=\beta=f$ a.e.   So by Lemma \ref{lemma:continuity_at_a_point_as_equality_of_upper_and_lower_functions}, $f$ is continuous a.e.\footnote{Implicit in this last statement, I think, is that the endpoints are are set of measure 0, even in the limit.  If $E_k$ denotes the set of endpoints of the subintervals of $P_k$, and $E_{ik}$ denotes the $i$th such endpoint for $i=1,...,N_k$, then $\mu(\lim_{k \to \infty} E_k) \stackrel{1}{=} \lim_{k \to \infty} \mu(E_k) = \lim_k \mu(\cup_{i=1}^{N_k} E_{ik}) \stackrel{2}{=} 0$, where (1) holds by continuity of measure (from below; recall each successive partition is a refinement of the previous) and (2) holds since by additivity of measure, since each $E_{ik}$ is a singleton and the Lebesgue measure of any singleton is 0.
}
\item $\boxed{\impliedby}$.  By hypothesis and Lemma  \ref{lemma:continuity_at_a_point_as_equality_of_upper_and_lower_functions}, $\alpha = f = \beta$ a.e.   As a result, $f$ is measurable.   {\tiny ($\alpha, \beta$ are limits of simple functions, and hence measurable by closure properties of simple functions.  Thus, $f$ differs from a measurable function only on a subset of a set of measure 0.   Since the Lebesgue measurable sets $\overline{\B}([a,b])$ are complete, $f$ must be measurable by Problem \ref{prob:in_a_complete_metric_space_you_are_a_measurable_function_if_you_are_equal_to_some_other_measurable_function_ae}.)}\footnote{After this line \cite{ash2000probability} also adds that $f$ is integrable. {\tiny (Since $f$ is bounded, say $|f| \leq L$, we have $\int_{[a,b]} f \dmu \leq \int_{[a,b]} L \dmu = L (b-a) < \infty $.) } But on my reading, we can just use the a.e. theorem directly after arguing that $f$ is measurable.} Since $\alpha=f=\beta$ a.e., by Theorem \ref{thm:almost_everywhere} (b),  we have
\begin{align}
\ds\int_{[a,b]} \alpha \dmu =  \ds\int_{[a,b]} f \dmu  = \ds\int_{[a,b]} \beta \dmu  
\label{eqn:lebesgue_integral_of_riemann_integral_fucntion_equals_the_lebesgue_integral_of_the_limits_of_the_upper_and_lower_functions}
\end{align}

Thus $f$ is Riemann integrable by \eqref{eqn:criterion_for_riemann_integrability_in_terms_of_lebesgue_integral}.\footnote{Presumably the ``independent of the sequence of partitions" condition of \eqref{eqn:criterion_for_riemann_integrability_in_terms_of_lebesgue_integral} is met here, since the argument -- in particular, Lemma  \ref{lemma:continuity_at_a_point_as_equality_of_upper_and_lower_functions} -- does not seem to depend on the sequence of partitions.}
\end{itemize}
\item If $f$ is Riemann integrable, then $f$ is continuous a.e. by part (a).   So \eqref{eqn:lebesgue_integral_of_riemann_integral_fucntion_equals_the_lebesgue_integral_of_the_limits_of_the_upper_and_lower_functions} holds.  Then, by \eqref{eqn:criterion_for_riemann_integrability_in_terms_of_lebesgue_integral}, $\int_{[a,b]} f \dmu = r$, the value of the Riemann integral. 
\end{alphabate}
\end{proof}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliography{references_ash_notes.bib}
\bibliographystyle{unsrt}
 
\newpage 
\appendix

\section{Supremum and Infimum}

Following are some definitions and propositions that we use in the notes.\footnote{For a nice introductory overview, see \url{https://www.math.ucdavis.edu/~hunter/m125b/ch2.pdf}.}

\subsection{Characterization}

First, we define upper and lower bounds.
\begin{definition}
A set $A \subset \R$ of real numbers is bounded from above if there exists a real number $M \in \R$, called an \textit{upper bound} of $A$, such that $x \leq M$ for every $x \in A$.  Similarly, $A$  is bounded from below if there exists a real number $m \in \R$, called an \textit{lower bound} of $A$, such that $x \geq m$ for every $x \in A$.  A set is \textit{bounded} if it is bounded from above and below.
\label{def:upper_and_lower_bound}	
\end{definition}


Now, we define infimum and supremum.
\begin{definition}
Suppose that $A \subset \R$ is a set of real numbers. If $M \in \R$ is an upper bound of $A$ such that $M \leq M'$ for every upper bound $M'$ of $A$, then $M$ is called the \textit{supremum} of $A$, denoted $M=\sup A$.   Similarly, if $m \in \R$ is an lower bound of $A$ such that $m \geq m'$ for every lower bound $m'$ of $A$, then $m$ is called the \textit{infimum} of $A$, denoted $m=\inf A$.\label{def:supremum_and_infimum}	
\end{definition}

We sometimes use an alternate characterization of infimum and supremum.

\begin{proposition}

If $A \subset \R$, then $M = \sup A$ if and only if (a) $M$ is an upper bound of $A$; (b) for every $M' < M$, there exists an $a \in A$ such that $a>M'$.  Similarly, $m = \inf A$ if and only if (a) $m$ is a lower bound of $A$; (b) for all $m'>m$, there exists an $a \in A$ such that $a<m'$.

\begin{proof}
We prove the alternate characterization for the supremum only, as the proof for infimum is similar.    We only need to show equivalence for the part (b)'s, as the part (a)'s are identical. 

We first show that the definition implies part the proposition.  We proceed by way of contradiction.  Let $M = \sup A$, $M' <M$, and suppose there is no $a \in A : a > M'$. Then $M'$ is an upper bound of $A$ where $M' <M$, contradicting part (b) of the definition of supremum.   

Now we show that the proposition implies the definition. Part (b) of the proposition implies that if $M' < M$, then $M'$ is not an upper bound. Thus part (b) of the definition is satisfied.
\end{proof}
\label{prop:supremum_and_infimum_alternate_characterization}
\end{proposition}



\begin{remark}
The (b) statement in Proposition \ref{prop:supremum_and_infimum_alternate_characterization} roughly tell us that any other candidate for a smaller supremum fails, because it will not be an upper bound.  Similarly, any other candidate for a larger infimum fails, because it will not be a lower bound. 	
\end{remark}

\begin{remark}
Another way to write Proposition \ref{prop:supremum_and_infimum_alternate_characterization} is as follows:	

If $A \subset \R$, then $M = \sup A$ if and only if (a) $M$ is an upper bound of $A$; (b) for all $\epsilon >0$, there exists an $a \in A$ such that $a>M-\epsilon$.  Similarly, $m = \inf A$ if and only if (a) $m$ is a lower bound of $A$; (b) for all $\epsilon >0$, there exists an $a \in A$ such that $a<m+\epsilon$.
\label{rk:usage_of_alternate_characterization_of_inf_and_sup}
\end{remark}

\begin{remark}{\remarktitle{Existence of sequences converging to the infimum and supremum}}
By Remark \ref{rk:usage_of_alternate_characterization_of_inf_and_sup}, if $A \subset \R$, we can always find a non-decreasing sequence $\set{x_n} \subset A$ such that $\lim_{n \to \infty} x_n = \sup A$, and likewise for the infimum.  
\end{remark}

\begin{remark}{\remarktitle{When the upper or lower bound is contained in the set itself}}
Note that if a set $A$ \textit{contains} an upper bound, then it is automatically a supremum.  That is, if $M$ is an upper bound of $A$ such that $M \in A$, then the \textit{least} upper bound property (the second condition in the characterizations above) automatically follows.  For instance, condition (b) in Proposition \ref{prop:supremum_and_infimum_alternate_characterization} is immediately satisfied by setting $a=M$.   When the supremum is contained in the set, it is called a \textit{maximum}.   A similar remark holds for infima: when the lower bound is contained in the set, it is automatically the infimum, and it is called the minimum.
\label{rk:when_upper_or_lower_bound_is_contained_in_the_set_itself} 
\end{remark}


\begin{remark}
One way to show that $\sup A = \sup B$ is using breaking the equality into \framebox{$\leq$}, \framebox{$\geq$}.  We can then show
\begin{itemize}
\item \framebox{$\leq$} if RHS is an upper bound on the LHS
\item \framebox{$\geq$} if RHS is a supremum over a subset of the LHS (i.e. if $B \subset A)$	
\end{itemize}
\label{rk:one_way_to_show_two_supremums_are_equal}
\end{remark}

\subsection{Properties}

The proposition below characterizes the behavior of the infimum and supremum under set containment. Namely, making a set smaller increases its supremum and decreases its infimum. 

\begin{proposition}
Suppose that $A$ and $B$ are subsets of $\R$ such that $A \subset B$.  If $\sup A$ and $\sup B$ exist, then $\sup A \leq \sup B$.  If $\inf A$ and $\inf B$ exist, then $\inf A \geq \inf B$.
\label{prop:sup_and_inf_for_subsets_are_tighter}
\end{proposition}

Now we characterize the behavior of the infimum and supremum when we multiply a set by a constant.

\begin{definition}
If $A \subset \R$ and $c \in \R$, we define
\[ cA := \set{x \in \R : x = ca \text{ for some } a \in A}\]	
\end{definition}

\begin{proposition}

\begin{align*}
\intertext{If $c \geq 0$ then} 
\sup cA = c \sup A, &\quad \quad \inf cA = c \inf A\\
\intertext{If $c < 0$ then} 
\sup cA = c \inf A, &\quad \quad \inf cA = c \sup A
\end{align*}
\label{prop:supremum_and_infimum_under_constant_multiples_of_sets}
\end{proposition}

\begin{proof}
If $c=0$, then the result holds because $cA = \set{0}$ and $\sup \set{0} = \inf \set{0} = 0$ by Remark \ref{rk:when_upper_or_lower_bound_is_contained_in_the_set_itself}.	If $c >0$, then $M \geq a$ if and only if $cM \geq ca$, so $M$ is an upper bound of $A$ if and only if $cM$ is an upper bound of $cA$, so $\sup cA = c \sup A$.   If $c<0$, then $M \geq a$ if and only if $cM \leq ca$, so $M$ is an upper bound of $A$ if and only if $cM$ is a lower bound of $cA$, so $\inf cA = c \sup A$.  The remaining results follow similarly. 
\end{proof}


Now we characterize the behavior of infimum and supremum over set (Minskowski) sums and differences.

\begin{definition}
If $A, B \subset \R$ are non-empty, we define the \textit{Minkowski sum} of the two sets, denoted $A+B$, by 
\[ A + B := \set{z : z = x + y \text{ for some } x \in A, y \in B } \]
Similarly, we define the \textit{Minkowski difference} of two sets, denoted $A-B$, by
\[ A - B := \set{z : z = x - y \text{ for some } x \in A, y \in B } \]
\label{def:minkowski_sum_and_difference}	
\end{definition}

\begin{proposition}
If $A, B \subset \R$ are non-empty, then 
\begin{align*}
\sup (A+B) = \sup A + \sup B, &\quad \inf (A+B) = \inf A + \inf B 	 \\
\sup (A-B) = \sup A - \inf B, &\quad \inf (A-B) = \inf A - \sup B 	 \\
\end{align*}

\label{prop:sup_and_inf_for_minkowski_sum_and_diff}	
\end{proposition}

\begin{remark}
Proposition \ref{prop:sup_and_inf_for_minkowski_sum_and_diff} can be informally described as saying that the infimum and supremum distribute over addition and subtraction, but negative signs ``flip" infima to suprema, and vice versa. 
\end{remark}

\begin{proposition}
Let $\set{x_n}$ be a sequence of real numbers.  If $\set{x_n}$ is increasing, then its supremum is the limit. 	If $\set{x_n}$ is decreasing, then its infimum is the limit.
\label{prop:limit_of_monotone_sequences}
\end{proposition}


\subsection{Limit inferior and limit superior of real valued sequences}

\begin{definition}
If $a_n$ is a sequence of real numbers, then  we define its limit inferior and limit superior as 
\[ \liminf_{n \to \infty} a_n := \lim_{n \to \infty} \inf_{m \geq n} a_m, \quad \quad \limsup_{n \to \infty} a_n := \lim_{n \to \infty} \sup_{m \geq n} a_m \]	
\end{definition}

\begin{remark}
The definitions can be presented in quantified form.  For example, \cite{apostol1974mathematical} defines the limit superior as follows. Suppose there is a real number $S$ satisfying the following two conditions
\begin{enumerate}
\item \begin{align*}
 \forall \epsilon > 0, \exists N \in \mathbb{N}: \forall n \geq N,\\
 x_n < S + \epsilon 	
 \end{align*}

\item \begin{align*}
 \forall \epsilon > 0, N \in \mathbb{N}, \exists n \geq N : \\
 x_n > S - \epsilon 	
 \end{align*}
\end{enumerate}
then $S$ is the limit superior of $\set{x_n}$.  We can think of (1) as stating that $S$ is an asymptotic upper bound;  ultimately \textit{all} terms of the sequence lie to the left of $S + \epsilon$.  We can think of the additional condition (2) as then guaranteeing that $S$ is an asymptotic least upper bound; \textit{infinitely many} terms lie to the right of $U - \epsilon$ (so $U - \epsilon$ cannot be an upper bound for any $n$). 
\end{remark}

Unlike the limit, the limit inferior and limit superior always exist, although they may be $\pm \infty$. 

\begin{proposition}
\[ \liminf_{n \to \infty} a_n  \leq \limsup_{n \to \infty} a_n  \]
\label{prop:liminf_upper_bounded_by_limsup}
\end{proposition}

\begin{proof}
\[\liminf_{n \to \infty} a_n  \stackexplain{def}{=} \lim_{n \to \infty} \inf_{m \geq n} a_m \; \stackexplain{*}{\leq} \;  \lim_{n \to \infty} \sup_{m \geq n} a_m \stackexplain{def}{=}  \limsup_{n \to \infty} a_n. \]
{\tiny (Note: * holds because limits preserve non-strict inequalities.)}	
\end{proof}

\subsection{Functions}

The supremum and infimum of functions are the supremum and infimum of its range, and so results about sets translate immediately to results about functions.

\begin{definition}
If $f : A \to \R$ is a function, then 
\[ \sup_A f := \sup \set{f(x) : x \in A}, \quad \quad \inf_A f := \inf \set{f(x) : x \in A} \]	
\end{definition}

One useful result is that the limit of an increasing sequence of functions is its supremum.

\begin{proposition}
If $f_n \leq f_{n+1}$ for all $n \in \mathbb{N}$, and $f_n \to f$, then $f = \sup_n f_n$.
\label{prop:limit_of_an_increasing_sequence_of_functions_is_its_supremum}	
\end{proposition}



\subsubsection{Limit inferior and limit superior of functions}

\begin{definition}
If $\set{f_n}$ is a sequence of functions, then  we define its limit inferior and limit superior as 
\[ \liminf_{n \to \infty} f := \lim_{n \to \infty} \inf_{m \geq n} f_m, \quad \quad \limsup_{n \to \infty} f := \lim_{n \to \infty} \sup_{m \geq n} f_m \]	
\end{definition}


Applying Proposition \ref{prop:liminf_upper_bounded_by_limsup} to a function pointwise, we have 
\begin{align}
\liminf_{n \to \infty} f  \leq \limsup_{n \to \infty} f  
\label{eqn:liminf_upper_bounded_by_limsup_for_functions}
\end{align}



\section{Some information relevant to Riemann integrals} \label{sec:some_info_relevant_to_Riemann_integrals}

Let us present (using  \cite{strichartz2000way} for reference, along with pp. 56 of \cite{folland1999real} and pp.55 of \cite{ash2000probability}) some information relevant to Riemann integration for real-valued functions.  

First off, recall that the Riemann integral $\int_{a}^b f(x) \, dx$, when it exists,  is defined only for real-valued functions  $f$ whose domain is a compact space $[a,b] \subset \R$.   

Now consider the following definitions:

\begin{itemize}
\item A \textit{partition} of a compact interval $[a,b]$ is a finite sequence $P=\set{x_i}_{i=0}^n$ such that $a=x_0 < x_1 < ... < x_n = b$. 
\item Given a partition $P$, the \textit{upper sum} $S^+(f,P)$ and \textit{lower sum} $S^-(f,P)$ are defined by\footnote{References \cite{strichartz2000way} and \cite{folland1999real} define the supremum and infimum over closed sets $[x_{i-1}, x_i]$, whereas \cite{ash2000probability} defines them over $(x_{i-1},x_i]$.  It presumably doesn't matter.}
\begin{align*}
S^+(f,P) &:= \ds\sum_{i=1}^n M_i (x_i - x_{i-1}) \\
&\quad \text{ where $M_i$ is the supremum of $f$ on $(x_{i-1}, x_i]$.} \\	
S^-(f,P) &:= \ds\sum_{i=1}^n m_i (x_i - x_{i-1}) \\
&\quad \text{ where $m_i$ is the infimum of $f$ on $(x_{i-1}, x_i]$.} \\
\end{align*}
\item The \textit{oscillation} $\text{Osc}(f,P)$ of a function $f$ over a partition $P$ is given by the difference of the upper and lower sums; i.e. $ \text{Osc}(f,P) := S^+(f,P) - S^-(f,P)$.
\item The \textit{maximum interval length} of $P$ is defined by $ \max_{i=1,...,n} \big|[x_{i-1}, x_i]\big|$.
\end{itemize}

Finally, we present a proposition we use in the main text. 

\begin{proposition}
If $f$ is a bounded real-valued function on $[a,b]$, then $f$ is Riemann integrable iff $\text{Osc}(f,P) \to 0$ as the maximum interval length of $P$ goes to 0.
\label{prop:Riemann_integrable_iff_oscillation_goes_to_zero_as_partition_gets_finer}
\end{proposition}

\begin{proof}
See Theorem 6.2.1 of \cite{strichartz2000way}.	
\end{proof}



\section{Miscellaneous}
\subsection{Right semi-closed intervals}
\begin{definition}
A \textbf{right semi-closed interval} is a set of the form $(a,b] = \set{x : a < x \leq b}, -\infty \leq a < b < \infty$.  By convention, we also count $(a,\infty)$ as right semi-closed for $-\infty \leq a < \infty$. 
\label{def:rsc_intervals}
\end{definition}

\subsection{DeMorgan's Law applies to relative complements} 

\begin{remark}
DeMorgan's Law also holds for relative complements.  That is, given a sequence of sets $A_1, A_2, ...$ that are subsets of another set $X$, we have:

\begin{align*}
X - \bigcap_{n=1}^\infty A_n = \bigcup_{n=1}^\infty (X - A_n)
\labelit \label{eqn:demorgan_for_relative_complements}	
\end{align*}

	
\end{remark}


\end{document}
